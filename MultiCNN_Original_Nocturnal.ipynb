{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c0a15e4-1949-4dce-a792-954d897675c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from scipy import stats\n",
    "from scipy.signal import find_peaks, detrend\n",
    "import pywt\n",
    "\n",
    "from numpy import arange, array, linspace, loadtxt, log2, logspace, mean, polyfit\n",
    "from numpy import zeros, pi, sin, cos, arctan2, sqrt, real, imag, conj, tile\n",
    "from numpy import round, interp, diff, unique, where\n",
    "from pandas import DataFrame, date_range\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import pyplot\n",
    "from scipy.stats import pearsonr, mannwhitneyu, kruskal, norm\n",
    "from sklearn.linear_model import LinearRegression, Ridge, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GroupKFold\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score,f1_score, recall_score, precision_score,roc_auc_score, roc_curve, auc,accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier, GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.utils import shuffle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import GlobalAveragePooling2D,GlobalMaxPooling2D,Concatenate,Input,Dropout, Conv2D, MaxPooling2D, Flatten,Multiply,Attention,Dense,concatenate,Masking,BatchNormalization, Reshape\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications import DenseNet121\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, History\n",
    "history = History()\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "import dill\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from scipy.signal import savgol_filter\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e52d8c9-f1e3-4b65-8bb6-e4596cf71687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# List all available GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# Set the visible devices\n",
    "try:\n",
    "    tf.config.set_visible_devices(gpus[1], 'GPU')  # Adjust indices as needed\n",
    "    # tf.config.set_visible_devices(gpus[7], 'GPU')  # Adjust indices as needed\n",
    "except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a21e1ac-3894-455d-8100-b863503f6589",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_nan_rows(X_daily, X_individual, y_label):\n",
    "    # Find rows with NaNs in either feature vector\n",
    "    nan_mask_daily = np.any(np.isnan(X_daily), axis=(1, 2))\n",
    "    nan_mask_individual = np.any(np.isnan(X_individual), axis=(1, 2))\n",
    "    \n",
    "    nan_mask_combined = nan_mask_daily | nan_mask_individual    \n",
    "    # Keep only rows without NaNs\n",
    "    X_daily_clean = X_daily[~nan_mask_combined]\n",
    "    X_individual_clean = X_individual[~nan_mask_combined]\n",
    "    y_label_clean = y_label[~nan_mask_combined]\n",
    "    return X_daily_clean, X_individual_clean, y_label_clean\n",
    "\n",
    "def apply_smote_resampling(X_matrices, X_features_daily, X_features_individual, y, matrix_shape0=288):\n",
    "    smote = SMOTE(random_state=42)\n",
    "\n",
    "    # Combine all inputs into a single 2D array for SMOTE\n",
    "    X_combined = np.hstack([\n",
    "        X_matrices.reshape(-1, matrix_shape0 * 288*3),\n",
    "        X_features_daily,\n",
    "        X_features_individual\n",
    "    ])\n",
    "\n",
    "    # Apply SMOTE to the combined array and the target\n",
    "    X_resampled_combined, y_resampled = smote.fit_resample(X_combined, y)\n",
    "\n",
    "    # Extract the resampled components\n",
    "    X_matrices_resampled = X_resampled_combined[:, :matrix_shape0 * 288*3].reshape(-1, matrix_shape0, 288, 3)\n",
    "    start = matrix_shape0 * 288*3\n",
    "    X_features_daily_resampled = X_resampled_combined[:, start:start + X_features_daily.shape[1]]\n",
    "    start += X_features_daily.shape[1]\n",
    "    X_features_individual_resampled = X_resampled_combined[:, start:]\n",
    "    \n",
    "    return (X_matrices_resampled, \n",
    "            X_features_daily_resampled, \n",
    "            X_features_individual_resampled, \n",
    "            y_resampled)\n",
    "\n",
    "def apply_smote_resampling_mask(X_matrices, X_features_daily, X_features_individual, mask_daily, mask_individual, y, matrix_shape0=288):\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_combined = np.hstack([\n",
    "        X_matrices.reshape(-1, matrix_shape0 * 288*3),\n",
    "        X_features_daily,\n",
    "        X_features_individual,\n",
    "        mask_daily,\n",
    "        mask_individual\n",
    "    ])\n",
    "    X_resampled_combined, y_resampled = smote.fit_resample(X_combined, y)\n",
    "\n",
    "    X_matrices_resampled = X_resampled_combined[:, :matrix_shape0 * 288*3].reshape(-1, matrix_shape0, 288, 3)\n",
    "    start = matrix_shape0 * 288*3\n",
    "    X_features_daily_resampled = X_resampled_combined[:, start:start + X_features_daily.shape[1]]\n",
    "    start += X_features_daily.shape[1]\n",
    "    X_features_individual_resampled = X_resampled_combined[:, start:start + X_features_individual.shape[1]]\n",
    "    start += X_features_individual.shape[1]\n",
    "    mask_daily_resampled = X_resampled_combined[:, start:start + mask_daily.shape[1]]\n",
    "    start += mask_daily.shape[1]\n",
    "    mask_individual_resampled = X_resampled_combined[:, start:]\n",
    "\n",
    "    return (X_matrices_resampled, \n",
    "            X_features_daily_resampled, \n",
    "            X_features_individual_resampled, \n",
    "            mask_daily_resampled, \n",
    "            mask_individual_resampled, \n",
    "            y_resampled)\n",
    "def apply_smote_resampling_mask_2d(X_matrices, X_features_daily, X_features_individual, mask_daily, mask_individual, y, matrix_shape0=288):\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_combined = np.hstack([\n",
    "        X_matrices.reshape(-1, matrix_shape0 * 288*2),\n",
    "        X_features_daily,\n",
    "        X_features_individual,\n",
    "        mask_daily,\n",
    "        mask_individual\n",
    "    ])\n",
    "    X_resampled_combined, y_resampled = smote.fit_resample(X_combined, y)\n",
    "\n",
    "    X_matrices_resampled = X_resampled_combined[:, :matrix_shape0 * 288*2].reshape(-1, matrix_shape0, 288, 2)\n",
    "    start = matrix_shape0 * 288*2\n",
    "    X_features_daily_resampled = X_resampled_combined[:, start:start + X_features_daily.shape[1]]\n",
    "    start += X_features_daily.shape[1]\n",
    "    X_features_individual_resampled = X_resampled_combined[:, start:start + X_features_individual.shape[1]]\n",
    "    start += X_features_individual.shape[1]\n",
    "    mask_daily_resampled = X_resampled_combined[:, start:start + mask_daily.shape[1]]\n",
    "    start += mask_daily.shape[1]\n",
    "    mask_individual_resampled = X_resampled_combined[:, start:]\n",
    "\n",
    "    return (X_matrices_resampled, \n",
    "            X_features_daily_resampled, \n",
    "            X_features_individual_resampled, \n",
    "            mask_daily_resampled, \n",
    "            mask_individual_resampled, \n",
    "            y_resampled)\n",
    "def apply_smote_resampling_mask_1d(X_matrices, X_features_daily, X_features_individual, mask_daily, mask_individual, y, matrix_shape0=288):\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_combined = np.hstack([\n",
    "        X_matrices.reshape(-1, matrix_shape0 * 288*1),\n",
    "        X_features_daily,\n",
    "        X_features_individual,\n",
    "        mask_daily,\n",
    "        mask_individual\n",
    "    ])\n",
    "    X_resampled_combined, y_resampled = smote.fit_resample(X_combined, y)\n",
    "\n",
    "    X_matrices_resampled = X_resampled_combined[:, :matrix_shape0 * 288*1].reshape(-1, matrix_shape0, 288, 1)\n",
    "    start = matrix_shape0 * 288*1\n",
    "    X_features_daily_resampled = X_resampled_combined[:, start:start + X_features_daily.shape[1]]\n",
    "    start += X_features_daily.shape[1]\n",
    "    X_features_individual_resampled = X_resampled_combined[:, start:start + X_features_individual.shape[1]]\n",
    "    start += X_features_individual.shape[1]\n",
    "    mask_daily_resampled = X_resampled_combined[:, start:start + mask_daily.shape[1]]\n",
    "    start += mask_daily.shape[1]\n",
    "    mask_individual_resampled = X_resampled_combined[:, start:]\n",
    "\n",
    "    return (X_matrices_resampled, \n",
    "            X_features_daily_resampled, \n",
    "            X_features_individual_resampled, \n",
    "            mask_daily_resampled, \n",
    "            mask_individual_resampled, \n",
    "            y_resampled)\n",
    "    \n",
    "def apply_SMOTEENN_resampling_mask(X_matrices, X_features_daily, X_features_individual, mask_daily, mask_individual, y, matrix_shape0=288):\n",
    "    smoteenn = SMOTEENN(random_state=42)\n",
    "    X_combined = np.hstack([\n",
    "        X_matrices.reshape(-1, matrix_shape0 * 288*3),\n",
    "        X_features_daily,\n",
    "        X_features_individual,\n",
    "        mask_daily,\n",
    "        mask_individual\n",
    "    ])\n",
    "    X_resampled_combined, y_resampled = smoteenn.fit_resample(X_combined, y)\n",
    "\n",
    "    X_matrices_resampled = X_resampled_combined[:, :matrix_shape0 * 288*3].reshape(-1, matrix_shape0, 288, 3)\n",
    "    start = matrix_shape0 * 288*3\n",
    "    X_features_daily_resampled = X_resampled_combined[:, start:start + X_features_daily.shape[1]]\n",
    "    start += X_features_daily.shape[1]\n",
    "    X_features_individual_resampled = X_resampled_combined[:, start:start + X_features_individual.shape[1]]\n",
    "    start += X_features_individual.shape[1]\n",
    "    mask_daily_resampled = X_resampled_combined[:, start:start + mask_daily.shape[1]]\n",
    "    start += mask_daily.shape[1]\n",
    "    mask_individual_resampled = X_resampled_combined[:, start:]\n",
    "\n",
    "    return (X_matrices_resampled, \n",
    "            X_features_daily_resampled, \n",
    "            X_features_individual_resampled, \n",
    "            mask_daily_resampled, \n",
    "            mask_individual_resampled, \n",
    "            y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63882209-4d46-49d6-8c41-ef2f2d560b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/data1/ma98/data_generated/dict_3d_cgm_mex_morl_original_70_15min.dill', 'rb') as f:\n",
    "    loaded_dict = dill.load(f)\n",
    "    \n",
    "data_dict = loaded_dict.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3526739d-9a8e-48a1-897b-2a54d39af0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491 491\n"
     ]
    }
   ],
   "source": [
    "filtered_data_dict = {}\n",
    "for participant_id, days_data in data_dict.items():\n",
    "    filtered_days_data = []\n",
    "    for current_date, day_data in days_data.items():\n",
    "\n",
    "        if (day_data['len_original_cgm'] > 252 and np.sum(day_data['CGM_stats_daily_original'].isna()).sum()<1):\n",
    "            filtered_days_data.append(day_data)\n",
    "    \n",
    "    if filtered_days_data:\n",
    "        filtered_data_dict[participant_id] = filtered_days_data\n",
    "\n",
    "print(len(data_dict),len(filtered_data_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dcd6047-c728-4ab4-8546-4d171e905624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in the Data ...\n",
      "X_matrices_power: 0  NaNs with shape: (10702, 288, 288, 3)\n",
      "X_matrices_coeffs: 0  NaNs with shape: (10702, 288, 288, 3)\n",
      "X_features_daily: 385521  NaNs with shape: (10702, 1, 326)\n",
      "X_features_individual: 70296  NaNs with shape: (10702, 1, 294)\n",
      "X_features_daily_cgm: 0  NaNs with shape: (10702, 1, 136)\n",
      "X_features_individual_cgm: 0  NaNs with shape: (10702, 1, 141)\n",
      "y_label hypo_early_night: 0  NaNs with shape: (10702, 1)\n",
      "y_label hypo_night: 0  NaNs with shape: (10702, 1)\n",
      "y_label hypo_long_night: 0  NaNs with shape: (10702, 1)\n",
      "y_label hypo_night_morning: 0  NaNs with shape: (10702, 1)\n",
      "y_label hyper_day: 0  NaNs with shape: (10702, 1)\n",
      "y_label hypo_late_night: 0  NaNs with shape: (10702, 1)\n",
      "y_label hyper_night: 0  NaNs with shape: (10702, 1)\n",
      "y_label hyper_early_night: 0  NaNs with shape: (10702, 1)\n",
      "y_label hypo_morning: 0  NaNs with shape: (10702, 1)\n",
      "y_label hypo_day: 0  NaNs with shape: (10702, 1)\n"
     ]
    }
   ],
   "source": [
    "# Prepare the groups based on participant IDs\n",
    "participant_ids = []\n",
    "X_features_individual, X_features_daily = [], []\n",
    "X_features_individual_cgm, X_features_daily_cgm = [], []\n",
    "X_matrices_power, X_matrices_coeffs = [], []\n",
    "y_labels = { \n",
    "    \"hypo_early_night\": [], \"hypo_night\": [], \"hypo_long_night\": [],\n",
    "    \"hypo_night_morning\": [], \"hyper_day\": [], \"hypo_late_night\": [],\n",
    "    \"hyper_night\": [], \"hyper_early_night\": [], \"hypo_morning\": [],\n",
    "    \"hypo_day\": []\n",
    "}\n",
    "\n",
    "for participant_id, days_data in filtered_data_dict.items():\n",
    "    participant_ids.extend([participant_id] * len(days_data))\n",
    "    for day_data in days_data:\n",
    "        X_matrices_power.append(day_data['full_matrix_cgm_power'])\n",
    "        X_matrices_coeffs.append(day_data['full_matrix_cgm_coeffs'])\n",
    "        X_features_daily_cgm.append(day_data['CGM_stats_daily'])\n",
    "        X_features_individual_cgm.append(day_data['CGM_stats_participant'])\n",
    "        X_features_daily.append(np.concatenate([\n",
    "            day_data['CGM_stats_daily_original'],\n",
    "            day_data['Basal_stats_daily'],\n",
    "            day_data['Carbs_stats_daily'],\n",
    "            day_data['HR_stats_daily']], axis=1))\n",
    "        X_features_individual.append(np.concatenate([\n",
    "            [[day_data['A1c']]],\n",
    "            [[day_data['Weight']]],\n",
    "            [[day_data['Height']]],\n",
    "            day_data['CGM_stats_participant'],\n",
    "            day_data['Basal_stats_participant'],\n",
    "            day_data['HR_stats_participant']], axis=1))\n",
    "        \n",
    "        # Store labels in the dictionary\n",
    "        for label in y_labels.keys():\n",
    "            y_labels[label].append(day_data['next_day_cgm_labels_original'][label])\n",
    "    \n",
    "participant_ids = np.array(participant_ids)\n",
    "X_matrices_power = np.array(X_matrices_power)\n",
    "X_matrices_coeffs = np.array(X_matrices_coeffs)\n",
    "X_features_daily = np.array(X_features_daily)\n",
    "X_features_individual = np.array(X_features_individual)\n",
    "X_features_daily_cgm = np.array(X_features_daily_cgm)\n",
    "X_features_individual_cgm = np.array(X_features_individual_cgm)\n",
    "\n",
    "# Convert labels to NumPy arrays\n",
    "for key in y_labels:\n",
    "    y_labels[key] = np.array(y_labels[key], dtype=np.float32)\n",
    "\n",
    "# Normalize the individual features\n",
    "def standard_scale(data):\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(data.reshape(-1, data.shape[-1]))\n",
    "\n",
    "# Apply vectorized scaling\n",
    "X_features_individual_scaled = standard_scale(X_features_individual)\n",
    "X_features_daily_scaled = standard_scale(X_features_daily)\n",
    "X_features_individual_cgm_scaled = standard_scale(X_features_individual_cgm)\n",
    "X_features_daily_cgm_scaled = standard_scale(X_features_daily_cgm)\n",
    "\n",
    "def check_nans(arr, name):\n",
    "    print(f\"{name}: {np.isnan(arr).sum()}  NaNs with shape: {arr.shape}\")\n",
    "\n",
    "print('NaNs in the Data ...')\n",
    "check_nans(X_matrices_power, \"X_matrices_power\")\n",
    "check_nans(X_matrices_coeffs, \"X_matrices_coeffs\")\n",
    "check_nans(X_features_daily, \"X_features_daily\")\n",
    "check_nans(X_features_individual, \"X_features_individual\")\n",
    "check_nans(X_features_daily_cgm, \"X_features_daily_cgm\")\n",
    "check_nans(X_features_individual_cgm, \"X_features_individual_cgm\")\n",
    "for key in y_labels:\n",
    "    check_nans(y_labels[key], f\"y_label {key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6c10bca-c8cd-4e9b-9697-5de18892f018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.07285298e-06, 1.09657967e-04, 1.49772296e-04, ...,\n",
       "        2.34176964e-05, 5.28250211e-05, 1.95310295e-04],\n",
       "       [2.50270754e-03, 3.17086616e-03, 9.22433324e-05, ...,\n",
       "        3.66439113e-03, 1.30995087e-02, 1.30063819e-02],\n",
       "       [1.55885471e-02, 2.09501266e-03, 1.45394958e-03, ...,\n",
       "        7.26925644e-03, 2.63986305e-03, 3.72076772e-05],\n",
       "       ...,\n",
       "       [1.42963757e-05, 2.65158540e-04, 6.26985951e-04, ...,\n",
       "        1.89597705e-04, 2.37221582e-03, 2.15363007e-03],\n",
       "       [5.62506759e-03, 8.67475687e-03, 8.48445730e-03, ...,\n",
       "        2.01446124e-03, 6.29517492e-03, 9.75784029e-03],\n",
       "       [2.32378114e-03, 4.64502720e-03, 4.15342970e-03, ...,\n",
       "        1.69490564e-05, 1.54745031e-04, 6.26550838e-04]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def manual_standard_scaling(matrix):\n",
    "    # mean = np.nanmean(matrix)\n",
    "    std = np.nanstd(matrix)\n",
    "    scaled_matrix = matrix / std\n",
    "    return scaled_matrix\n",
    "    \n",
    "X_matrices_power_scaled = np.zeros_like(X_matrices_power)\n",
    "for i in range(X_matrices_power.shape[0]):\n",
    "    matrix_coefficients_scaled = manual_standard_scaling(X_matrices_power[i, :, :, 0])\n",
    "    X_matrices_power_scaled[i, :, :, 0] = matrix_coefficients_scaled\n",
    "    \n",
    "    matrix_power_scaled = manual_standard_scaling(X_matrices_power[i, :, :, 1])\n",
    "    X_matrices_power_scaled[i, :, :, 1] = matrix_power_scaled\n",
    "    matrix_power_scaled = manual_standard_scaling(X_matrices_power[i, :, :, 2])\n",
    "    X_matrices_power_scaled[i, :, :, 2] = matrix_power_scaled\n",
    "    \n",
    "X_matrices_coeffs_scaled = np.zeros_like(X_matrices_coeffs)\n",
    "for i in range(X_matrices_coeffs.shape[0]):\n",
    "    matrix_coefficients_scaled = manual_standard_scaling(X_matrices_coeffs[i, :, :, 0])\n",
    "    X_matrices_coeffs_scaled[i, :, :, 0] = matrix_coefficients_scaled\n",
    "    \n",
    "    matrix_power_scaled = manual_standard_scaling(X_matrices_coeffs[i, :, :, 1])\n",
    "    X_matrices_coeffs_scaled[i, :, :, 1] = matrix_power_scaled\n",
    "    matrix_power_scaled = manual_standard_scaling(X_matrices_coeffs[i, :, :, 2])\n",
    "    X_matrices_coeffs_scaled[i, :, :, 2] = matrix_power_scaled\n",
    "    \n",
    "X_matrices_power_scaled[0,:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc1a493b-3ca0-4b4d-8ef9-8c3f5f18101a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10702, 288, 288)\n"
     ]
    }
   ],
   "source": [
    "# Remove the first channel and keep only channels 1 and 2\n",
    "X_power_mex_morl = X_matrices_power_scaled[:, :, :, 1:]  \n",
    "X_coeffs_mex_power_morl = X_matrices_power_scaled[:, :, :, [0,2]]  \n",
    "X_coeffs_power_mex = X_matrices_power_scaled[:, :, :, :2]  \n",
    "X_coeffs_morl = X_matrices_coeffs_scaled[:, :, :, 0]  \n",
    "X_coeffs_mex = X_matrices_power_scaled[:, :, :, 0]  \n",
    "X_power_mex = X_matrices_power_scaled[:, :, :, :1]  \n",
    "X_power_morl = X_matrices_power_scaled[:, :, :, 2]  \n",
    "\n",
    "# Check the new shape\n",
    "print(X_coeffs_mex.shape)  # Should output (10707, 288, 288, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f8dbbc0-bd27-47d5-8457-0bf8ba2ff88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2368"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attention mechanism\n",
    "def attention_block(x):\n",
    "    attention = Conv2D(32, kernel_size=(1, 1), activation='relu')(x)\n",
    "    attention = BatchNormalization()(attention)\n",
    "    attention = GlobalMaxPooling2D()(attention)\n",
    "    attention = Dense(x.shape[-1], activation='sigmoid')(attention)\n",
    "    attention = Reshape((1, 1, x.shape[-1]))(attention)\n",
    "    attention = Multiply()([x, attention])\n",
    "    return attention\n",
    "def create_model():\n",
    "    # Define the CNN Model\n",
    "    input_matrix = Input(shape=(matrix_shape0, 288, 3), name='input_matrix')\n",
    "    input_features_daily = Input(shape=(X_features_daily_scaled.shape[1],), name='input_features_daily')\n",
    "    input_features_individual = Input(shape=(X_features_individual_scaled.shape[1],), name='input_features_individual')\n",
    "    input_mask_daily = Input(shape=(X_features_daily_scaled.shape[1],), name='input_mask_daily')\n",
    "    input_mask_individual = Input(shape=(X_features_individual_scaled.shape[1],), name='input_mask_individual')\n",
    "    \n",
    "    conv1 = Conv2D(32, kernel_size=(5, 5), strides=(2, 2), activation='relu', kernel_regularizer=l2(0.001))(input_matrix)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv1 = attention_block(conv1)  # Add attention here\n",
    "    # conv1 = Dropout(0.2)(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, kernel_size=(3, 3), dilation_rate=(2, 2), activation='relu', kernel_regularizer=l2(0.001))(conv1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    # conv2 = Dropout(0.2)(conv2)\n",
    "\n",
    "    # Convolution Block 3 with Spatial Pyramid Pooling\n",
    "    conv3 = Conv2D(128, kernel_size=(3, 3), strides=(2, 2), activation='relu', kernel_regularizer=l2(0.001))(conv2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    # Flatten and concatenate with feature vectors\n",
    "    flat = Flatten()(conv3)\n",
    "    dense_flat = Dense(1024, activation='relu', kernel_regularizer=l2(0.001))(flat)\n",
    "    attention_flat = Dense(1024, activation='softmax')(dense_flat)\n",
    "    attention_flat = Multiply()([dense_flat, attention_flat])\n",
    "\n",
    "    densed_fully = Dense(512, activation='relu')(attention_flat)\n",
    "    densed_fully = Dropout(0.5)(densed_fully)\n",
    "\n",
    "    # Masked dense layers for the daily features\n",
    "    masked_daily = Multiply()([input_features_daily, input_mask_daily])  # Apply mask to daily features\n",
    "    dense_daily = Dense(128, activation='relu')(masked_daily)\n",
    "    \n",
    "    # Masked dense layers for the individual features\n",
    "    masked_individual = Multiply()([input_features_individual, input_mask_individual])\n",
    "    dense_individual = Dense(128, activation='relu')(masked_individual)\n",
    "    \n",
    "    # Combine feature inputs\n",
    "    concat_features = concatenate([dense_daily, dense_individual])\n",
    "    \n",
    "    # Cross-Attention mechanism to extract relevant parts of both feature vectors\n",
    "    attention_weights = Dense(256, activation='softmax')(concat_features)\n",
    "    attention_features = Multiply()([concat_features, attention_weights])\n",
    "    \n",
    "    # Combine all inputs\n",
    "    concat_all = concatenate([densed_fully, attention_features])\n",
    "    \n",
    "    fc_combined = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(concat_all)\n",
    "    fc_combined = Dropout(0.6)(fc_combined)\n",
    "\n",
    "    attention_fc_combined = Dense(256, activation='relu')(fc_combined)\n",
    "    attention_fc_combined = Dropout(0.7)(attention_fc_combined)\n",
    "    \n",
    "    fc_additional = Dense(128, activation='relu')(attention_fc_combined)\n",
    "    output = Dense(1, activation='sigmoid', dtype='float32')(fc_additional)\n",
    "    model = Model(inputs=[input_matrix, input_features_daily, input_features_individual, input_mask_daily, input_mask_individual], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy', 'AUC'])\n",
    "    return model\n",
    "import gc\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc698823-b225-4098-bc78-bbb7444b9a2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 1...\n",
      "351, 69, 46, participants in Train, Validation, and Test sets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-01 21:19:03.959681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78973 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:2a:00.0, compute capability: 8.0\n",
      "2024-10-01 21:19:06.242194: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-01 21:19:06.242228: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-01 21:19:06.242253: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-01 21:19:06.242275: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-01 21:19:06.242312: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-01 21:19:06.242359: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-01 21:19:06.242512: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-01 21:19:06.242580: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-01 21:19:06.242610: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-01 21:19:06.242750: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-01 21:19:06.242790: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-01 21:19:06.242935: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-01 21:19:06.242980: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-01 21:19:06.245917: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.0\n",
      "2024-10-01 21:19:06.245929: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2024-10-01 21:19:06.245962: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-10-01 21:19:06.245993: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-10-01 21:19:06.246020: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-10-01 21:19:06.246132: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-10-01 21:19:06.246149: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-10-01 21:19:06.246163: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-10-01 21:19:06.246179: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-10-01 21:19:06.246205: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-10-01 21:19:06.246458: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-10-01 21:19:06.246474: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-10-01 21:19:06.246483: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-10-01 21:19:06.246539: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-10-01 21:19:06.246590: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-01 21:19:48.997516: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fab3c008220 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-10-01 21:19:48.997608: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "2024-10-01 21:19:49.605381: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-01 21:19:59.591210: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8907\n",
      "2024-10-01 21:20:07.253007: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-01 21:20:07.256644: W tensorflow/compiler/xla/stream_executor/gpu/redzone_allocator.cc:322] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2024-10-01 21:20:07.260179: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-01 21:20:07.263422: W tensorflow/compiler/xla/service/gpu/buffer_comparator.cc:1052] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Setting XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda  or modifying $PATH can be used to set the location of ptxas\n",
      "This message will only be logged once.\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-01 21:20:13.267261: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-01 21:20:14.125445: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m426/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.7726 - accuracy: 0.6853 - loss: 2.3265"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-01 21:20:28.450225: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - AUC: 0.7731 - accuracy: 0.6859 - loss: 2.3226"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-01 21:20:36.469777: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-01 21:20:38.271427: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 54ms/step - AUC: 0.7733 - accuracy: 0.6861 - loss: 2.3213 - val_AUC: 0.6473 - val_accuracy: 0.6476 - val_loss: 1.5179 - learning_rate: 1.0000e-04\n",
      "Epoch 2/35\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - AUC: 0.9377 - accuracy: 0.8767 - loss: 0.8907 - val_AUC: 0.9547 - val_accuracy: 0.8949 - val_loss: 0.7076 - learning_rate: 1.0000e-04\n",
      "Epoch 3/35\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - AUC: 0.9762 - accuracy: 0.9287 - loss: 0.5964 - val_AUC: 0.9598 - val_accuracy: 0.9010 - val_loss: 0.5967 - learning_rate: 1.0000e-04\n",
      "Epoch 4/35\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - AUC: 0.9833 - accuracy: 0.9429 - loss: 0.4771 - val_AUC: 0.9620 - val_accuracy: 0.8834 - val_loss: 0.5871 - learning_rate: 1.0000e-04\n",
      "Epoch 5/35\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - AUC: 0.9901 - accuracy: 0.9545 - loss: 0.3839 - val_AUC: 0.9581 - val_accuracy: 0.9037 - val_loss: 0.5263 - learning_rate: 1.0000e-04\n",
      "Epoch 6/35\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - AUC: 0.9924 - accuracy: 0.9628 - loss: 0.3281 - val_AUC: 0.9566 - val_accuracy: 0.8976 - val_loss: 0.5288 - learning_rate: 1.0000e-04\n",
      "Epoch 7/35\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - AUC: 0.9947 - accuracy: 0.9723 - loss: 0.2799 - val_AUC: 0.9464 - val_accuracy: 0.8792 - val_loss: 0.6110 - learning_rate: 1.0000e-04\n",
      "Epoch 8/35\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - AUC: 0.9964 - accuracy: 0.9780 - loss: 0.2421 - val_AUC: 0.9487 - val_accuracy: 0.8761 - val_loss: 0.6082 - learning_rate: 1.0000e-04\n",
      "Epoch 9/35\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - AUC: 0.9975 - accuracy: 0.9804 - loss: 0.2193 - val_AUC: 0.9484 - val_accuracy: 0.8823 - val_loss: 0.6018 - learning_rate: 1.0000e-04\n",
      "Epoch 10/35\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - AUC: 0.9982 - accuracy: 0.9850 - loss: 0.1970 - val_AUC: 0.9429 - val_accuracy: 0.8628 - val_loss: 0.6538 - learning_rate: 1.0000e-04\n",
      "Epoch 11/35\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - AUC: 0.9991 - accuracy: 0.9879 - loss: 0.1791 - val_AUC: 0.9402 - val_accuracy: 0.8765 - val_loss: 0.6886 - learning_rate: 5.0000e-05\n",
      "Epoch 12/35\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - AUC: 0.9992 - accuracy: 0.9957 - loss: 0.1568 - val_AUC: 0.9358 - val_accuracy: 0.8807 - val_loss: 0.7481 - learning_rate: 5.0000e-05\n",
      "Epoch 13/35\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - AUC: 0.9993 - accuracy: 0.9968 - loss: 0.1491 - val_AUC: 0.9273 - val_accuracy: 0.8727 - val_loss: 0.8880 - learning_rate: 5.0000e-05\n",
      "Epoch 14/35\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - AUC: 0.9995 - accuracy: 0.9948 - loss: 0.1500 - val_AUC: 0.9298 - val_accuracy: 0.8746 - val_loss: 0.8479 - learning_rate: 5.0000e-05\n",
      "Epoch 15/35\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - AUC: 0.9997 - accuracy: 0.9954 - loss: 0.1445 - val_AUC: 0.9310 - val_accuracy: 0.8826 - val_loss: 0.8285 - learning_rate: 5.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-01 21:24:07.498453: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.3382778465747833, Train accuracy: 0.9654569029808044\n",
      "Validation loss: 0.5263001322746277, Validation accuracy: 0.9036697149276733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-01 21:24:27.299820: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m248/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-01 21:24:30.885198: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step\n",
      "\u001b[1m30/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-01 21:24:33.622984: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
      "Test ROC AUC: 0.8860\n",
      "Test Accuracy: 0.8168\n",
      "Test MAE: 0.1589\n",
      "Test Percision: 0.4138\n",
      "Test Specificity: 0.8241\n",
      "Test Sensitivity(Recall): 0.7714\n",
      "Test F1: 0.5387 \n",
      "\n",
      "Fold 1 - AUC: 0.8860, Accuracy: 0.8168, Recall: 0.7714, Precision: 0.4138, Specificity: 0.8241, F1: 0.5387\n",
      "\n",
      "[[717 153]\n",
      " [ 32 108]]\n",
      "Processing fold 2...\n",
      "349, 70, 47, participants in Train, Validation, and Test sets\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-01 21:37:38.001905: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m430/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - AUC: 0.7206 - accuracy: 0.6452 - loss: 2.2917"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-01 21:37:54.828908: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m432/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - AUC: 0.7211 - accuracy: 0.6457 - loss: 2.2894"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-01 21:38:07.295714: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m432/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 63ms/step - AUC: 0.7214 - accuracy: 0.6459 - loss: 2.2882 - val_AUC: 0.7873 - val_accuracy: 0.6715 - val_loss: 1.3363 - learning_rate: 1.0000e-04\n",
      "Epoch 2/35\n",
      "\u001b[1m432/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - AUC: 0.9392 - accuracy: 0.8780 - loss: 0.9648 - val_AUC: 0.9622 - val_accuracy: 0.8815 - val_loss: 0.7602 - learning_rate: 1.0000e-04\n",
      "Epoch 3/35\n",
      "\u001b[1m432/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - AUC: 0.9746 - accuracy: 0.9263 - loss: 0.6493 - val_AUC: 0.9695 - val_accuracy: 0.9051 - val_loss: 0.5884 - learning_rate: 1.0000e-04\n",
      "Epoch 4/35\n",
      "\u001b[1m432/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - AUC: 0.9837 - accuracy: 0.9400 - loss: 0.5001 - val_AUC: 0.9669 - val_accuracy: 0.9002 - val_loss: 0.5484 - learning_rate: 1.0000e-04\n",
      "Epoch 5/35\n",
      "\u001b[1m432/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - AUC: 0.9895 - accuracy: 0.9502 - loss: 0.4024 - val_AUC: 0.9638 - val_accuracy: 0.9077 - val_loss: 0.5063 - learning_rate: 1.0000e-04\n",
      "Epoch 6/35\n",
      "\u001b[1m432/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - AUC: 0.9933 - accuracy: 0.9642 - loss: 0.3299 - val_AUC: 0.9599 - val_accuracy: 0.9017 - val_loss: 0.5147 - learning_rate: 1.0000e-04\n",
      "Epoch 7/35\n",
      "\u001b[1m432/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - AUC: 0.9954 - accuracy: 0.9704 - loss: 0.2862 - val_AUC: 0.9609 - val_accuracy: 0.9055 - val_loss: 0.4847 - learning_rate: 1.0000e-04\n",
      "Epoch 8/35\n",
      "\u001b[1m432/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - AUC: 0.9962 - accuracy: 0.9762 - loss: 0.2487 - val_AUC: 0.9577 - val_accuracy: 0.8901 - val_loss: 0.5381 - learning_rate: 1.0000e-04\n",
      "Epoch 9/35\n",
      "\u001b[1m432/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - AUC: 0.9975 - accuracy: 0.9801 - loss: 0.2201 - val_AUC: 0.9549 - val_accuracy: 0.8999 - val_loss: 0.5283 - learning_rate: 1.0000e-04\n",
      "Epoch 10/35\n",
      "\u001b[1m432/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - AUC: 0.9984 - accuracy: 0.9835 - loss: 0.1991 - val_AUC: 0.9569 - val_accuracy: 0.9006 - val_loss: 0.5346 - learning_rate: 1.0000e-04\n",
      "Epoch 11/35\n",
      "\u001b[1m432/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - AUC: 0.9990 - accuracy: 0.9867 - loss: 0.1789 - val_AUC: 0.9578 - val_accuracy: 0.9021 - val_loss: 0.5049 - learning_rate: 1.0000e-04\n",
      "Epoch 12/35\n",
      "\u001b[1m432/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - AUC: 0.9991 - accuracy: 0.9922 - loss: 0.1602 - val_AUC: 0.9524 - val_accuracy: 0.8987 - val_loss: 0.5398 - learning_rate: 1.0000e-04\n",
      "Epoch 13/35\n",
      "\u001b[1m432/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - AUC: 0.9997 - accuracy: 0.9940 - loss: 0.1516 - val_AUC: 0.9509 - val_accuracy: 0.9036 - val_loss: 0.5665 - learning_rate: 5.0000e-05\n",
      "Epoch 14/35\n",
      "\u001b[1m432/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - AUC: 0.9991 - accuracy: 0.9964 - loss: 0.1426 - val_AUC: 0.9423 - val_accuracy: 0.8928 - val_loss: 0.6821 - learning_rate: 5.0000e-05\n",
      "Epoch 15/35\n",
      "\u001b[1m432/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - AUC: 0.9998 - accuracy: 0.9983 - loss: 0.1324 - val_AUC: 0.9351 - val_accuracy: 0.8886 - val_loss: 0.7766 - learning_rate: 5.0000e-05\n",
      "Epoch 16/35\n",
      "\u001b[1m432/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - AUC: 0.9996 - accuracy: 0.9953 - loss: 0.1336 - val_AUC: 0.9499 - val_accuracy: 0.8924 - val_loss: 0.6129 - learning_rate: 5.0000e-05\n",
      "Epoch 17/35\n",
      "\u001b[1m432/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - AUC: 0.9995 - accuracy: 0.9975 - loss: 0.1279 - val_AUC: 0.9372 - val_accuracy: 0.8898 - val_loss: 0.6925 - learning_rate: 5.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-01 21:41:14.197115: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.2706405818462372, Train accuracy: 0.9720694422721863\n",
      "Validation loss: 0.484682559967041, Validation accuracy: 0.9054558873176575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-01 21:41:37.301032: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n",
      "Test ROC AUC: 0.8756\n",
      "Test Accuracy: 0.7868\n",
      "Test MAE: 0.1893\n",
      "Test Percision: 0.4304\n",
      "Test Specificity: 0.7887\n",
      "Test Sensitivity(Recall): 0.7771\n",
      "Test F1: 0.5540 \n",
      "\n",
      "Fold 2 - AUC: 0.8756, Accuracy: 0.7868, Recall: 0.7771, Precision: 0.4304, Specificity: 0.7887, F1: 0.5540\n",
      "\n",
      "[[672 180]\n",
      " [ 39 136]]\n",
      "Processing fold 3...\n",
      "349, 70, 47, participants in Train, Validation, and Test sets\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-01 21:44:34.917197: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m430/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - AUC: 0.7647 - accuracy: 0.6840 - loss: 2.4463"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-01 21:44:53.405978: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - AUC: 0.7652 - accuracy: 0.6846 - loss: 2.4428"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 58ms/step - AUC: 0.7654 - accuracy: 0.6847 - loss: 2.4416 - val_AUC: 0.8142 - val_accuracy: 0.6504 - val_loss: 1.4529 - learning_rate: 1.0000e-04\n",
      "Epoch 2/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - AUC: 0.9389 - accuracy: 0.8807 - loss: 1.0531 - val_AUC: 0.9628 - val_accuracy: 0.9027 - val_loss: 0.7899 - learning_rate: 1.0000e-04\n",
      "Epoch 3/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - AUC: 0.9771 - accuracy: 0.9256 - loss: 0.6927 - val_AUC: 0.9703 - val_accuracy: 0.9016 - val_loss: 0.6172 - learning_rate: 1.0000e-04\n",
      "Epoch 4/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - AUC: 0.9856 - accuracy: 0.9435 - loss: 0.5251 - val_AUC: 0.9698 - val_accuracy: 0.9054 - val_loss: 0.5458 - learning_rate: 1.0000e-04\n",
      "Epoch 5/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - AUC: 0.9920 - accuracy: 0.9586 - loss: 0.4110 - val_AUC: 0.9633 - val_accuracy: 0.8872 - val_loss: 0.6305 - learning_rate: 1.0000e-04\n",
      "Epoch 6/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - AUC: 0.9934 - accuracy: 0.9664 - loss: 0.3463 - val_AUC: 0.9721 - val_accuracy: 0.9105 - val_loss: 0.4662 - learning_rate: 1.0000e-04\n",
      "Epoch 7/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - AUC: 0.9961 - accuracy: 0.9751 - loss: 0.2875 - val_AUC: 0.9597 - val_accuracy: 0.8938 - val_loss: 0.4920 - learning_rate: 1.0000e-04\n",
      "Epoch 8/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - AUC: 0.9970 - accuracy: 0.9791 - loss: 0.2555 - val_AUC: 0.9610 - val_accuracy: 0.9004 - val_loss: 0.5379 - learning_rate: 1.0000e-04\n",
      "Epoch 9/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - AUC: 0.9976 - accuracy: 0.9801 - loss: 0.2334 - val_AUC: 0.9608 - val_accuracy: 0.8981 - val_loss: 0.5422 - learning_rate: 1.0000e-04\n",
      "Epoch 10/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - AUC: 0.9978 - accuracy: 0.9850 - loss: 0.2098 - val_AUC: 0.9554 - val_accuracy: 0.8973 - val_loss: 0.5307 - learning_rate: 1.0000e-04\n",
      "Epoch 11/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - AUC: 0.9983 - accuracy: 0.9896 - loss: 0.1954 - val_AUC: 0.9531 - val_accuracy: 0.8884 - val_loss: 0.6198 - learning_rate: 1.0000e-04\n",
      "Epoch 12/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - AUC: 0.9992 - accuracy: 0.9920 - loss: 0.1720 - val_AUC: 0.9503 - val_accuracy: 0.9031 - val_loss: 0.6306 - learning_rate: 5.0000e-05\n",
      "Epoch 13/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - AUC: 0.9994 - accuracy: 0.9963 - loss: 0.1545 - val_AUC: 0.9480 - val_accuracy: 0.8973 - val_loss: 0.6609 - learning_rate: 5.0000e-05\n",
      "Epoch 14/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - AUC: 0.9995 - accuracy: 0.9969 - loss: 0.1482 - val_AUC: 0.9463 - val_accuracy: 0.8988 - val_loss: 0.6825 - learning_rate: 5.0000e-05\n",
      "Epoch 15/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - AUC: 0.9996 - accuracy: 0.9974 - loss: 0.1412 - val_AUC: 0.9394 - val_accuracy: 0.8961 - val_loss: 0.7397 - learning_rate: 5.0000e-05\n",
      "Epoch 16/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - AUC: 0.9990 - accuracy: 0.9952 - loss: 0.1473 - val_AUC: 0.9359 - val_accuracy: 0.8880 - val_loss: 0.8055 - learning_rate: 5.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-01 21:48:27.809048: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.2844220697879791, Train accuracy: 0.9785621762275696\n",
      "Validation loss: 0.46621665358543396, Validation accuracy: 0.9104651212692261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m246/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-01 21:48:47.735971: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step\n",
      "\u001b[1m27/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-01 21:48:50.182189: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Test ROC AUC: 0.8738\n",
      "Test Accuracy: 0.8428\n",
      "Test MAE: 0.1503\n",
      "Test Percision: 0.4867\n",
      "Test Specificity: 0.8682\n",
      "Test Sensitivity(Recall): 0.7006\n",
      "Test F1: 0.5744 \n",
      "\n",
      "Fold 3 - AUC: 0.8738, Accuracy: 0.8428, Recall: 0.7006, Precision: 0.4867, Specificity: 0.8682, F1: 0.5744\n",
      "\n",
      "[[764 116]\n",
      " [ 47 110]]\n",
      "Processing fold 4...\n",
      "349, 70, 47, participants in Train, Validation, and Test sets\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m430/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - AUC: 0.7483 - accuracy: 0.6611 - loss: 2.4296"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-01 21:53:08.417216: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - AUC: 0.7488 - accuracy: 0.6617 - loss: 2.4263"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-01 21:53:15.810683: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 58ms/step - AUC: 0.7490 - accuracy: 0.6619 - loss: 2.4252 - val_AUC: 0.7502 - val_accuracy: 0.6625 - val_loss: 1.4446 - learning_rate: 1.0000e-04\n",
      "Epoch 2/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - AUC: 0.9395 - accuracy: 0.8853 - loss: 1.0367 - val_AUC: 0.9391 - val_accuracy: 0.8718 - val_loss: 0.7799 - learning_rate: 1.0000e-04\n",
      "Epoch 3/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - AUC: 0.9763 - accuracy: 0.9271 - loss: 0.6091 - val_AUC: 0.9476 - val_accuracy: 0.8776 - val_loss: 0.6090 - learning_rate: 1.0000e-04\n",
      "Epoch 4/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - AUC: 0.9851 - accuracy: 0.9433 - loss: 0.4469 - val_AUC: 0.9565 - val_accuracy: 0.8868 - val_loss: 0.5145 - learning_rate: 1.0000e-04\n",
      "Epoch 5/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - AUC: 0.9912 - accuracy: 0.9580 - loss: 0.3476 - val_AUC: 0.9457 - val_accuracy: 0.8871 - val_loss: 0.5377 - learning_rate: 1.0000e-04\n",
      "Epoch 6/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - AUC: 0.9939 - accuracy: 0.9668 - loss: 0.2936 - val_AUC: 0.9526 - val_accuracy: 0.8700 - val_loss: 0.5721 - learning_rate: 1.0000e-04\n",
      "Epoch 7/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - AUC: 0.9949 - accuracy: 0.9706 - loss: 0.2711 - val_AUC: 0.9508 - val_accuracy: 0.8627 - val_loss: 0.5904 - learning_rate: 1.0000e-04\n",
      "Epoch 8/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - AUC: 0.9974 - accuracy: 0.9793 - loss: 0.2258 - val_AUC: 0.9416 - val_accuracy: 0.8660 - val_loss: 0.6320 - learning_rate: 1.0000e-04\n",
      "Epoch 9/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - AUC: 0.9978 - accuracy: 0.9846 - loss: 0.2058 - val_AUC: 0.9346 - val_accuracy: 0.8645 - val_loss: 0.6789 - learning_rate: 1.0000e-04\n",
      "Epoch 10/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - AUC: 0.9992 - accuracy: 0.9900 - loss: 0.1790 - val_AUC: 0.9229 - val_accuracy: 0.8554 - val_loss: 0.7964 - learning_rate: 5.0000e-05\n",
      "Epoch 11/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - AUC: 0.9997 - accuracy: 0.9932 - loss: 0.1630 - val_AUC: 0.9235 - val_accuracy: 0.8627 - val_loss: 0.7951 - learning_rate: 5.0000e-05\n",
      "Epoch 12/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - AUC: 0.9995 - accuracy: 0.9972 - loss: 0.1548 - val_AUC: 0.9270 - val_accuracy: 0.8700 - val_loss: 0.7788 - learning_rate: 5.0000e-05\n",
      "Epoch 13/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - AUC: 0.9994 - accuracy: 0.9931 - loss: 0.1573 - val_AUC: 0.9185 - val_accuracy: 0.8627 - val_loss: 0.8699 - learning_rate: 5.0000e-05\n",
      "Epoch 14/35\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - AUC: 0.9995 - accuracy: 0.9947 - loss: 0.1510 - val_AUC: 0.9071 - val_accuracy: 0.8532 - val_loss: 1.0253 - learning_rate: 5.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-01 21:56:14.211553: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.3522334098815918, Train accuracy: 0.9610934257507324\n",
      "Validation loss: 0.5144957304000854, Validation accuracy: 0.8867786526679993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m247/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-01 21:56:39.471371: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 0.8487\n",
      "Test Accuracy: 0.7888\n",
      "Test MAE: 0.1823\n",
      "Test Percision: 0.4144\n",
      "Test Specificity: 0.8082\n",
      "Test Sensitivity(Recall): 0.6899\n",
      "Test F1: 0.5178 \n",
      "\n",
      "Fold 4 - AUC: 0.8487, Accuracy: 0.7888, Recall: 0.6899, Precision: 0.4144, Specificity: 0.8082, F1: 0.5178\n",
      "\n",
      "[[649 154]\n",
      " [ 49 109]]\n",
      "\n",
      "Average Train Accuracy: 0.9693 (+- 0.0066)\n",
      "Average Validation Accuracy: 0.9016 (+- 0.0089)\n",
      "Average Test Accuracy: 0.8088 (+- 0.0230)\n",
      "Average Test Recall: 0.7348 (+- 0.0397)\n",
      "Average Test Precision: 0.4363 (+- 0.0298)\n",
      "Average Test Specificity: 0.8223 (+- 0.0293)\n",
      "Average Test AUC: 0.8710 (+- 0.0137)\n",
      "Average Test F1: 0.5462 (+- 0.0207)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated Models on holdout set ... \n",
      "\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-01 21:56:43.047674: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step\n",
      "Holdout ROC AUC: 0.9877\n",
      "Holdout Accuracy: 0.9488\n",
      "Holdout MAE: 0.1823\n",
      "Holdout Percision: 0.7672\n",
      "Holdout Specificity: 0.9453\n",
      "Holdout Sensitivity(Recall): 0.9674\n",
      "Holdout F1: 0.8558 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best 3 models (ROC AUC) to prdict holdout:\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Holdout ROC AUC: 0.9862\n",
      "Holdout Accuracy: 0.9471\n",
      "Holdout MAE: 0.1823\n",
      "Holdout Percision: 0.7607\n",
      "Holdout Specificity: 0.9433\n",
      "Holdout Sensitivity(Recall): 0.9674\n",
      "Holdout F1: 0.8517 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[466,  28],\n",
       "       [  3,  89]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################# ORIGINAL 70 K_Fold 3-channel input w/ Masking, Daily & Individual input, Classifying Hypo Night\n",
    "########################################################################################################################################\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "folder_name = \"/home/ma98/Compressed_DEXI_Data/Hypo_70_Original/Hypo_Night\"\n",
    "matrix_shape0 = 288\n",
    "# Reshape matrices to the required shapes\n",
    "X_features_daily_imputed = np.nan_to_num(X_features_daily_scaled, nan=0.0)\n",
    "X_features_individual_imputed = np.nan_to_num(X_features_individual_scaled, nan=0.0)\n",
    "\n",
    "# Create masks for missing values\n",
    "mask_daily = np.isfinite(X_features_daily_scaled).astype(np.float32)\n",
    "mask_individual = np.isfinite(X_features_individual_scaled).astype(np.float32)\n",
    "\n",
    "# Initialize GroupKFold\n",
    "num_splits = 4\n",
    "group_kfold = GroupKFold(n_splits=num_splits)\n",
    "unique_participants = np.unique(participant_ids)\n",
    "# # Shuffle to ensure no artifacts in test train/validation split\n",
    "# unique_participants = shuffle(unique_participants, random_state=42)\n",
    "\n",
    "# Completely hold out a test set before cross-validation\n",
    "holdout_participants = unique_participants[int(0.95 * len(unique_participants)):]\n",
    "holdout_idx = np.where(np.isin(participant_ids, holdout_participants))[0]\n",
    "\n",
    "# Remove the holdout participants from the pool used for cross-validation model\n",
    "model_participants = unique_participants[:int(0.95 * len(unique_participants))]\n",
    "\n",
    "final_results_night = {\n",
    "    \"fold_model\": [],\n",
    "    \"specificity_scores\": [],\n",
    "    \"accuracy_scores\": [],\n",
    "    \"precision_scores\": [],\n",
    "    \"recall_scores\": [],\n",
    "    \"f1_scores\": [],\n",
    "    \"roc_auc_scores\": [],\n",
    "    \"mae\": [],\n",
    "    \"mse\": [],\n",
    "    \"fold_train_loss\": [],\n",
    "    \"fold_train_acc\": [],\n",
    "    \"fold_val_loss\": [],\n",
    "    \"fold_val_acc\": [],\n",
    "    \"conf_matrix\": [],\n",
    "    \"class_report\": [],\n",
    "    \"train_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_acc\": []\n",
    "}\n",
    "for fold, (train_idx, val_test_idx) in enumerate(group_kfold.split(X_matrices_power_scaled, y_hypo_night, groups=participant_ids)):\n",
    "    # 75% of the data as train set\n",
    "    train_participants = model_participants[np.isin(model_participants, participant_ids[train_idx])]    \n",
    "    val_test_participants = model_participants[np.isin(model_participants, participant_ids[val_test_idx])]\n",
    "    \n",
    "    val_size = int(len(val_test_participants) * 3 / 5)\n",
    "    val_participants = val_test_participants[:val_size]\n",
    "    test_participants = val_test_participants[val_size:]\n",
    "    \n",
    "    # Get corresponding indices\n",
    "    val_idx = np.where(np.isin(participant_ids, val_participants))[0]\n",
    "    test_idx = np.where(np.isin(participant_ids, test_participants))[0]\n",
    "    print(f\"Processing fold {fold + 1}...\")\n",
    "    print(f\"{len(train_participants)}, {len(val_participants)}, {len(test_participants)}, participants in Train, Validation, and Test sets\" )\n",
    "\n",
    "    # Train-test split based on indices\n",
    "    X_matrices_coeffs_train,X_matrices_coeffs_val, X_matrices_coeffs_test = X_matrices_power_scaled[train_idx],X_matrices_power_scaled[val_idx], X_matrices_power_scaled[test_idx]\n",
    "    X_features_daily_train,X_features_daily_val, X_features_daily_test = X_features_daily_imputed[train_idx],X_features_daily_imputed[val_idx], X_features_daily_imputed[test_idx]\n",
    "    X_features_individual_train,X_features_individual_val, X_features_individual_test = X_features_individual_imputed[train_idx],X_features_individual_imputed[val_idx], X_features_individual_imputed[test_idx]\n",
    "    y_label_train,y_label_val, y_label_test = y_hypo_night[train_idx],y_hypo_night[val_idx], y_hypo_night[test_idx]\n",
    "    mask_daily_train,mask_daily_val, mask_daily_test = mask_daily[train_idx], mask_daily[val_idx], mask_daily[test_idx]\n",
    "    mask_individual_train,mask_individual_val, mask_individual_test = mask_individual[train_idx],mask_individual[val_idx], mask_individual[test_idx]\n",
    "\n",
    "    # Resample training data\n",
    "    X_matrices_coeffs_train_resampled, X_features_daily_train_resampled, \\\n",
    "    X_features_individual_train_resampled, mask_daily_train_resampled, \\\n",
    "    mask_individual_train_resampled, y_label_train_resampled = apply_smote_resampling_mask(\n",
    "        X_matrices_coeffs_train,\n",
    "        X_features_daily_train,\n",
    "        X_features_individual_train,\n",
    "        mask_daily_train,\n",
    "        mask_individual_train,\n",
    "        y_label_train, matrix_shape0=matrix_shape0\n",
    "    )\n",
    "    # Resample Validation data\n",
    "    X_matrices_coeffs_val_resampled, X_features_daily_val_resampled, \\\n",
    "    X_features_individual_val_resampled, mask_daily_val_resampled, \\\n",
    "    mask_individual_val_resampled, y_label_val_resampled = apply_smote_resampling_mask(\n",
    "        X_matrices_coeffs_val,\n",
    "        X_features_daily_val,\n",
    "        X_features_individual_val,\n",
    "        mask_daily_val,\n",
    "        mask_individual_val,\n",
    "        y_label_val, matrix_shape0=matrix_shape0\n",
    "    )\n",
    "    num_epochs = 35\n",
    "    # Create a new model instance\n",
    "    model = create_model()\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    # checkpoint = ModelCheckpoint(filepath=os.path.join(folder_name, 'best_model_fold_{}.keras'.format(fold)), monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "    learning_rate_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7)\n",
    "    # Model training and evaluation\n",
    "    history_hypo_night = model.fit([X_matrices_coeffs_train_resampled, X_features_daily_train_resampled, X_features_individual_train_resampled, mask_daily_train_resampled, mask_individual_train_resampled], \n",
    "                                         y_label_train_resampled, \n",
    "                                         epochs=num_epochs, batch_size=32, verbose=1,\n",
    "                                         validation_data=([X_matrices_coeffs_val_resampled, X_features_daily_val_resampled, X_features_individual_val_resampled, mask_daily_val_resampled, mask_individual_val_resampled], y_label_val_resampled),\n",
    "                                         callbacks=[early_stopping, learning_rate_scheduler])\n",
    "    # Evaluate training and testing performance\n",
    "    train_score = model.evaluate([X_matrices_coeffs_train_resampled, X_features_daily_train_resampled, X_features_individual_train_resampled, mask_daily_train_resampled, mask_individual_train_resampled], \n",
    "                                 y_label_train_resampled, verbose=0)\n",
    "    val_score = model.evaluate([X_matrices_coeffs_val_resampled, X_features_daily_val_resampled, X_features_individual_val_resampled, mask_daily_val_resampled, mask_individual_val_resampled], \n",
    "                                y_label_val_resampled, verbose=0)\n",
    "    print('\\nTrain loss: {}, Train accuracy: {}'.format(train_score[0], train_score[1]))\n",
    "    print('Validation loss: {}, Validation accuracy: {}'.format(val_score[0], val_score[1]))\n",
    "    # print('Test loss: {}, Test accuracy: {}\\n'.format(test_score[0], test_score[1]))\n",
    "    y_pred_train = model.predict([X_matrices_coeffs_train, X_features_daily_train,X_features_individual_train, mask_daily_train, mask_individual_train])\n",
    "    y_pred_test = model.predict([X_matrices_coeffs_test, X_features_daily_test,X_features_individual_test, mask_daily_test, mask_individual_test])\n",
    "\n",
    "    mae_train = mean_absolute_error(y_label_train, y_pred_train)\n",
    "    mse_train = mean_squared_error(y_label_train, y_pred_train)\n",
    "\n",
    "    roc_auc_test = roc_auc_score(y_label_test, y_pred_test)\n",
    "    print(f'Test ROC AUC: {roc_auc_test:.4f}')\n",
    "\n",
    "    y_pred_train_binary = (y_pred_train >= 0.5).astype(int)\n",
    "    y_pred_test_binary = (y_pred_test >= 0.2).astype(int)\n",
    "    mae_test = mean_absolute_error(y_label_test, y_pred_test)\n",
    "    mse_test = mean_squared_error(y_label_test, y_pred_test)\n",
    "    accuracy = accuracy_score(y_label_test, y_pred_test_binary)\n",
    "    recall = recall_score(y_label_test, y_pred_test_binary)\n",
    "    f1 = f1_score(y_label_test, y_pred_test_binary)\n",
    "    precision = precision_score(y_label_test, y_pred_test_binary)\n",
    "    specificity = recall_score(y_label_test, y_pred_test_binary, pos_label=0)\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    print(f'Test MAE: {mae_test:.4f}')\n",
    "    print(f'Test Percision: {precision:.4f}')\n",
    "    print(f'Test Specificity: {specificity:.4f}')\n",
    "    print(f'Test Sensitivity(Recall): {recall:.4f}')\n",
    "    print(f'Test F1: {f1:.4f} \\n')\n",
    "    print(f'Fold {fold + 1} - AUC: {roc_auc_test:.4f}, Accuracy: {accuracy:.4f}, Recall: {recall:.4f}, Precision: {precision:.4f}, Specificity: {specificity:.4f}, F1: {f1:.4f}\\n')\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_label_test, y_pred_test_binary)\n",
    "    # Classification Report\n",
    "    class_report = classification_report(y_label_test, y_pred_test_binary)\n",
    "    print(conf_matrix)\n",
    "    final_results_night[\"precision_scores\"].append(precision)\n",
    "    final_results_night[\"recall_scores\"].append(recall)\n",
    "    final_results_night[\"f1_scores\"].append(f1)\n",
    "    final_results_night[\"accuracy_scores\"].append(accuracy)\n",
    "    final_results_night[\"roc_auc_scores\"].append(roc_auc_test)\n",
    "    final_results_night[\"specificity_scores\"].append(specificity)\n",
    "    final_results_night[\"mae\"].append(mae_test)\n",
    "    final_results_night[\"mse\"].append(mse_test)\n",
    "    final_results_night[\"train_loss\"].append(train_score[0])\n",
    "    final_results_night[\"train_acc\"].append(train_score[1])\n",
    "    final_results_night[\"val_loss\"].append(val_score[0])\n",
    "    final_results_night[\"val_acc\"].append(val_score[1])\n",
    "    final_results_night[\"fold_train_acc\"].append(history_hypo_night.history['accuracy'])\n",
    "    final_results_night[\"fold_train_loss\"].append(history_hypo_night.history['loss'])\n",
    "    final_results_night[\"fold_val_acc\"].append(history_hypo_night.history['val_accuracy'])\n",
    "    final_results_night[\"fold_val_loss\"].append(history_hypo_night.history['val_loss'])\n",
    "    final_results_night[\"conf_matrix\"].append(conf_matrix)\n",
    "    final_results_night[\"class_report\"].append(class_report)\n",
    "    final_results_night[\"fold_model\"].append(model)\n",
    "          \n",
    "# Calculate and print average and std across folds\n",
    "print(f'\\nAverage Train Accuracy: {np.mean(final_results_night[\"train_acc\"]):.4f} (+- {np.std(final_results_night[\"train_acc\"]):.4f})')\n",
    "print(f'Average Validation Accuracy: {np.mean(final_results_night[\"val_acc\"]):.4f} (+- {np.std(final_results_night[\"val_acc\"]):.4f})')\n",
    "print(f'Average Test Accuracy: {np.mean(final_results_night[\"accuracy_scores\"]):.4f} (+- {np.std(final_results_night[\"accuracy_scores\"]):.4f})')\n",
    "print(f'Average Test Recall: {np.mean(final_results_night[\"recall_scores\"]):.4f} (+- {np.std(final_results_night[\"recall_scores\"]):.4f})')\n",
    "print(f'Average Test Precision: {np.mean(final_results_night[\"precision_scores\"]):.4f} (+- {np.std(final_results_night[\"precision_scores\"]):.4f})')\n",
    "print(f'Average Test Specificity: {np.mean(final_results_night[\"specificity_scores\"]):.4f} (+- {np.std(final_results_night[\"specificity_scores\"]):.4f})')\n",
    "print(f'Average Test AUC: {np.mean(final_results_night[\"roc_auc_scores\"]):.4f} (+- {np.std(final_results_night[\"roc_auc_scores\"]):.4f})')\n",
    "print(f'Average Test F1: {np.mean(final_results_night[\"f1_scores\"]):.4f} (+- {np.std(final_results_night[\"f1_scores\"]):.4f})')\n",
    "\n",
    "max_epochs = max(len(fold) for fold in final_results_night[\"fold_val_loss\"])\n",
    "# Initialize arrays to store average and std dev for each epoch\n",
    "avg_loss = np.zeros(max_epochs)\n",
    "std_loss = np.zeros(max_epochs)\n",
    "avg_acc = np.zeros(max_epochs)\n",
    "std_acc = np.zeros(max_epochs)\n",
    "# Compute average and standard deviation for each epoch\n",
    "for epoch in range(max_epochs):\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    for fold_loss, fold_acc in zip(final_results_night[\"fold_val_loss\"], final_results_night[\"fold_val_acc\"]):\n",
    "        if epoch < len(fold_loss):\n",
    "            losses.append(fold_loss[epoch])\n",
    "        if epoch < len(fold_acc):\n",
    "            accuracies.append(fold_acc[epoch])\n",
    "    \n",
    "    if losses:\n",
    "        avg_loss[epoch] = np.mean(losses)\n",
    "        std_loss[epoch] = np.std(losses)\n",
    "    if accuracies:\n",
    "        avg_acc[epoch] = np.mean(accuracies)\n",
    "        std_acc[epoch] = np.std(accuracies)\n",
    "# Plot average loss and accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, max_epochs + 1), avg_loss, color='blue', label='Validation Loss')\n",
    "plt.fill_between(range(1, max_epochs + 1), \n",
    "                 avg_loss - std_loss,\n",
    "                 avg_loss + std_loss,\n",
    "                 color='blue', alpha=0.2)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Validation Loss per Epoch')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, max_epochs + 1), avg_acc, color='blue', label='Validation Accuracy')\n",
    "plt.fill_between(range(1, max_epochs + 1), \n",
    "                 avg_acc - std_acc,\n",
    "                 avg_acc + std_acc,\n",
    "                 color='blue', alpha=0.2)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Validation Accuracy per Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(folder_name, 'loss_accuracy_plot.png'))\n",
    "plt.show()\n",
    "\n",
    "########################################################################################################################################\n",
    "print(f\"Aggregated Models on holdout set ... \\n\")\n",
    "\n",
    "# Train-test split based on indices\n",
    "X_matrices_coeffs_holdout = X_matrices_power_scaled[holdout_idx]\n",
    "X_features_daily_holdout = X_features_daily_imputed[holdout_idx]\n",
    "X_features_individual_holdout = X_features_individual_imputed[holdout_idx]\n",
    "y_label_holdout = y_hypo_night[holdout_idx]\n",
    "mask_daily_holdout = mask_daily[holdout_idx]\n",
    "mask_individual_holdout = mask_individual[holdout_idx]\n",
    "\n",
    "# Initialize arrays to store predictions from each fold\n",
    "y_pred_holdout_agg = np.zeros((len(holdout_idx),))  # Assuming binary classification\n",
    "# Aggregate predictions from each fold model\n",
    "for model in final_results_night[\"fold_model\"]:\n",
    "    y_pred_holdout_fold = model.predict([X_matrices_coeffs_holdout, X_features_daily_holdout, X_features_individual_holdout, mask_daily_holdout, mask_individual_holdout])\n",
    "    y_pred_holdout_agg += y_pred_holdout_fold.flatten()  # Accumulate predictions\n",
    "    y_pred_holdout_avg = np.mean(y_pred_holdout_fold, axis=0)\n",
    "# Average the predictions from all folds\n",
    "y_pred_holdout_agg /= num_splits\n",
    "\n",
    "mae_holdout = mean_absolute_error(y_label_holdout, y_pred_holdout_agg)\n",
    "mse_holdout = mean_squared_error(y_label_holdout, y_pred_holdout_agg)\n",
    "roc_auc = roc_auc_score(y_label_holdout, y_pred_holdout_agg)\n",
    "print(f'Holdout ROC AUC: {roc_auc:.4f}')\n",
    "\n",
    "y_pred_holdout_binary_agg = (y_pred_holdout_agg >= 0.4).astype(int)\n",
    "accuracy = accuracy_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "recall = recall_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "precision = precision_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "f1 = f1_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "specificity = recall_score(y_label_holdout, y_pred_holdout_binary_agg, pos_label=0)\n",
    "\n",
    "print(f'Holdout Accuracy: {accuracy:.4f}')\n",
    "print(f'Holdout MAE: {mae_test:.4f}')\n",
    "print(f'Holdout Percision: {precision:.4f}')\n",
    "print(f'Holdout Specificity: {specificity:.4f}')\n",
    "print(f'Holdout Sensitivity(Recall): {recall:.4f}')\n",
    "print(f'Holdout F1: {f1:.4f} \\n')\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(conf_matrix, cmap='Blues', interpolation='nearest')\n",
    "plt.title('Confusion Matrix for Final Model')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        plt.text(j, i, conf_matrix[i, j], \n",
    "                 ha='center', va='center', color='black', fontsize=14)\n",
    "plt.savefig(os.path.join(folder_name, 'conf_matrix_plot.png'))\n",
    "plt.show()\n",
    "\n",
    "description_path = os.path.join(folder_name, 'Description.txt')\n",
    "with open(description_path, 'w') as f:\n",
    "    f.write(\"\"\"\n",
    "    # K_Fold 3-channel _ORIGINAL _Below70 Hypo, input w/ Masking, Daily & Individual input, Classifying Hypo Night\n",
    "    \"\"\")\n",
    "        # Write the results\n",
    "    f.write(f'\\nAverage Train Accuracy: {np.mean(final_results_night[\"train_acc\"]):.4f} (+- {np.std(final_results_night[\"train_acc\"]):.4f})\\n')\n",
    "    f.write(f'Average Validation Accuracy: {np.mean(final_results_night[\"val_acc\"]):.4f} (+- {np.std(final_results_night[\"val_acc\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Accuracy: {np.mean(final_results_night[\"accuracy_scores\"]):.4f} (+- {np.std(final_results_night[\"accuracy_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Recall: {np.mean(final_results_night[\"recall_scores\"]):.4f} (+- {np.std(final_results_night[\"recall_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Precision: {np.mean(final_results_night[\"precision_scores\"]):.4f} (+- {np.std(final_results_night[\"precision_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Specificity: {np.mean(final_results_night[\"specificity_scores\"]):.4f} (+- {np.std(final_results_night[\"specificity_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test AUC: {np.mean(final_results_night[\"roc_auc_scores\"]):.4f} (+- {np.std(final_results_night[\"roc_auc_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test F1: {np.mean(final_results_night[\"f1_scores\"]):.4f} (+- {np.std(final_results_night[\"f1_scores\"]):.4f})\\n')\n",
    "    \n",
    "    # Writing holdout results\n",
    "    f.write(f'Holdout ROC AUC: {roc_auc:.4f}\\n')\n",
    "    f.write(f'Holdout Accuracy: {accuracy:.4f}\\n')\n",
    "    f.write(f'Holdout MAE: {mae_test:.4f}\\n')\n",
    "    f.write(f'Holdout Precision: {precision:.4f}\\n')\n",
    "    f.write(f'Holdout Specificity: {specificity:.4f}\\n')\n",
    "    f.write(f'Holdout Sensitivity (Recall): {recall:.4f}\\n')\n",
    "    f.write(f'Holdout F1: {f1:.4f}\\n')\n",
    "model_summary_path = os.path.join(folder_name, 'model_summary.txt')\n",
    "with open(model_summary_path, 'w') as f:\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "#model.summary()\n",
    "# Save the final results as pickle\n",
    "final_results_path = os.path.join(folder_name, 'final_results.pkl')\n",
    "with open(final_results_path, 'wb') as file:\n",
    "    pickle.dump(final_results_night, file)\n",
    "\n",
    "print(\"\\nBest 3 models (ROC AUC) to prdict holdout:\")\n",
    "best_of = 3\n",
    "top_3_model_indices = np.argsort(final_results_night[\"roc_auc_scores\"])[-best_of:][::-1]\n",
    "y_pred_holdout_agg = np.zeros((len(holdout_idx),))  # Assuming binary classification\n",
    "for idx in top_3_model_indices:\n",
    "    model = final_results_night[\"fold_model\"][idx]\n",
    "    y_pred_holdout_fold = model.predict([X_matrices_coeffs_holdout, X_features_daily_holdout, X_features_individual_holdout, mask_daily_holdout, mask_individual_holdout])\n",
    "    y_pred_holdout_agg += y_pred_holdout_fold.flatten()\n",
    "y_pred_holdout_agg /= best_of\n",
    "\n",
    "mae_holdout = mean_absolute_error(y_label_holdout, y_pred_holdout_agg)\n",
    "mse_holdout = mean_squared_error(y_label_holdout, y_pred_holdout_agg)\n",
    "roc_auc = roc_auc_score(y_label_holdout, y_pred_holdout_agg)\n",
    "print(f'Holdout ROC AUC: {roc_auc:.4f}')\n",
    "\n",
    "y_pred_holdout_binary_agg = (y_pred_holdout_agg >= 0.4).astype(int)\n",
    "accuracy = accuracy_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "recall = recall_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "precision = precision_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "f1 = f1_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "specificity = recall_score(y_label_holdout, y_pred_holdout_binary_agg, pos_label=0)\n",
    "\n",
    "print(f'Holdout Accuracy: {accuracy:.4f}')\n",
    "print(f'Holdout MAE: {mae_test:.4f}')\n",
    "print(f'Holdout Percision: {precision:.4f}')\n",
    "print(f'Holdout Specificity: {specificity:.4f}')\n",
    "print(f'Holdout Sensitivity(Recall): {recall:.4f}')\n",
    "print(f'Holdout F1: {f1:.4f} \\n')\n",
    "conf_matrix = confusion_matrix(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "conf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0cd239d-90c1-4d44-8e1b-cfa3b2a53e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 1...\n",
      "351, 69, 46, participants in Train, Validation, and Test sets\n",
      "Class weights:  {0: 0.5849001603264831, 1: 3.4446351931330472}\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-02 00:54:12.107877: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m501/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - AUC: 0.5833 - accuracy: 0.7015 - loss: 2.3997"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-02 00:54:29.801605: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - AUC: 0.5834 - accuracy: 0.7014 - loss: 2.3987"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 51ms/step - AUC: 0.5836 - accuracy: 0.7013 - loss: 2.3978 - val_AUC: 0.7698 - val_accuracy: 0.6365 - val_loss: 1.1716 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - AUC: 0.7946 - accuracy: 0.7314 - loss: 1.1317 - val_AUC: 0.8300 - val_accuracy: 0.7609 - val_loss: 0.7949 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - AUC: 0.8369 - accuracy: 0.7341 - loss: 0.8368 - val_AUC: 0.8386 - val_accuracy: 0.7548 - val_loss: 0.7524 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - AUC: 0.8774 - accuracy: 0.7743 - loss: 0.6879 - val_AUC: 0.8612 - val_accuracy: 0.8043 - val_loss: 0.6356 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - AUC: 0.9073 - accuracy: 0.8178 - loss: 0.5950 - val_AUC: 0.8467 - val_accuracy: 0.7561 - val_loss: 0.6803 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - AUC: 0.9168 - accuracy: 0.8184 - loss: 0.5530 - val_AUC: 0.8693 - val_accuracy: 0.7670 - val_loss: 0.6521 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - AUC: 0.9420 - accuracy: 0.8576 - loss: 0.4801 - val_AUC: 0.8569 - val_accuracy: 0.8261 - val_loss: 0.5653 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - AUC: 0.9549 - accuracy: 0.8822 - loss: 0.4273 - val_AUC: 0.8643 - val_accuracy: 0.8546 - val_loss: 0.5329 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - AUC: 0.9615 - accuracy: 0.8957 - loss: 0.4108 - val_AUC: 0.8670 - val_accuracy: 0.8295 - val_loss: 0.5788 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - AUC: 0.9570 - accuracy: 0.8973 - loss: 0.3939 - val_AUC: 0.8726 - val_accuracy: 0.8444 - val_loss: 0.5610 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - AUC: 0.9715 - accuracy: 0.9167 - loss: 0.3405 - val_AUC: 0.8701 - val_accuracy: 0.8594 - val_loss: 0.5470 - learning_rate: 1.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - AUC: 0.9719 - accuracy: 0.9157 - loss: 0.3339 - val_AUC: 0.8655 - val_accuracy: 0.8730 - val_loss: 0.5343 - learning_rate: 1.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - AUC: 0.9806 - accuracy: 0.9366 - loss: 0.2978 - val_AUC: 0.8652 - val_accuracy: 0.8750 - val_loss: 0.5651 - learning_rate: 5.0000e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - AUC: 0.9856 - accuracy: 0.9473 - loss: 0.2623 - val_AUC: 0.8587 - val_accuracy: 0.8662 - val_loss: 0.5861 - learning_rate: 5.0000e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - AUC: 0.9861 - accuracy: 0.9519 - loss: 0.2516 - val_AUC: 0.8629 - val_accuracy: 0.8641 - val_loss: 0.5979 - learning_rate: 5.0000e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - AUC: 0.9864 - accuracy: 0.9545 - loss: 0.2422 - val_AUC: 0.8466 - val_accuracy: 0.8682 - val_loss: 0.6196 - learning_rate: 5.0000e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - AUC: 0.9884 - accuracy: 0.9603 - loss: 0.2274 - val_AUC: 0.8307 - val_accuracy: 0.8838 - val_loss: 0.6349 - learning_rate: 2.5000e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - AUC: 0.9901 - accuracy: 0.9639 - loss: 0.2170 - val_AUC: 0.8238 - val_accuracy: 0.8730 - val_loss: 0.6850 - learning_rate: 2.5000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-02 00:57:22.275432: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-02 00:57:25.797766: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.4001213610172272, Train accuracy: 0.9081734418869019\n",
      "Validation loss: 0.5328898429870605, Validation accuracy: 0.854619562625885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-02 00:57:49.375613: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-02 00:57:52.690446: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step\n",
      "\u001b[1m29/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-02 00:57:55.442256: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step\n",
      "Test ROC AUC: 0.8875\n",
      "Test Accuracy: 0.8109\n",
      "Test MAE: 0.1786\n",
      "Test Percision: 0.4073\n",
      "Test Specificity: 0.8126\n",
      "Test Sensitivity(Recall): 0.8000\n",
      "Test F1: 0.5398 \n",
      "\n",
      "Fold 1 - AUC: 0.8875, Accuracy: 0.8109, Recall: 0.8000, Precision: 0.4073, Specificity: 0.8126, F1: 0.5398\n",
      "\n",
      "[[707 163]\n",
      " [ 28 112]]\n",
      "Processing fold 2...\n",
      "349, 70, 47, participants in Train, Validation, and Test sets\n",
      "Class weights:  {0: 0.580752532561505, 1: 3.595878136200717}\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-02 00:58:51.354580: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m497/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - AUC: 0.6132 - accuracy: 0.6516 - loss: 2.0835"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-02 00:59:05.212504: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - AUC: 0.6137 - accuracy: 0.6513 - loss: 2.0776"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-02 00:59:10.542056: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-02 00:59:12.372111: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 39ms/step - AUC: 0.6139 - accuracy: 0.6512 - loss: 2.0764 - val_AUC: 0.7671 - val_accuracy: 0.6841 - val_loss: 0.8342 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - AUC: 0.7862 - accuracy: 0.6909 - loss: 0.8799 - val_AUC: 0.7999 - val_accuracy: 0.6671 - val_loss: 0.7755 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - AUC: 0.8376 - accuracy: 0.7334 - loss: 0.7362 - val_AUC: 0.8355 - val_accuracy: 0.7396 - val_loss: 0.7106 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - AUC: 0.8807 - accuracy: 0.7834 - loss: 0.6454 - val_AUC: 0.8510 - val_accuracy: 0.7781 - val_loss: 0.6717 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - AUC: 0.9064 - accuracy: 0.8094 - loss: 0.5892 - val_AUC: 0.8628 - val_accuracy: 0.8081 - val_loss: 0.5909 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - AUC: 0.9200 - accuracy: 0.8382 - loss: 0.5436 - val_AUC: 0.8655 - val_accuracy: 0.7996 - val_loss: 0.6257 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - AUC: 0.9310 - accuracy: 0.8519 - loss: 0.4968 - val_AUC: 0.8729 - val_accuracy: 0.8166 - val_loss: 0.5883 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - AUC: 0.9443 - accuracy: 0.8709 - loss: 0.4494 - val_AUC: 0.8806 - val_accuracy: 0.8068 - val_loss: 0.5985 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - AUC: 0.9529 - accuracy: 0.8743 - loss: 0.4367 - val_AUC: 0.8750 - val_accuracy: 0.7905 - val_loss: 0.6538 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - AUC: 0.9622 - accuracy: 0.8969 - loss: 0.3879 - val_AUC: 0.8790 - val_accuracy: 0.8394 - val_loss: 0.5517 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - AUC: 0.9641 - accuracy: 0.8964 - loss: 0.3746 - val_AUC: 0.8721 - val_accuracy: 0.8538 - val_loss: 0.5503 - learning_rate: 1.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - AUC: 0.9653 - accuracy: 0.9096 - loss: 0.3606 - val_AUC: 0.8746 - val_accuracy: 0.8270 - val_loss: 0.5901 - learning_rate: 1.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - AUC: 0.9739 - accuracy: 0.9176 - loss: 0.3321 - val_AUC: 0.8697 - val_accuracy: 0.8166 - val_loss: 0.6487 - learning_rate: 1.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - AUC: 0.9766 - accuracy: 0.9300 - loss: 0.3053 - val_AUC: 0.8663 - val_accuracy: 0.8597 - val_loss: 0.5584 - learning_rate: 1.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - AUC: 0.9800 - accuracy: 0.9412 - loss: 0.2880 - val_AUC: 0.8660 - val_accuracy: 0.8440 - val_loss: 0.5676 - learning_rate: 1.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - AUC: 0.9795 - accuracy: 0.9392 - loss: 0.2823 - val_AUC: 0.8700 - val_accuracy: 0.8597 - val_loss: 0.5806 - learning_rate: 5.0000e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - AUC: 0.9872 - accuracy: 0.9582 - loss: 0.2418 - val_AUC: 0.8557 - val_accuracy: 0.8662 - val_loss: 0.6122 - learning_rate: 5.0000e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - AUC: 0.9861 - accuracy: 0.9567 - loss: 0.2351 - val_AUC: 0.8698 - val_accuracy: 0.8590 - val_loss: 0.6120 - learning_rate: 5.0000e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - AUC: 0.9900 - accuracy: 0.9614 - loss: 0.2165 - val_AUC: 0.8598 - val_accuracy: 0.8708 - val_loss: 0.6317 - learning_rate: 5.0000e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - AUC: 0.9918 - accuracy: 0.9718 - loss: 0.2050 - val_AUC: 0.8573 - val_accuracy: 0.8662 - val_loss: 0.6621 - learning_rate: 2.5000e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - AUC: 0.9930 - accuracy: 0.9745 - loss: 0.1866 - val_AUC: 0.8381 - val_accuracy: 0.8675 - val_loss: 0.7050 - learning_rate: 2.5000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-02 01:04:46.503455: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.3517620861530304, Train accuracy: 0.9192624092102051\n",
      "Validation loss: 0.5502704977989197, Validation accuracy: 0.8537858724594116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-02 01:09:00.078282: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n",
      "Test ROC AUC: 0.8887\n",
      "Test Accuracy: 0.8169\n",
      "Test MAE: 0.1784\n",
      "Test Percision: 0.4774\n",
      "Test Specificity: 0.8239\n",
      "Test Sensitivity(Recall): 0.7829\n",
      "Test F1: 0.5931 \n",
      "\n",
      "Fold 2 - AUC: 0.8887, Accuracy: 0.8169, Recall: 0.7829, Precision: 0.4774, Specificity: 0.8239, F1: 0.5931\n",
      "\n",
      "[[702 150]\n",
      " [ 38 137]]\n",
      "Processing fold 3...\n",
      "349, 70, 47, participants in Train, Validation, and Test sets\n",
      "Class weights:  {0: 0.579399451421972, 1: 3.6486363636363635}\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m497/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - AUC: 0.5699 - accuracy: 0.5857 - loss: 2.2167"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-02 01:11:02.899307: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - AUC: 0.5708 - accuracy: 0.5860 - loss: 2.2110"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-02 01:11:13.133035: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 45ms/step - AUC: 0.5709 - accuracy: 0.5861 - loss: 2.2099 - val_AUC: 0.6973 - val_accuracy: 0.5349 - val_loss: 1.0028 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - AUC: 0.7685 - accuracy: 0.6644 - loss: 0.9595 - val_AUC: 0.8218 - val_accuracy: 0.7429 - val_loss: 0.7240 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - AUC: 0.8405 - accuracy: 0.7454 - loss: 0.7475 - val_AUC: 0.8395 - val_accuracy: 0.7508 - val_loss: 0.7130 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - AUC: 0.8833 - accuracy: 0.7785 - loss: 0.6475 - val_AUC: 0.8684 - val_accuracy: 0.7455 - val_loss: 0.7264 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - AUC: 0.9192 - accuracy: 0.8305 - loss: 0.5561 - val_AUC: 0.8711 - val_accuracy: 0.7601 - val_loss: 0.7072 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - AUC: 0.9277 - accuracy: 0.8313 - loss: 0.5207 - val_AUC: 0.8825 - val_accuracy: 0.8233 - val_loss: 0.5800 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - AUC: 0.9391 - accuracy: 0.8521 - loss: 0.4725 - val_AUC: 0.8780 - val_accuracy: 0.8352 - val_loss: 0.5585 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - AUC: 0.9485 - accuracy: 0.8672 - loss: 0.4407 - val_AUC: 0.8741 - val_accuracy: 0.8066 - val_loss: 0.5937 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - AUC: 0.9572 - accuracy: 0.8787 - loss: 0.4024 - val_AUC: 0.8727 - val_accuracy: 0.7934 - val_loss: 0.6198 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - AUC: 0.9599 - accuracy: 0.8878 - loss: 0.3779 - val_AUC: 0.8794 - val_accuracy: 0.8173 - val_loss: 0.6008 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - AUC: 0.9685 - accuracy: 0.9026 - loss: 0.3501 - val_AUC: 0.8728 - val_accuracy: 0.8698 - val_loss: 0.5347 - learning_rate: 1.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - AUC: 0.9715 - accuracy: 0.9161 - loss: 0.3318 - val_AUC: 0.8741 - val_accuracy: 0.8545 - val_loss: 0.5852 - learning_rate: 1.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - AUC: 0.9731 - accuracy: 0.9143 - loss: 0.3167 - val_AUC: 0.8744 - val_accuracy: 0.8193 - val_loss: 0.6582 - learning_rate: 1.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - AUC: 0.9790 - accuracy: 0.9329 - loss: 0.2992 - val_AUC: 0.8765 - val_accuracy: 0.8419 - val_loss: 0.5951 - learning_rate: 1.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - AUC: 0.9810 - accuracy: 0.9396 - loss: 0.2707 - val_AUC: 0.8808 - val_accuracy: 0.8452 - val_loss: 0.6179 - learning_rate: 1.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - AUC: 0.9874 - accuracy: 0.9531 - loss: 0.2385 - val_AUC: 0.8643 - val_accuracy: 0.8757 - val_loss: 0.6245 - learning_rate: 5.0000e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - AUC: 0.9915 - accuracy: 0.9647 - loss: 0.2061 - val_AUC: 0.8690 - val_accuracy: 0.8631 - val_loss: 0.6509 - learning_rate: 5.0000e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - AUC: 0.9924 - accuracy: 0.9668 - loss: 0.2029 - val_AUC: 0.8480 - val_accuracy: 0.8704 - val_loss: 0.6805 - learning_rate: 5.0000e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - AUC: 0.9916 - accuracy: 0.9689 - loss: 0.1987 - val_AUC: 0.8319 - val_accuracy: 0.8777 - val_loss: 0.8004 - learning_rate: 5.0000e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - AUC: 0.9937 - accuracy: 0.9746 - loss: 0.1894 - val_AUC: 0.8404 - val_accuracy: 0.8711 - val_loss: 0.7782 - learning_rate: 2.5000e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - AUC: 0.9934 - accuracy: 0.9757 - loss: 0.1797 - val_AUC: 0.8317 - val_accuracy: 0.8698 - val_loss: 0.7857 - learning_rate: 2.5000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-02 01:14:32.073980: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.2994927167892456, Train accuracy: 0.93708735704422\n",
      "Validation loss: 0.5346757769584656, Validation accuracy: 0.869767427444458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m248/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-02 01:15:01.459498: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-02 01:15:05.429283: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "Test ROC AUC: 0.8871\n",
      "Test Accuracy: 0.8717\n",
      "Test MAE: 0.1350\n",
      "Test Percision: 0.5606\n",
      "Test Specificity: 0.9011\n",
      "Test Sensitivity(Recall): 0.7070\n",
      "Test F1: 0.6254 \n",
      "\n",
      "Fold 3 - AUC: 0.8871, Accuracy: 0.8717, Recall: 0.7070, Precision: 0.5606, Specificity: 0.9011, F1: 0.6254\n",
      "\n",
      "[[793  87]\n",
      " [ 46 111]]\n",
      "Processing fold 4...\n",
      "349, 70, 47, participants in Train, Validation, and Test sets\n",
      "Class weights:  {0: 0.5804888631761643, 1: 3.6060197663971247}\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m499/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - AUC: 0.5898 - accuracy: 0.7255 - loss: 2.5150"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - AUC: 0.5902 - accuracy: 0.7252 - loss: 2.5123"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-02 01:16:48.719991: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - AUC: 0.5903 - accuracy: 0.7252 - loss: 2.5114 - val_AUC: 0.7154 - val_accuracy: 0.6463 - val_loss: 1.3628 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - AUC: 0.7463 - accuracy: 0.6288 - loss: 1.2845 - val_AUC: 0.8053 - val_accuracy: 0.6508 - val_loss: 1.0420 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - AUC: 0.8345 - accuracy: 0.7238 - loss: 0.9621 - val_AUC: 0.8304 - val_accuracy: 0.6927 - val_loss: 0.9045 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - AUC: 0.9065 - accuracy: 0.7948 - loss: 0.7283 - val_AUC: 0.8615 - val_accuracy: 0.8270 - val_loss: 0.6630 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - AUC: 0.9188 - accuracy: 0.8310 - loss: 0.6302 - val_AUC: 0.8404 - val_accuracy: 0.7869 - val_loss: 0.6854 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - AUC: 0.9278 - accuracy: 0.8457 - loss: 0.5685 - val_AUC: 0.8549 - val_accuracy: 0.8117 - val_loss: 0.6381 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - AUC: 0.9521 - accuracy: 0.8819 - loss: 0.4796 - val_AUC: 0.8601 - val_accuracy: 0.8486 - val_loss: 0.5836 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - AUC: 0.9603 - accuracy: 0.8920 - loss: 0.4329 - val_AUC: 0.8570 - val_accuracy: 0.8397 - val_loss: 0.5804 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - AUC: 0.9612 - accuracy: 0.8963 - loss: 0.4130 - val_AUC: 0.8661 - val_accuracy: 0.8499 - val_loss: 0.5842 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - AUC: 0.9710 - accuracy: 0.9121 - loss: 0.3849 - val_AUC: 0.8657 - val_accuracy: 0.8531 - val_loss: 0.5609 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - AUC: 0.9786 - accuracy: 0.9276 - loss: 0.3318 - val_AUC: 0.8559 - val_accuracy: 0.8620 - val_loss: 0.5628 - learning_rate: 1.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - AUC: 0.9769 - accuracy: 0.9339 - loss: 0.3216 - val_AUC: 0.8570 - val_accuracy: 0.8518 - val_loss: 0.5732 - learning_rate: 1.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - AUC: 0.9831 - accuracy: 0.9343 - loss: 0.3018 - val_AUC: 0.8449 - val_accuracy: 0.8327 - val_loss: 0.6355 - learning_rate: 1.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - AUC: 0.9849 - accuracy: 0.9401 - loss: 0.2889 - val_AUC: 0.8617 - val_accuracy: 0.8378 - val_loss: 0.6419 - learning_rate: 1.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - AUC: 0.9888 - accuracy: 0.9495 - loss: 0.2588 - val_AUC: 0.8438 - val_accuracy: 0.8658 - val_loss: 0.6543 - learning_rate: 5.0000e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - AUC: 0.9918 - accuracy: 0.9638 - loss: 0.2318 - val_AUC: 0.8216 - val_accuracy: 0.8734 - val_loss: 0.7235 - learning_rate: 5.0000e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - AUC: 0.9927 - accuracy: 0.9660 - loss: 0.2225 - val_AUC: 0.8189 - val_accuracy: 0.8734 - val_loss: 0.7426 - learning_rate: 5.0000e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - AUC: 0.9921 - accuracy: 0.9669 - loss: 0.2191 - val_AUC: 0.8157 - val_accuracy: 0.8709 - val_loss: 0.7666 - learning_rate: 5.0000e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - AUC: 0.9936 - accuracy: 0.9784 - loss: 0.1942 - val_AUC: 0.7962 - val_accuracy: 0.8747 - val_loss: 0.8211 - learning_rate: 2.5000e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - AUC: 0.9963 - accuracy: 0.9848 - loss: 0.1784 - val_AUC: 0.7770 - val_accuracy: 0.8823 - val_loss: 0.8684 - learning_rate: 2.5000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.3499069809913635, Train accuracy: 0.9302354454994202\n",
      "Validation loss: 0.5609224438667297, Validation accuracy: 0.8530534505844116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m246/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step\n",
      "\u001b[1m26/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 01:23:30.359738: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 0.8994\n",
      "Test Accuracy: 0.8429\n",
      "Test MAE: 0.1566\n",
      "Test Percision: 0.5149\n",
      "Test Specificity: 0.8580\n",
      "Test Sensitivity(Recall): 0.7658\n",
      "Test F1: 0.6158 \n",
      "\n",
      "Fold 4 - AUC: 0.8994, Accuracy: 0.8429, Recall: 0.7658, Precision: 0.5149, Specificity: 0.8580, F1: 0.6158\n",
      "\n",
      "[[689 114]\n",
      " [ 37 121]]\n",
      "\n",
      "Average Train Accuracy: 0.9237 (+- 0.0110)\n",
      "Average Validation Accuracy: 0.8578 (+- 0.0069)\n",
      "Average Test Accuracy: 0.8356 (+- 0.0241)\n",
      "Average Test Recall: 0.7639 (+- 0.0350)\n",
      "Average Test Precision: 0.4900 (+- 0.0561)\n",
      "Average Test Specificity: 0.8489 (+- 0.0345)\n",
      "Average Test AUC: 0.8907 (+- 0.0050)\n",
      "Average Test F1: 0.5935 (+- 0.0332)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated Models on holdout set ... \n",
      "\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-02 01:23:33.278904: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
      "Holdout ROC AUC: 0.9800\n",
      "Holdout Accuracy: 0.9317\n",
      "Holdout MAE: 0.1566\n",
      "Holdout Percision: 0.7000\n",
      "Holdout Specificity: 0.9211\n",
      "Holdout Sensitivity(Recall): 0.9891\n",
      "Holdout F1: 0.8198 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best 3 models (ROC AUC) to prdict holdout:\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Holdout ROC AUC: 0.9768\n",
      "Holdout Accuracy: 0.9078\n",
      "Holdout MAE: 0.1566\n",
      "Holdout Percision: 0.6357\n",
      "Holdout Specificity: 0.8968\n",
      "Holdout Sensitivity(Recall): 0.9674\n",
      "Holdout F1: 0.7672 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[443,  51],\n",
       "       [  3,  89]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################# Class Weights Original 70 K_Fold 3-channel input w/ Masking, Daily & Individual input, Classifying Hypo Night\n",
    "########################################################################################################################################\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "folder_name = \"/home/ma98/Compressed_DEXI_Data/Hypo_70_Original/Hypo_Night\"\n",
    "matrix_shape0 = 288\n",
    "# Reshape matrices to the required shapes\n",
    "X_features_daily_imputed = np.nan_to_num(X_features_daily_scaled, nan=0.0)\n",
    "X_features_individual_imputed = np.nan_to_num(X_features_individual_scaled, nan=0.0)\n",
    "\n",
    "# Create masks for missing values\n",
    "mask_daily = np.isfinite(X_features_daily_scaled).astype(np.float32)\n",
    "mask_individual = np.isfinite(X_features_individual_scaled).astype(np.float32)\n",
    "\n",
    "# Initialize GroupKFold\n",
    "num_splits = 4\n",
    "group_kfold = GroupKFold(n_splits=num_splits)\n",
    "unique_participants = np.unique(participant_ids)\n",
    "# # Shuffle to ensure no artifacts in test train/validation split\n",
    "# unique_participants = shuffle(unique_participants, random_state=42)\n",
    "\n",
    "# Completely hold out a test set before cross-validation\n",
    "holdout_participants = unique_participants[int(0.95 * len(unique_participants)):]\n",
    "holdout_idx = np.where(np.isin(participant_ids, holdout_participants))[0]\n",
    "\n",
    "# Remove the holdout participants from the pool used for cross-validation model\n",
    "model_participants = unique_participants[:int(0.95 * len(unique_participants))]\n",
    "\n",
    "final_results_night = {\n",
    "    \"fold_model\": [],\n",
    "    \"specificity_scores\": [],\n",
    "    \"accuracy_scores\": [],\n",
    "    \"precision_scores\": [],\n",
    "    \"recall_scores\": [],\n",
    "    \"f1_scores\": [],\n",
    "    \"roc_auc_scores\": [],\n",
    "    \"mae\": [],\n",
    "    \"mse\": [],\n",
    "    \"fold_train_loss\": [],\n",
    "    \"fold_train_acc\": [],\n",
    "    \"fold_val_loss\": [],\n",
    "    \"fold_val_acc\": [],\n",
    "    \"conf_matrix\": [],\n",
    "    \"class_report\": [],\n",
    "    \"train_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_acc\": []\n",
    "}\n",
    "# # Enable mixed precision\n",
    "# keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "for fold, (train_idx, val_test_idx) in enumerate(group_kfold.split(X_matrices_power_scaled, y_labels['hypo_night'], groups=participant_ids)):\n",
    "    # 75% of the data as train set\n",
    "    train_participants = model_participants[np.isin(model_participants, participant_ids[train_idx])]    \n",
    "    val_test_participants = model_participants[np.isin(model_participants, participant_ids[val_test_idx])]\n",
    "    \n",
    "    val_size = int(len(val_test_participants) * 3 / 5)\n",
    "    val_participants = val_test_participants[:val_size]\n",
    "    test_participants = val_test_participants[val_size:]\n",
    "    \n",
    "    # Get corresponding indices\n",
    "    val_idx = np.where(np.isin(participant_ids, val_participants))[0]\n",
    "    test_idx = np.where(np.isin(participant_ids, test_participants))[0]\n",
    "    print(f\"Processing fold {fold + 1}...\")\n",
    "    print(f\"{len(train_participants)}, {len(val_participants)}, {len(test_participants)}, participants in Train, Validation, and Test sets\" )\n",
    "\n",
    "    # Train-test split based on indices\n",
    "    X_matrices_coeffs_train,X_matrices_coeffs_val, X_matrices_coeffs_test = X_matrices_power_scaled[train_idx],X_matrices_power_scaled[val_idx], X_matrices_power_scaled[test_idx]\n",
    "    X_features_daily_train,X_features_daily_val, X_features_daily_test = X_features_daily_imputed[train_idx],X_features_daily_imputed[val_idx], X_features_daily_imputed[test_idx]\n",
    "    X_features_individual_train,X_features_individual_val, X_features_individual_test = X_features_individual_imputed[train_idx],X_features_individual_imputed[val_idx], X_features_individual_imputed[test_idx]\n",
    "    y_label_train,y_label_val, y_label_test = y_labels['hypo_night'][train_idx],y_labels['hypo_night'][val_idx], y_labels['hypo_night'][test_idx]\n",
    "    mask_daily_train,mask_daily_val, mask_daily_test = mask_daily[train_idx], mask_daily[val_idx], mask_daily[test_idx]\n",
    "    mask_individual_train,mask_individual_val, mask_individual_test = mask_individual[train_idx],mask_individual[val_idx], mask_individual[test_idx]\n",
    "\n",
    "    num_epochs = 30\n",
    "    # Create a new model instance\n",
    "    model = create_model()\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    # checkpoint = ModelCheckpoint(filepath=os.path.join(folder_name, 'best_model_fold_{}.keras'.format(fold)), monitor='val_AUC', save_best_only=True, mode='max')\n",
    "    learning_rate_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-7)\n",
    "    y_label_train_flat = y_label_train.ravel()\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_label_train_flat), y=y_label_train_flat)\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "    print(\"Class weights: \", class_weight_dict)\n",
    "    history_hypo_night = model.fit([X_matrices_coeffs_train, X_features_daily_train, X_features_individual_train, mask_daily_train, mask_individual_train], \n",
    "                                         y_label_train, \n",
    "                                         epochs=num_epochs, batch_size=16, verbose=1,\n",
    "                                         validation_data=([X_matrices_coeffs_val, X_features_daily_val, X_features_individual_val, mask_daily_val, mask_individual_val], y_label_val),\n",
    "                                         callbacks=[early_stopping, learning_rate_scheduler],\n",
    "                                         class_weight=class_weight_dict)\n",
    "    # Evaluate training and testing performance\n",
    "    train_score = model.evaluate([X_matrices_coeffs_train, X_features_daily_train, X_features_individual_train, mask_daily_train, mask_individual_train], \n",
    "                                 y_label_train, verbose=0)\n",
    "    val_score = model.evaluate([X_matrices_coeffs_val, X_features_daily_val, X_features_individual_val, mask_daily_val, mask_individual_val], \n",
    "                                y_label_val, verbose=0)\n",
    "    print('\\nTrain loss: {}, Train accuracy: {}'.format(train_score[0], train_score[1]))\n",
    "    print('Validation loss: {}, Validation accuracy: {}'.format(val_score[0], val_score[1]))\n",
    "    # print('Test loss: {}, Test accuracy: {}\\n'.format(test_score[0], test_score[1]))\n",
    "    y_pred_train = model.predict([X_matrices_coeffs_train, X_features_daily_train,X_features_individual_train, mask_daily_train, mask_individual_train])\n",
    "    y_pred_test = model.predict([X_matrices_coeffs_test, X_features_daily_test,X_features_individual_test, mask_daily_test, mask_individual_test])\n",
    "\n",
    "    mae_train = mean_absolute_error(y_label_train, y_pred_train)\n",
    "    mse_train = mean_squared_error(y_label_train, y_pred_train)\n",
    "\n",
    "    roc_auc_test = roc_auc_score(y_label_test, y_pred_test)\n",
    "    print(f'Test ROC AUC: {roc_auc_test:.4f}')\n",
    "\n",
    "    y_pred_train_binary = (y_pred_train >= 0.5).astype(int)\n",
    "    y_pred_test_binary = (y_pred_test >= 0.3).astype(int)\n",
    "    mae_test = mean_absolute_error(y_label_test, y_pred_test)\n",
    "    mse_test = mean_squared_error(y_label_test, y_pred_test)\n",
    "    accuracy = accuracy_score(y_label_test, y_pred_test_binary)\n",
    "    recall = recall_score(y_label_test, y_pred_test_binary)\n",
    "    f1 = f1_score(y_label_test, y_pred_test_binary)\n",
    "    precision = precision_score(y_label_test, y_pred_test_binary)\n",
    "    specificity = recall_score(y_label_test, y_pred_test_binary, pos_label=0)\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    print(f'Test MAE: {mae_test:.4f}')\n",
    "    print(f'Test Percision: {precision:.4f}')\n",
    "    print(f'Test Specificity: {specificity:.4f}')\n",
    "    print(f'Test Sensitivity(Recall): {recall:.4f}')\n",
    "    print(f'Test F1: {f1:.4f} \\n')\n",
    "    print(f'Fold {fold + 1} - AUC: {roc_auc_test:.4f}, Accuracy: {accuracy:.4f}, Recall: {recall:.4f}, Precision: {precision:.4f}, Specificity: {specificity:.4f}, F1: {f1:.4f}\\n')\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_label_test, y_pred_test_binary)\n",
    "    # Classification Report\n",
    "    class_report = classification_report(y_label_test, y_pred_test_binary)\n",
    "    print(conf_matrix)\n",
    "    final_results_night[\"precision_scores\"].append(precision)\n",
    "    final_results_night[\"recall_scores\"].append(recall)\n",
    "    final_results_night[\"f1_scores\"].append(f1)\n",
    "    final_results_night[\"accuracy_scores\"].append(accuracy)\n",
    "    final_results_night[\"roc_auc_scores\"].append(roc_auc_test)\n",
    "    final_results_night[\"specificity_scores\"].append(specificity)\n",
    "    final_results_night[\"mae\"].append(mae_test)\n",
    "    final_results_night[\"mse\"].append(mse_test)\n",
    "    final_results_night[\"train_loss\"].append(train_score[0])\n",
    "    final_results_night[\"train_acc\"].append(train_score[1])\n",
    "    final_results_night[\"val_loss\"].append(val_score[0])\n",
    "    final_results_night[\"val_acc\"].append(val_score[1])\n",
    "    final_results_night[\"fold_train_acc\"].append(history_hypo_night.history['accuracy'])\n",
    "    final_results_night[\"fold_train_loss\"].append(history_hypo_night.history['loss'])\n",
    "    final_results_night[\"fold_val_acc\"].append(history_hypo_night.history['val_accuracy'])\n",
    "    final_results_night[\"fold_val_loss\"].append(history_hypo_night.history['val_loss'])\n",
    "    final_results_night[\"conf_matrix\"].append(conf_matrix)\n",
    "    final_results_night[\"class_report\"].append(class_report)\n",
    "    final_results_night[\"fold_model\"].append(model)\n",
    "          \n",
    "# Calculate and print average and std across folds\n",
    "print(f'\\nAverage Train Accuracy: {np.mean(final_results_night[\"train_acc\"]):.4f} (+- {np.std(final_results_night[\"train_acc\"]):.4f})')\n",
    "print(f'Average Validation Accuracy: {np.mean(final_results_night[\"val_acc\"]):.4f} (+- {np.std(final_results_night[\"val_acc\"]):.4f})')\n",
    "print(f'Average Test Accuracy: {np.mean(final_results_night[\"accuracy_scores\"]):.4f} (+- {np.std(final_results_night[\"accuracy_scores\"]):.4f})')\n",
    "print(f'Average Test Recall: {np.mean(final_results_night[\"recall_scores\"]):.4f} (+- {np.std(final_results_night[\"recall_scores\"]):.4f})')\n",
    "print(f'Average Test Precision: {np.mean(final_results_night[\"precision_scores\"]):.4f} (+- {np.std(final_results_night[\"precision_scores\"]):.4f})')\n",
    "print(f'Average Test Specificity: {np.mean(final_results_night[\"specificity_scores\"]):.4f} (+- {np.std(final_results_night[\"specificity_scores\"]):.4f})')\n",
    "print(f'Average Test AUC: {np.mean(final_results_night[\"roc_auc_scores\"]):.4f} (+- {np.std(final_results_night[\"roc_auc_scores\"]):.4f})')\n",
    "print(f'Average Test F1: {np.mean(final_results_night[\"f1_scores\"]):.4f} (+- {np.std(final_results_night[\"f1_scores\"]):.4f})')\n",
    "\n",
    "max_epochs = max(len(fold) for fold in final_results_night[\"fold_val_loss\"])\n",
    "# Initialize arrays to store average and std dev for each epoch\n",
    "avg_loss = np.zeros(max_epochs)\n",
    "std_loss = np.zeros(max_epochs)\n",
    "avg_acc = np.zeros(max_epochs)\n",
    "std_acc = np.zeros(max_epochs)\n",
    "# Compute average and standard deviation for each epoch\n",
    "for epoch in range(max_epochs):\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    for fold_loss, fold_acc in zip(final_results_night[\"fold_val_loss\"], final_results_night[\"fold_val_acc\"]):\n",
    "        if epoch < len(fold_loss):\n",
    "            losses.append(fold_loss[epoch])\n",
    "        if epoch < len(fold_acc):\n",
    "            accuracies.append(fold_acc[epoch])\n",
    "    \n",
    "    if losses:\n",
    "        avg_loss[epoch] = np.mean(losses)\n",
    "        std_loss[epoch] = np.std(losses)\n",
    "    if accuracies:\n",
    "        avg_acc[epoch] = np.mean(accuracies)\n",
    "        std_acc[epoch] = np.std(accuracies)\n",
    "# Plot average loss and accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, max_epochs + 1), avg_loss, color='blue', label='Validation Loss')\n",
    "plt.fill_between(range(1, max_epochs + 1), \n",
    "                 avg_loss - std_loss,\n",
    "                 avg_loss + std_loss,\n",
    "                 color='blue', alpha=0.2)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Validation Loss per Epoch')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, max_epochs + 1), avg_acc, color='blue', label='Validation Accuracy')\n",
    "plt.fill_between(range(1, max_epochs + 1), \n",
    "                 avg_acc - std_acc,\n",
    "                 avg_acc + std_acc,\n",
    "                 color='blue', alpha=0.2)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Validation Accuracy per Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(folder_name, 'loss_accuracy_plot.png'))\n",
    "plt.show()\n",
    "\n",
    "########################################################################################################################################\n",
    "print(f\"Aggregated Models on holdout set ... \\n\")\n",
    "\n",
    "# Train-test split based on indices\n",
    "X_matrices_coeffs_holdout = X_matrices_power_scaled[holdout_idx]\n",
    "X_features_daily_holdout = X_features_daily_imputed[holdout_idx]\n",
    "X_features_individual_holdout = X_features_individual_imputed[holdout_idx]\n",
    "y_label_holdout = y_labels['hypo_night'][holdout_idx]\n",
    "mask_daily_holdout = mask_daily[holdout_idx]\n",
    "mask_individual_holdout = mask_individual[holdout_idx]\n",
    "\n",
    "# Initialize arrays to store predictions from each fold\n",
    "y_pred_holdout_agg = np.zeros((len(holdout_idx),))  # Assuming binary classification\n",
    "# Aggregate predictions from each fold model\n",
    "for model in final_results_night[\"fold_model\"]:\n",
    "    y_pred_holdout_fold = model.predict([X_matrices_coeffs_holdout, X_features_daily_holdout, X_features_individual_holdout, mask_daily_holdout, mask_individual_holdout])\n",
    "    y_pred_holdout_agg += y_pred_holdout_fold.flatten()  # Accumulate predictions\n",
    "    y_pred_holdout_avg = np.mean(y_pred_holdout_fold, axis=0)\n",
    "# Average the predictions from all folds\n",
    "y_pred_holdout_agg /= num_splits\n",
    "\n",
    "mae_holdout = mean_absolute_error(y_label_holdout, y_pred_holdout_agg)\n",
    "mse_holdout = mean_squared_error(y_label_holdout, y_pred_holdout_agg)\n",
    "roc_auc = roc_auc_score(y_label_holdout, y_pred_holdout_agg)\n",
    "print(f'Holdout ROC AUC: {roc_auc:.4f}')\n",
    "\n",
    "y_pred_holdout_binary_agg = (y_pred_holdout_agg >= 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "recall = recall_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "precision = precision_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "f1 = f1_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "specificity = recall_score(y_label_holdout, y_pred_holdout_binary_agg, pos_label=0)\n",
    "\n",
    "print(f'Holdout Accuracy: {accuracy:.4f}')\n",
    "print(f'Holdout MAE: {mae_test:.4f}')\n",
    "print(f'Holdout Percision: {precision:.4f}')\n",
    "print(f'Holdout Specificity: {specificity:.4f}')\n",
    "print(f'Holdout Sensitivity(Recall): {recall:.4f}')\n",
    "print(f'Holdout F1: {f1:.4f} \\n')\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(conf_matrix, cmap='Blues', interpolation='nearest')\n",
    "plt.title('Confusion Matrix for Final Model')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        plt.text(j, i, conf_matrix[i, j], \n",
    "                 ha='center', va='center', color='black', fontsize=14)\n",
    "plt.savefig(os.path.join(folder_name, 'conf_matrix_plot.png'))\n",
    "plt.show()\n",
    "\n",
    "description_path = os.path.join(folder_name, 'Description.txt')\n",
    "with open(description_path, 'w') as f:\n",
    "    f.write(\"\"\"\n",
    "    # K_Fold 3-channel _Smooth _Below70 Hypo, input w/ Masking, Daily & Individual input, Classifying Hypo Night\n",
    "    \"\"\")\n",
    "        # Write the results\n",
    "    f.write(f'\\nAverage Train Accuracy: {np.mean(final_results_night[\"train_acc\"]):.4f} (+- {np.std(final_results_night[\"train_acc\"]):.4f})\\n')\n",
    "    f.write(f'Average Validation Accuracy: {np.mean(final_results_night[\"val_acc\"]):.4f} (+- {np.std(final_results_night[\"val_acc\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Accuracy: {np.mean(final_results_night[\"accuracy_scores\"]):.4f} (+- {np.std(final_results_night[\"accuracy_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Recall: {np.mean(final_results_night[\"recall_scores\"]):.4f} (+- {np.std(final_results_night[\"recall_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Precision: {np.mean(final_results_night[\"precision_scores\"]):.4f} (+- {np.std(final_results_night[\"precision_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Specificity: {np.mean(final_results_night[\"specificity_scores\"]):.4f} (+- {np.std(final_results_night[\"specificity_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test AUC: {np.mean(final_results_night[\"roc_auc_scores\"]):.4f} (+- {np.std(final_results_night[\"roc_auc_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test F1: {np.mean(final_results_night[\"f1_scores\"]):.4f} (+- {np.std(final_results_night[\"f1_scores\"]):.4f})\\n')\n",
    "    \n",
    "    # Writing holdout results\n",
    "    f.write(f'Holdout ROC AUC: {roc_auc:.4f}\\n')\n",
    "    f.write(f'Holdout Accuracy: {accuracy:.4f}\\n')\n",
    "    f.write(f'Holdout MAE: {mae_test:.4f}\\n')\n",
    "    f.write(f'Holdout Precision: {precision:.4f}\\n')\n",
    "    f.write(f'Holdout Specificity: {specificity:.4f}\\n')\n",
    "    f.write(f'Holdout Sensitivity (Recall): {recall:.4f}\\n')\n",
    "    f.write(f'Holdout F1: {f1:.4f}\\n')\n",
    "model_summary_path = os.path.join(folder_name, 'model_summary.txt')\n",
    "with open(model_summary_path, 'w') as f:\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "#model.summary()\n",
    "# Save the final results as pickle\n",
    "final_results_path = os.path.join(folder_name, 'final_results.pkl')\n",
    "with open(final_results_path, 'wb') as file:\n",
    "    pickle.dump(final_results_night, file)\n",
    "\n",
    "print(\"\\nBest 3 models (ROC AUC) to prdict holdout:\")\n",
    "best_of = 3\n",
    "top_3_model_indices = np.argsort(final_results_night[\"roc_auc_scores\"])[-best_of:][::-1]\n",
    "y_pred_holdout_agg = np.zeros((len(holdout_idx),))  # Assuming binary classification\n",
    "for idx in top_3_model_indices:\n",
    "    model = final_results_night[\"fold_model\"][idx]\n",
    "    y_pred_holdout_fold = model.predict([X_matrices_coeffs_holdout, X_features_daily_holdout, X_features_individual_holdout, mask_daily_holdout, mask_individual_holdout])\n",
    "    y_pred_holdout_agg += y_pred_holdout_fold.flatten()\n",
    "y_pred_holdout_agg /= best_of\n",
    "\n",
    "mae_holdout = mean_absolute_error(y_label_holdout, y_pred_holdout_agg)\n",
    "mse_holdout = mean_squared_error(y_label_holdout, y_pred_holdout_agg)\n",
    "roc_auc = roc_auc_score(y_label_holdout, y_pred_holdout_agg)\n",
    "print(f'Holdout ROC AUC: {roc_auc:.4f}')\n",
    "\n",
    "y_pred_holdout_binary_agg = (y_pred_holdout_agg >= 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "recall = recall_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "precision = precision_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "f1 = f1_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "specificity = recall_score(y_label_holdout, y_pred_holdout_binary_agg, pos_label=0)\n",
    "\n",
    "print(f'Holdout Accuracy: {accuracy:.4f}')\n",
    "print(f'Holdout MAE: {mae_test:.4f}')\n",
    "print(f'Holdout Percision: {precision:.4f}')\n",
    "print(f'Holdout Specificity: {specificity:.4f}')\n",
    "print(f'Holdout Sensitivity(Recall): {recall:.4f}')\n",
    "print(f'Holdout F1: {f1:.4f} \\n')\n",
    "conf_matrix = confusion_matrix(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "conf_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbeaaec-0324-4740-9b74-29c0a860e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run garbage collection\n",
    "gc.collect()\n",
    "################# Batch 64_Class Weights Original 70 K_Fold 3-channel input w/ Masking, Daily & Individual input, Classifying Hypo Night\n",
    "########################################################################################################################################\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "folder_name = \"/home/ma98/Compressed_DEXI_Data/Hypo_70_Original/Hypo_Night\"\n",
    "matrix_shape0 = 288\n",
    "# Reshape matrices to the required shapes\n",
    "X_features_daily_imputed = np.nan_to_num(X_features_daily_scaled, nan=0.0)\n",
    "X_features_individual_imputed = np.nan_to_num(X_features_individual_scaled, nan=0.0)\n",
    "\n",
    "# Create masks for missing values\n",
    "mask_daily = np.isfinite(X_features_daily_scaled).astype(np.float32)\n",
    "mask_individual = np.isfinite(X_features_individual_scaled).astype(np.float32)\n",
    "\n",
    "# Initialize GroupKFold\n",
    "num_splits = 4\n",
    "group_kfold = GroupKFold(n_splits=num_splits)\n",
    "unique_participants = np.unique(participant_ids)\n",
    "# # Shuffle to ensure no artifacts in test train/validation split\n",
    "# unique_participants = shuffle(unique_participants, random_state=42)\n",
    "\n",
    "# Completely hold out a test set before cross-validation\n",
    "holdout_participants = unique_participants[int(0.95 * len(unique_participants)):]\n",
    "holdout_idx = np.where(np.isin(participant_ids, holdout_participants))[0]\n",
    "\n",
    "# Remove the holdout participants from the pool used for cross-validation model\n",
    "model_participants = unique_participants[:int(0.95 * len(unique_participants))]\n",
    "\n",
    "final_results_night = {\n",
    "    \"fold_model\": [],\n",
    "    \"specificity_scores\": [],\n",
    "    \"accuracy_scores\": [],\n",
    "    \"precision_scores\": [],\n",
    "    \"recall_scores\": [],\n",
    "    \"f1_scores\": [],\n",
    "    \"roc_auc_scores\": [],\n",
    "    \"mae\": [],\n",
    "    \"mse\": [],\n",
    "    \"fold_train_loss\": [],\n",
    "    \"fold_train_acc\": [],\n",
    "    \"fold_val_loss\": [],\n",
    "    \"fold_val_acc\": [],\n",
    "    \"conf_matrix\": [],\n",
    "    \"class_report\": [],\n",
    "    \"train_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_acc\": []\n",
    "}\n",
    "# # Enable mixed precision\n",
    "# keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "for fold, (train_idx, val_test_idx) in enumerate(group_kfold.split(X_matrices_power_scaled, y_labels['hypo_night'], groups=participant_ids)):\n",
    "    # 75% of the data as train set\n",
    "    train_participants = model_participants[np.isin(model_participants, participant_ids[train_idx])]    \n",
    "    val_test_participants = model_participants[np.isin(model_participants, participant_ids[val_test_idx])]\n",
    "    \n",
    "    val_size = int(len(val_test_participants) * 3 / 5)\n",
    "    val_participants = val_test_participants[:val_size]\n",
    "    test_participants = val_test_participants[val_size:]\n",
    "    \n",
    "    # Get corresponding indices\n",
    "    val_idx = np.where(np.isin(participant_ids, val_participants))[0]\n",
    "    test_idx = np.where(np.isin(participant_ids, test_participants))[0]\n",
    "    print(f\"Processing fold {fold + 1}...\")\n",
    "    print(f\"{len(train_participants)}, {len(val_participants)}, {len(test_participants)}, participants in Train, Validation, and Test sets\" )\n",
    "\n",
    "    # Train-test split based on indices\n",
    "    X_matrices_coeffs_train,X_matrices_coeffs_val, X_matrices_coeffs_test = X_matrices_power_scaled[train_idx],X_matrices_power_scaled[val_idx], X_matrices_power_scaled[test_idx]\n",
    "    X_features_daily_train,X_features_daily_val, X_features_daily_test = X_features_daily_imputed[train_idx],X_features_daily_imputed[val_idx], X_features_daily_imputed[test_idx]\n",
    "    X_features_individual_train,X_features_individual_val, X_features_individual_test = X_features_individual_imputed[train_idx],X_features_individual_imputed[val_idx], X_features_individual_imputed[test_idx]\n",
    "    y_label_train,y_label_val, y_label_test = y_labels['hypo_night'][train_idx],y_labels['hypo_night'][val_idx], y_labels['hypo_night'][test_idx]\n",
    "    mask_daily_train,mask_daily_val, mask_daily_test = mask_daily[train_idx], mask_daily[val_idx], mask_daily[test_idx]\n",
    "    mask_individual_train,mask_individual_val, mask_individual_test = mask_individual[train_idx],mask_individual[val_idx], mask_individual[test_idx]\n",
    "\n",
    "    num_epochs = 30\n",
    "    # Create a new model instance\n",
    "    model = create_model()\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    checkpoint = ModelCheckpoint(filepath=os.path.join(folder_name, 'best_model_fold_{}.keras'.format(fold)), monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "    learning_rate_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-7)\n",
    "    y_label_train_flat = y_label_train.ravel()\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_label_train_flat), y=y_label_train_flat)\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "    print(\"Class weights: \", class_weight_dict)\n",
    "    history_hypo_night = model.fit([X_matrices_coeffs_train, X_features_daily_train, X_features_individual_train, mask_daily_train, mask_individual_train], \n",
    "                                         y_label_train, \n",
    "                                         epochs=num_epochs, batch_size=64, verbose=1,\n",
    "                                         validation_data=([X_matrices_coeffs_val, X_features_daily_val, X_features_individual_val, mask_daily_val, mask_individual_val], y_label_val),\n",
    "                                         callbacks=[early_stopping, learning_rate_scheduler, checkpoint],\n",
    "                                         class_weight=class_weight_dict)\n",
    "    # Evaluate training and testing performance\n",
    "    train_score = model.evaluate([X_matrices_coeffs_train, X_features_daily_train, X_features_individual_train, mask_daily_train, mask_individual_train], \n",
    "                                 y_label_train, verbose=0)\n",
    "    val_score = model.evaluate([X_matrices_coeffs_val, X_features_daily_val, X_features_individual_val, mask_daily_val, mask_individual_val], \n",
    "                                y_label_val, verbose=0)\n",
    "    print('\\nTrain loss: {}, Train accuracy: {}'.format(train_score[0], train_score[1]))\n",
    "    print('Validation loss: {}, Validation accuracy: {}'.format(val_score[0], val_score[1]))\n",
    "    # print('Test loss: {}, Test accuracy: {}\\n'.format(test_score[0], test_score[1]))\n",
    "    y_pred_train = model.predict([X_matrices_coeffs_train, X_features_daily_train,X_features_individual_train, mask_daily_train, mask_individual_train])\n",
    "    y_pred_test = model.predict([X_matrices_coeffs_test, X_features_daily_test,X_features_individual_test, mask_daily_test, mask_individual_test])\n",
    "\n",
    "    mae_train = mean_absolute_error(y_label_train, y_pred_train)\n",
    "    mse_train = mean_squared_error(y_label_train, y_pred_train)\n",
    "\n",
    "    roc_auc_test = roc_auc_score(y_label_test, y_pred_test)\n",
    "    print(f'Test ROC AUC: {roc_auc_test:.4f}')\n",
    "\n",
    "    y_pred_train_binary = (y_pred_train >= 0.5).astype(int)\n",
    "    y_pred_test_binary = (y_pred_test >= 0.3).astype(int)\n",
    "    mae_test = mean_absolute_error(y_label_test, y_pred_test)\n",
    "    mse_test = mean_squared_error(y_label_test, y_pred_test)\n",
    "    accuracy = accuracy_score(y_label_test, y_pred_test_binary)\n",
    "    recall = recall_score(y_label_test, y_pred_test_binary)\n",
    "    f1 = f1_score(y_label_test, y_pred_test_binary)\n",
    "    precision = precision_score(y_label_test, y_pred_test_binary)\n",
    "    specificity = recall_score(y_label_test, y_pred_test_binary, pos_label=0)\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    print(f'Test MAE: {mae_test:.4f}')\n",
    "    print(f'Test Percision: {precision:.4f}')\n",
    "    print(f'Test Specificity: {specificity:.4f}')\n",
    "    print(f'Test Sensitivity(Recall): {recall:.4f}')\n",
    "    print(f'Test F1: {f1:.4f} \\n')\n",
    "    print(f'Fold {fold + 1} - AUC: {roc_auc_test:.4f}, Accuracy: {accuracy:.4f}, Recall: {recall:.4f}, Precision: {precision:.4f}, Specificity: {specificity:.4f}, F1: {f1:.4f}\\n')\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_label_test, y_pred_test_binary)\n",
    "    # Classification Report\n",
    "    class_report = classification_report(y_label_test, y_pred_test_binary)\n",
    "    print(conf_matrix)\n",
    "    final_results_night[\"precision_scores\"].append(precision)\n",
    "    final_results_night[\"recall_scores\"].append(recall)\n",
    "    final_results_night[\"f1_scores\"].append(f1)\n",
    "    final_results_night[\"accuracy_scores\"].append(accuracy)\n",
    "    final_results_night[\"roc_auc_scores\"].append(roc_auc_test)\n",
    "    final_results_night[\"specificity_scores\"].append(specificity)\n",
    "    final_results_night[\"mae\"].append(mae_test)\n",
    "    final_results_night[\"mse\"].append(mse_test)\n",
    "    final_results_night[\"train_loss\"].append(train_score[0])\n",
    "    final_results_night[\"train_acc\"].append(train_score[1])\n",
    "    final_results_night[\"val_loss\"].append(val_score[0])\n",
    "    final_results_night[\"val_acc\"].append(val_score[1])\n",
    "    final_results_night[\"fold_train_acc\"].append(history_hypo_night.history['accuracy'])\n",
    "    final_results_night[\"fold_train_loss\"].append(history_hypo_night.history['loss'])\n",
    "    final_results_night[\"fold_val_acc\"].append(history_hypo_night.history['val_accuracy'])\n",
    "    final_results_night[\"fold_val_loss\"].append(history_hypo_night.history['val_loss'])\n",
    "    final_results_night[\"conf_matrix\"].append(conf_matrix)\n",
    "    final_results_night[\"class_report\"].append(class_report)\n",
    "    final_results_night[\"fold_model\"].append(model)\n",
    "          \n",
    "# Calculate and print average and std across folds\n",
    "print(f'\\nAverage Train Accuracy: {np.mean(final_results_night[\"train_acc\"]):.4f} (+- {np.std(final_results_night[\"train_acc\"]):.4f})')\n",
    "print(f'Average Validation Accuracy: {np.mean(final_results_night[\"val_acc\"]):.4f} (+- {np.std(final_results_night[\"val_acc\"]):.4f})')\n",
    "print(f'Average Test Accuracy: {np.mean(final_results_night[\"accuracy_scores\"]):.4f} (+- {np.std(final_results_night[\"accuracy_scores\"]):.4f})')\n",
    "print(f'Average Test Recall: {np.mean(final_results_night[\"recall_scores\"]):.4f} (+- {np.std(final_results_night[\"recall_scores\"]):.4f})')\n",
    "print(f'Average Test Precision: {np.mean(final_results_night[\"precision_scores\"]):.4f} (+- {np.std(final_results_night[\"precision_scores\"]):.4f})')\n",
    "print(f'Average Test Specificity: {np.mean(final_results_night[\"specificity_scores\"]):.4f} (+- {np.std(final_results_night[\"specificity_scores\"]):.4f})')\n",
    "print(f'Average Test AUC: {np.mean(final_results_night[\"roc_auc_scores\"]):.4f} (+- {np.std(final_results_night[\"roc_auc_scores\"]):.4f})')\n",
    "print(f'Average Test F1: {np.mean(final_results_night[\"f1_scores\"]):.4f} (+- {np.std(final_results_night[\"f1_scores\"]):.4f})')\n",
    "\n",
    "max_epochs = max(len(fold) for fold in final_results_night[\"fold_val_loss\"])\n",
    "# Initialize arrays to store average and std dev for each epoch\n",
    "avg_loss = np.zeros(max_epochs)\n",
    "std_loss = np.zeros(max_epochs)\n",
    "avg_acc = np.zeros(max_epochs)\n",
    "std_acc = np.zeros(max_epochs)\n",
    "# Compute average and standard deviation for each epoch\n",
    "for epoch in range(max_epochs):\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    for fold_loss, fold_acc in zip(final_results_night[\"fold_val_loss\"], final_results_night[\"fold_val_acc\"]):\n",
    "        if epoch < len(fold_loss):\n",
    "            losses.append(fold_loss[epoch])\n",
    "        if epoch < len(fold_acc):\n",
    "            accuracies.append(fold_acc[epoch])\n",
    "    \n",
    "    if losses:\n",
    "        avg_loss[epoch] = np.mean(losses)\n",
    "        std_loss[epoch] = np.std(losses)\n",
    "    if accuracies:\n",
    "        avg_acc[epoch] = np.mean(accuracies)\n",
    "        std_acc[epoch] = np.std(accuracies)\n",
    "# Plot average loss and accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, max_epochs + 1), avg_loss, color='blue', label='Validation Loss')\n",
    "plt.fill_between(range(1, max_epochs + 1), \n",
    "                 avg_loss - std_loss,\n",
    "                 avg_loss + std_loss,\n",
    "                 color='blue', alpha=0.2)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Validation Loss per Epoch')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, max_epochs + 1), avg_acc, color='blue', label='Validation Accuracy')\n",
    "plt.fill_between(range(1, max_epochs + 1), \n",
    "                 avg_acc - std_acc,\n",
    "                 avg_acc + std_acc,\n",
    "                 color='blue', alpha=0.2)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Validation Accuracy per Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(folder_name, 'loss_accuracy_plot.png'))\n",
    "plt.show()\n",
    "\n",
    "########################################################################################################################################\n",
    "print(f\"Aggregated Models on holdout set ... \\n\")\n",
    "\n",
    "# Train-test split based on indices\n",
    "X_matrices_coeffs_holdout = X_matrices_power_scaled[holdout_idx]\n",
    "X_features_daily_holdout = X_features_daily_imputed[holdout_idx]\n",
    "X_features_individual_holdout = X_features_individual_imputed[holdout_idx]\n",
    "y_label_holdout = y_labels['hypo_night'][holdout_idx]\n",
    "mask_daily_holdout = mask_daily[holdout_idx]\n",
    "mask_individual_holdout = mask_individual[holdout_idx]\n",
    "\n",
    "# Initialize arrays to store predictions from each fold\n",
    "y_pred_holdout_agg = np.zeros((len(holdout_idx),))  # Assuming binary classification\n",
    "# Aggregate predictions from each fold model\n",
    "for model in final_results_night[\"fold_model\"]:\n",
    "    y_pred_holdout_fold = model.predict([X_matrices_coeffs_holdout, X_features_daily_holdout, X_features_individual_holdout, mask_daily_holdout, mask_individual_holdout])\n",
    "    y_pred_holdout_agg += y_pred_holdout_fold.flatten()  # Accumulate predictions\n",
    "    y_pred_holdout_avg = np.mean(y_pred_holdout_fold, axis=0)\n",
    "# Average the predictions from all folds\n",
    "y_pred_holdout_agg /= num_splits\n",
    "\n",
    "mae_holdout = mean_absolute_error(y_label_holdout, y_pred_holdout_agg)\n",
    "mse_holdout = mean_squared_error(y_label_holdout, y_pred_holdout_agg)\n",
    "roc_auc = roc_auc_score(y_label_holdout, y_pred_holdout_agg)\n",
    "print(f'Holdout ROC AUC: {roc_auc:.4f}')\n",
    "\n",
    "y_pred_holdout_binary_agg = (y_pred_holdout_agg >= 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "recall = recall_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "precision = precision_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "f1 = f1_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "specificity = recall_score(y_label_holdout, y_pred_holdout_binary_agg, pos_label=0)\n",
    "\n",
    "print(f'Holdout Accuracy: {accuracy:.4f}')\n",
    "print(f'Holdout MAE: {mae_test:.4f}')\n",
    "print(f'Holdout Percision: {precision:.4f}')\n",
    "print(f'Holdout Specificity: {specificity:.4f}')\n",
    "print(f'Holdout Sensitivity(Recall): {recall:.4f}')\n",
    "print(f'Holdout F1: {f1:.4f} \\n')\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(conf_matrix, cmap='Blues', interpolation='nearest')\n",
    "plt.title('Confusion Matrix for Final Model')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        plt.text(j, i, conf_matrix[i, j], \n",
    "                 ha='center', va='center', color='black', fontsize=14)\n",
    "plt.savefig(os.path.join(folder_name, 'conf_matrix_plot.png'))\n",
    "plt.show()\n",
    "\n",
    "description_path = os.path.join(folder_name, 'Description.txt')\n",
    "with open(description_path, 'w') as f:\n",
    "    f.write(\"\"\"\n",
    "    # K_Fold 3-channel _Smooth _Below70 Hypo, input w/ Masking, Daily & Individual input, Classifying Hypo Night\n",
    "    \"\"\")\n",
    "        # Write the results\n",
    "    f.write(f'\\nAverage Train Accuracy: {np.mean(final_results_night[\"train_acc\"]):.4f} (+- {np.std(final_results_night[\"train_acc\"]):.4f})\\n')\n",
    "    f.write(f'Average Validation Accuracy: {np.mean(final_results_night[\"val_acc\"]):.4f} (+- {np.std(final_results_night[\"val_acc\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Accuracy: {np.mean(final_results_night[\"accuracy_scores\"]):.4f} (+- {np.std(final_results_night[\"accuracy_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Recall: {np.mean(final_results_night[\"recall_scores\"]):.4f} (+- {np.std(final_results_night[\"recall_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Precision: {np.mean(final_results_night[\"precision_scores\"]):.4f} (+- {np.std(final_results_night[\"precision_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Specificity: {np.mean(final_results_night[\"specificity_scores\"]):.4f} (+- {np.std(final_results_night[\"specificity_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test AUC: {np.mean(final_results_night[\"roc_auc_scores\"]):.4f} (+- {np.std(final_results_night[\"roc_auc_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test F1: {np.mean(final_results_night[\"f1_scores\"]):.4f} (+- {np.std(final_results_night[\"f1_scores\"]):.4f})\\n')\n",
    "    \n",
    "    # Writing holdout results\n",
    "    f.write(f'Holdout ROC AUC: {roc_auc:.4f}\\n')\n",
    "    f.write(f'Holdout Accuracy: {accuracy:.4f}\\n')\n",
    "    f.write(f'Holdout MAE: {mae_test:.4f}\\n')\n",
    "    f.write(f'Holdout Precision: {precision:.4f}\\n')\n",
    "    f.write(f'Holdout Specificity: {specificity:.4f}\\n')\n",
    "    f.write(f'Holdout Sensitivity (Recall): {recall:.4f}\\n')\n",
    "    f.write(f'Holdout F1: {f1:.4f}\\n')\n",
    "model_summary_path = os.path.join(folder_name, 'model_summary.txt')\n",
    "with open(model_summary_path, 'w') as f:\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "#model.summary()\n",
    "# Save the final results as pickle\n",
    "final_results_path = os.path.join(folder_name, 'final_results.pkl')\n",
    "with open(final_results_path, 'wb') as file:\n",
    "    pickle.dump(final_results_night, file)\n",
    "\n",
    "print(\"\\nBest 3 models (ROC AUC) to prdict holdout:\")\n",
    "best_of = 3\n",
    "top_3_model_indices = np.argsort(final_results_night[\"roc_auc_scores\"])[-best_of:][::-1]\n",
    "y_pred_holdout_agg = np.zeros((len(holdout_idx),))  # Assuming binary classification\n",
    "for idx in top_3_model_indices:\n",
    "    model = final_results_night[\"fold_model\"][idx]\n",
    "    y_pred_holdout_fold = model.predict([X_matrices_coeffs_holdout, X_features_daily_holdout, X_features_individual_holdout, mask_daily_holdout, mask_individual_holdout])\n",
    "    y_pred_holdout_agg += y_pred_holdout_fold.flatten()\n",
    "y_pred_holdout_agg /= best_of\n",
    "\n",
    "mae_holdout = mean_absolute_error(y_label_holdout, y_pred_holdout_agg)\n",
    "mse_holdout = mean_squared_error(y_label_holdout, y_pred_holdout_agg)\n",
    "roc_auc = roc_auc_score(y_label_holdout, y_pred_holdout_agg)\n",
    "print(f'Holdout ROC AUC: {roc_auc:.4f}')\n",
    "\n",
    "y_pred_holdout_binary_agg = (y_pred_holdout_agg >= 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "recall = recall_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "precision = precision_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "f1 = f1_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "specificity = recall_score(y_label_holdout, y_pred_holdout_binary_agg, pos_label=0)\n",
    "\n",
    "print(f'Holdout Accuracy: {accuracy:.4f}')\n",
    "print(f'Holdout MAE: {mae_test:.4f}')\n",
    "print(f'Holdout Percision: {precision:.4f}')\n",
    "print(f'Holdout Specificity: {specificity:.4f}')\n",
    "print(f'Holdout Sensitivity(Recall): {recall:.4f}')\n",
    "print(f'Holdout F1: {f1:.4f} \\n')\n",
    "conf_matrix = confusion_matrix(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "conf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5fdf9c6-0324-4fc7-8fbf-886d886bb942",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 1...\n",
      "351, 69, 46, participants in Train, Validation, and Test sets\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 00:08:50.854788: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m907/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - AUC: 0.8141 - accuracy: 0.7369 - loss: 1.8511"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 00:09:09.036735: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:09.061279: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:09.071561: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:09.079277: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:09.080911: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:09.114675: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:09.124614: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:09.127007: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:09.137631: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:09.164215: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:09.194650: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:09.211350: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:09.212675: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:09.214703: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:09.223049: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:09.223695: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:09.266847: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:09.275245: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:09.284444: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:10.656913: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:10.669450: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:10.682840: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:10.683466: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:10.694855: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:10.712731: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:10.734999: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:10.735114: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:10.735183: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:10.739507: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:10.743435: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:10.767773: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:10.792569: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:10.795274: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:10.803022: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:10.830013: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:10.844952: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:10.850472: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:10.854124: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:10.860438: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:10.870322: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:10.885940: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:10.888654: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:10.893046: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:10.895924: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:10.904943: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:10.949451: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:13.345995: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:13.347709: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:13.362394: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:13.364621: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:13.369022: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:13.374234: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:13.381770: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:13.381913: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:13.382425: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:13.406735: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:13.413022: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:13.417705: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:13.426823: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:13.431432: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:13.433816: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:13.442674: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:13.459418: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:13.483096: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:13.484027: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:13.491534: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:13.492998: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:13.505762: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:13.518840: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:13.537980: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:13.548304: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:13.565772: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:16.218729: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:16.220387: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:16.230447: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:16.242617: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:16.243244: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:16.250448: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:16.251472: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:16.253732: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:16.255318: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:16.256800: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:16.268305: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:16.271912: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:16.279262: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:16.289834: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:16.297659: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:16.308557: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:16.317994: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:16.344737: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:16.348292: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:16.350806: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:16.357439: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:16.359113: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:16.361460: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:16.366575: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:16.394729: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:16.420969: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:19.049864: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:19.087999: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:19.095395: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:19.095596: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:19.095916: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:19.109286: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:19.126747: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:19.136115: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:19.144197: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:19.155487: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:19.169274: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:19.182511: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:19.184299: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:19.185409: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:19.185930: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:19.186433: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:19.192599: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:19.212474: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:19.221038: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:19.335915: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:21.311078: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:21.327442: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:21.350007: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:21.351799: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:21.356169: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:21.365266: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:21.369844: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:21.377444: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:21.403647: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:21.413721: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:21.428268: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:21.439147: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:21.443616: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:21.445171: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:21.447810: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:21.454139: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:21.472593: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:21.472703: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:21.487646: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:21.508150: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:23.454902: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:23.458504: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:23.468986: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:23.478677: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:23.479942: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:23.483836: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:23.489899: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:23.492420: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:23.504543: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:23.521520: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:23.532968: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:23.546948: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:23.562020: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:23.562558: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:23.569837: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:23.582130: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:23.593002: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:23.595949: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:23.600828: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:23.605040: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:23.605418: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:23.605611: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:23.667040: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:25.564654: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:25.573856: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:25.575578: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:25.581814: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:25.587028: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:25.588605: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:25.589442: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:25.594388: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:25.597313: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:25.601246: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:25.604994: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:25.624335: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:25.627514: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:25.637279: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:25.645260: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:25.659425: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:25.664771: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:25.693062: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:25.695504: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:25.695745: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:25.697819: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:25.700865: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:25.713215: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:25.713844: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:25.760269: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:25.833210: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:28.389759: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:28.397767: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:28.398665: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:28.414610: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:28.421293: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:28.422216: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:28.425692: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:28.426698: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:28.426838: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:28.435825: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:28.436297: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:28.453977: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:28.462794: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:28.471341: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:28.478754: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:28.479451: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:28.492951: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:28.507199: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:28.507248: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:28.525866: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:28.534060: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:28.539588: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:28.544470: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:28.576096: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:28.593447: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:28.627632: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:30.798661: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:30.800757: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:30.809013: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:30.815750: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:30.826590: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:30.836760: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:30.839335: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:30.859984: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:30.863710: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:30.874348: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:30.892792: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:30.900236: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:30.910359: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:30.919903: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:30.933315: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:30.937171: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:30.947298: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:30.959485: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:30.960517: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:30.971128: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:30.994203: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:31.002492: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:31.004272: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:32.845570: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:32.856763: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:32.884773: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:32.886943: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:32.898153: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:32.908318: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:32.929353: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:32.930854: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:32.932278: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:32.941862: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:32.972390: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:32.977396: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:32.979223: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:32.986114: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:32.988807: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:32.998689: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:33.030746: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:33.035088: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:33.059479: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:33.064234: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:34.785379: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:34.790513: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:34.797152: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:34.810962: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:34.816618: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:34.821954: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:34.823351: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:34.848164: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:34.850816: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:34.857815: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:34.868304: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:34.868376: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:34.886985: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:34.887803: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:34.896016: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:34.911693: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:34.919577: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:34.933381: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:34.934551: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:34.940514: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:34.983063: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:34.990880: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:35.002167: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:36.880109: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:36.883216: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:36.889107: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:36.893712: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:36.903929: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:36.909380: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:36.909656: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:36.920252: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:36.923909: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:36.928899: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:36.936712: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:36.939510: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:36.943530: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:36.950585: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:36.960832: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:36.979749: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:36.986681: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:36.997023: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:36.998562: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:37.010102: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:37.017015: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:37.028283: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:37.032849: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:37.033592: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:37.034683: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:37.198370: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:39.331224: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:39.339795: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:39.340845: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:39.355671: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:39.368052: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:39.368365: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:39.374711: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:39.377753: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:39.384023: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:39.388521: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:39.390491: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:39.392194: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:39.398050: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:39.401006: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:39.414806: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:39.424642: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:39.432508: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:39.440488: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:39.467244: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:39.469909: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:39.478683: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:39.487441: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:39.487782: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:39.496643: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:39.525202: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:39.546082: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:41.627093: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:41.642907: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:41.646849: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:41.656746: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:41.658464: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:41.664626: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:41.676396: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:41.676668: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:41.678827: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:41.681959: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:41.685138: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:41.691235: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:41.693684: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:41.701931: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:41.714745: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:41.719943: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:41.752145: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:41.761568: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:41.771298: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:41.782940: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:41.791832: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:41.797558: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:41.797789: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:41.797996: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:41.816057: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:41.881463: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:44.482724: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:44.483044: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:44.490890: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:44.500440: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:44.511145: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:44.511190: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:44.511490: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:44.512166: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:44.516301: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:44.522616: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:44.524011: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:44.524172: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:44.526071: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:44.543414: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:44.563765: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:44.569835: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:44.572876: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:44.595268: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:44.601930: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:44.602872: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:44.613942: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:44.623546: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:44.625076: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:44.637717: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:44.644057: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:44.665720: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:47.372101: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:47.382982: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:47.389821: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:47.411124: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:47.414838: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:47.414868: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:47.425185: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:47.441473: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:47.456774: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:47.463500: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:47.464629: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:47.468306: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:47.471915: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:47.475568: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:47.478463: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:47.478930: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:47.510727: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:47.516716: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:47.561028: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:48.978763: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:48.983662: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:49.001513: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:49.002277: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:49.006627: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:49.009972: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:49.016210: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:49.032349: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:49.037919: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:49.047776: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:49.050439: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:49.051686: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:49.072990: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:49.075091: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:49.081625: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:49.116561: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:49.120958: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:49.122598: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:49.126411: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:49.129284: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:49.184564: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:49.188922: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:49.193661: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:09:56.328095: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - AUC: 0.8143 - accuracy: 0.7372 - loss: 1.8496"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 00:10:03.757897: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:03.767927: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:03.770006: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:03.777220: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:03.784617: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:03.793323: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:03.795702: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:03.827533: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:03.837258: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:03.841924: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:03.842200: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:03.843165: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:03.850791: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:03.856671: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:03.858602: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:03.862749: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:03.897761: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:03.898080: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:03.901980: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:03.905635: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:03.907693: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:03.911076: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:03.911254: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:03.926214: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:03.932412: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:03.946126: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:03.964469: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:04.004540: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:07.723207: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:10.825319: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:10.826977: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:10.864148: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:10.869078: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:10.869110: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:10.869208: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:10.870271: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:10.883704: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:10.890880: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:10.898885: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:10.904167: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:10.945403: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:10.952691: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:10.954906: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:10.964179: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:10.975256: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:11.007563: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:11.035946: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:11.061474: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:11.087689: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:12.491653: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:12.492352: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:12.500585: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:12.503861: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:12.503939: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:12.510199: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:12.523356: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:12.533696: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:12.534769: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:12.546492: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:12.554440: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:12.558321: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:12.611265: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:12.625428: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:12.669030: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:12.678363: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:12.685234: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:12.688276: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:12.692733: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:12.696676: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:12.703741: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:12.703909: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:12.712067: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:12.712953: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:12.725177: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:12.743437: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:12.747313: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:15.027431: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:15.038226: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:15.062931: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:15.066421: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:15.084748: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:15.094758: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:15.099671: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:15.099814: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:15.113268: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:15.116898: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:15.120326: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:15.127833: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:15.130614: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:15.143519: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:15.150196: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:15.156344: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:15.157453: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:15.162093: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:15.164961: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:15.168738: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:15.169474: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:15.174857: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:15.180206: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:15.193828: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:15.205477: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:15.221203: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:15.254723: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:17.801502: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:17.802190: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:17.812266: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:17.814487: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:17.817096: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:17.822972: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:17.828482: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:17.830289: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:17.838537: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:17.841307: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:17.855105: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:17.866745: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:17.881767: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:17.892322: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:17.894672: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:17.899895: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:17.901107: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:17.904524: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:17.916666: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:17.931781: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:17.953634: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:17.993257: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:18.008898: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:18.012520: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:18.015398: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:18.016948: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:18.040009: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:20.678405: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:20.697955: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:20.716338: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:20.723584: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:20.726495: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:20.726579: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:20.737528: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:20.776436: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:20.784040: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:20.785402: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:20.797886: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:20.811227: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:20.815134: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:20.823796: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:20.837974: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:20.844997: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:20.854134: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:20.873043: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:20.892824: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:20.956435: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:20.981691: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:22.918276: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:22.930840: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:22.949674: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:22.951155: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:22.955545: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:22.967658: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:22.977209: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:22.984527: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:23.008687: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:23.014683: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:23.030342: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:23.031465: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:23.038582: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:23.070521: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:23.070587: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:23.073926: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:23.082298: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:23.087907: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:23.113726: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:23.142619: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:23.168108: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:25.066037: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:25.067840: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:25.070087: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:25.079888: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:25.089872: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:25.094339: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:25.103962: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:25.117373: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:25.121061: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:25.129442: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:25.158231: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:25.161491: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:25.175837: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:25.197120: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:25.202289: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:25.207311: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:25.207593: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:25.210355: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:25.213796: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:25.216124: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:25.219733: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:25.226648: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:25.295243: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:25.322812: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:27.171483: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:27.174826: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:27.181970: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:27.183792: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:27.184901: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:27.188816: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:27.192413: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:27.194065: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:27.197610: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:27.198846: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:27.200043: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:27.216081: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:27.225062: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:27.226934: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:27.235871: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:27.238806: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:27.262133: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:27.265617: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:27.287414: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:27.296064: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:27.302975: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:27.309035: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:27.312447: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:27.332937: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:27.340734: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:27.356649: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:27.382902: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:29.961527: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:29.968600: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:29.969289: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:29.979900: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:29.985160: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:29.990790: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:29.995147: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:29.995385: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:29.996955: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:30.007126: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:30.009295: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:30.021363: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:30.030420: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:30.032686: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:30.037275: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:30.046653: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:30.050425: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:30.061703: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:30.074712: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:30.076783: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:30.100887: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:30.102552: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:30.105693: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:30.114036: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:30.148575: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:30.159900: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:30.188140: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:32.436947: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:32.440346: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:32.444656: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:32.454510: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:32.464601: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:32.466313: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:32.472099: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:32.491902: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:32.501724: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:32.503862: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:32.519554: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:32.520350: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:32.531825: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:32.544057: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:32.555946: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:32.583797: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:32.586137: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:32.590251: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:32.597053: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:32.630069: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:32.652390: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:32.657814: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:32.682732: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:32.709644: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-10-02 00:10:35.925816: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 113ms/step - AUC: 0.8145 - accuracy: 0.7373 - loss: 1.8489 - val_AUC: 0.9650 - val_accuracy: 0.9038 - val_loss: 0.5501 - learning_rate: 1.0000e-04\n",
      "Epoch 2/25\n",
      "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - AUC: 0.9799 - accuracy: 0.9349 - loss: 0.4503 - val_AUC: 0.9708 - val_accuracy: 0.9181 - val_loss: 0.4447 - learning_rate: 1.0000e-04\n",
      "Epoch 3/25\n",
      "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - AUC: 0.9889 - accuracy: 0.9535 - loss: 0.3451 - val_AUC: 0.9832 - val_accuracy: 0.9291 - val_loss: 0.3879 - learning_rate: 1.0000e-04\n",
      "Epoch 4/25\n",
      "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - AUC: 0.9904 - accuracy: 0.9483 - loss: 0.3391 - val_AUC: 0.9667 - val_accuracy: 0.8998 - val_loss: 0.4167 - learning_rate: 1.0000e-04\n",
      "Epoch 5/25\n",
      "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - AUC: 0.9519 - accuracy: 0.8385 - loss: 0.5026 - val_AUC: 0.8664 - val_accuracy: 0.5793 - val_loss: 0.7848 - learning_rate: 1.0000e-04\n",
      "Epoch 6/25\n",
      "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - AUC: 0.7589 - accuracy: 0.5826 - loss: 0.7550 - val_AUC: 0.8419 - val_accuracy: 0.5793 - val_loss: 0.7131 - learning_rate: 1.0000e-04\n",
      "Epoch 7/25\n",
      "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - AUC: 0.7378 - accuracy: 0.5790 - loss: 0.7210 - val_AUC: 0.8403 - val_accuracy: 0.5764 - val_loss: 0.6867 - learning_rate: 1.0000e-04\n",
      "Epoch 8/25\n",
      "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - AUC: 0.7375 - accuracy: 0.5777 - loss: 0.7042 - val_AUC: 0.8402 - val_accuracy: 0.5742 - val_loss: 0.6758 - learning_rate: 5.0000e-05\n",
      "Epoch 9/25\n",
      "\u001b[1m615/909\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - AUC: 0.7186 - accuracy: 0.5690 - loss: 0.7015"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 110\u001b[0m\n\u001b[1;32m    108\u001b[0m learning_rate_scheduler \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-7\u001b[39m)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# Model training and evaluation\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m history_hypo_early_night \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_matrices_coeffs_train_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_features_daily_train_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_features_individual_train_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_daily_train_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_individual_train_resampled\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43my_label_train_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_matrices_coeffs_val_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_features_daily_val_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_features_individual_val_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_daily_val_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_individual_val_resampled\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_label_val_resampled\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate_scheduler\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Evaluate training and testing performance\u001b[39;00m\n\u001b[1;32m    116\u001b[0m train_score \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate([X_matrices_coeffs_train_resampled, X_features_daily_train_resampled, X_features_individual_train_resampled, mask_daily_train_resampled, mask_individual_train_resampled], \n\u001b[1;32m    117\u001b[0m                              y_label_train_resampled, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:876\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    874\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 876\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    880\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    881\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[1;32m     60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:55\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 55\u001b[0m       \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[1;32m     60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:209\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    207\u001b[0m overload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__tf_tensor__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m overload \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 209\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moverload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m#  pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m base_type, conversion_func \u001b[38;5;129;01min\u001b[39;00m get(\u001b[38;5;28mtype\u001b[39m(value)):\n\u001b[1;32m    212\u001b[0m   \u001b[38;5;66;03m# If dtype is None but preferred_dtype is not None, we try to\u001b[39;00m\n\u001b[1;32m    213\u001b[0m   \u001b[38;5;66;03m# cast to preferred_dtype first.\u001b[39;00m\n\u001b[1;32m    214\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:584\u001b[0m, in \u001b[0;36m_EagerTensorBase.__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__tf_tensor__\u001b[39m(\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28mself\u001b[39m, dtype: Optional[dtypes\u001b[38;5;241m.\u001b[39mDType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, name: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    583\u001b[0m     ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tensor_lib\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 584\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecuting_eagerly\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    585\u001b[0m     graph \u001b[38;5;241m=\u001b[39m get_default_graph()\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mbuilding_function:\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/context.py:2330\u001b[0m, in \u001b[0;36mexecuting_eagerly\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2328\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m default_execution_mode \u001b[38;5;241m==\u001b[39m EAGER_MODE\n\u001b[0;32m-> 2330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecuting_eagerly\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1014\u001b[0m, in \u001b[0;36mContext.executing_eagerly\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecuting_eagerly\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns True if current thread has eager executing enabled.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1014\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thread_local_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_eager\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run garbage collection\n",
    "gc.collect()\n",
    "################# ORIGINAL 70 K_Fold 3-channel input w/ Masking, Daily & Individual input, Classifying Hypo early_night\n",
    "########################################################################################################################################\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "folder_name = \"/home/ma98/Compressed_DEXI_Data/Hypo_70_Original/Hypo_Early_Night\"\n",
    "matrix_shape0 = 288\n",
    "# Reshape matrices to the required shapes\n",
    "X_features_daily_imputed = np.nan_to_num(X_features_daily_scaled, nan=0.0)\n",
    "X_features_individual_imputed = np.nan_to_num(X_features_individual_scaled, nan=0.0)\n",
    "\n",
    "# Create masks for missing values\n",
    "mask_daily = np.isfinite(X_features_daily_scaled).astype(np.float32)\n",
    "mask_individual = np.isfinite(X_features_individual_scaled).astype(np.float32)\n",
    "\n",
    "# Initialize GroupKFold\n",
    "num_splits = 4\n",
    "group_kfold = GroupKFold(n_splits=num_splits)\n",
    "unique_participants = np.unique(participant_ids)\n",
    "# # Shuffle to ensure no artifacts in test train/validation split\n",
    "# unique_participants = shuffle(unique_participants, random_state=42)\n",
    "\n",
    "# Completely hold out a test set before cross-validation\n",
    "holdout_participants = unique_participants[int(0.95 * len(unique_participants)):]\n",
    "holdout_idx = np.where(np.isin(participant_ids, holdout_participants))[0]\n",
    "\n",
    "# Remove the holdout participants from the pool used for cross-validation model\n",
    "model_participants = unique_participants[:int(0.95 * len(unique_participants))]\n",
    "\n",
    "final_results_early_night = {\n",
    "    \"fold_model\": [],\n",
    "    \"specificity_scores\": [],\n",
    "    \"accuracy_scores\": [],\n",
    "    \"precision_scores\": [],\n",
    "    \"recall_scores\": [],\n",
    "    \"f1_scores\": [],\n",
    "    \"roc_auc_scores\": [],\n",
    "    \"mae\": [],\n",
    "    \"mse\": [],\n",
    "    \"fold_train_loss\": [],\n",
    "    \"fold_train_acc\": [],\n",
    "    \"fold_val_loss\": [],\n",
    "    \"fold_val_acc\": [],\n",
    "    \"conf_matrix\": [],\n",
    "    \"class_report\": [],\n",
    "    \"train_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_acc\": []\n",
    "}\n",
    "# # Enable mixed precision\n",
    "# keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "for fold, (train_idx, val_test_idx) in enumerate(group_kfold.split(X_matrices_power_scaled, y_labels['hypo_early_night'], groups=participant_ids)):\n",
    "    # 75% of the data as train set\n",
    "    train_participants = model_participants[np.isin(model_participants, participant_ids[train_idx])]\n",
    "    # train_participants = shuffle(train_participants, random_state=42)  # Shuffle train participants\n",
    "    \n",
    "    # Randomly shuffle and Split remaining data into validation and test based on participants\n",
    "    val_test_participants = model_participants[np.isin(model_participants, participant_ids[val_test_idx])]\n",
    "    # val_test_participants = shuffle(val_test_participants, random_state=42)  # Shuffle val_test participants\n",
    "    \n",
    "    val_size = int(len(val_test_participants) * 3 / 5)\n",
    "    val_participants = val_test_participants[:val_size]\n",
    "    test_participants = val_test_participants[val_size:]\n",
    "    \n",
    "    # Get corresponding indices\n",
    "    val_idx = np.where(np.isin(participant_ids, val_participants))[0]\n",
    "    test_idx = np.where(np.isin(participant_ids, test_participants))[0]\n",
    "    print(f\"Processing fold {fold + 1}...\")\n",
    "    print(f\"{len(train_participants)}, {len(val_participants)}, {len(test_participants)}, participants in Train, Validation, and Test sets\" )\n",
    "\n",
    "    # Train-test split based on indices\n",
    "    X_matrices_coeffs_train,X_matrices_coeffs_val, X_matrices_coeffs_test = X_matrices_power_scaled[train_idx],X_matrices_power_scaled[val_idx], X_matrices_power_scaled[test_idx]\n",
    "    X_features_daily_train,X_features_daily_val, X_features_daily_test = X_features_daily_imputed[train_idx],X_features_daily_imputed[val_idx], X_features_daily_imputed[test_idx]\n",
    "    X_features_individual_train,X_features_individual_val, X_features_individual_test = X_features_individual_imputed[train_idx],X_features_individual_imputed[val_idx], X_features_individual_imputed[test_idx]\n",
    "    y_label_train,y_label_val, y_label_test = y_labels['hypo_early_night'][train_idx],y_labels['hypo_early_night'][val_idx], y_labels['hypo_early_night'][test_idx]\n",
    "    mask_daily_train,mask_daily_val, mask_daily_test = mask_daily[train_idx], mask_daily[val_idx], mask_daily[test_idx]\n",
    "    mask_individual_train,mask_individual_val, mask_individual_test = mask_individual[train_idx],mask_individual[val_idx], mask_individual[test_idx]\n",
    "\n",
    "    # Resample training data\n",
    "    X_matrices_coeffs_train_resampled, X_features_daily_train_resampled, \\\n",
    "    X_features_individual_train_resampled, mask_daily_train_resampled, \\\n",
    "    mask_individual_train_resampled, y_label_train_resampled = apply_smote_resampling_mask(\n",
    "        X_matrices_coeffs_train,\n",
    "        X_features_daily_train,\n",
    "        X_features_individual_train,\n",
    "        mask_daily_train,\n",
    "        mask_individual_train,\n",
    "        y_label_train, matrix_shape0=matrix_shape0\n",
    "    )\n",
    "    # Resample Validation data\n",
    "    X_matrices_coeffs_val_resampled, X_features_daily_val_resampled, \\\n",
    "    X_features_individual_val_resampled, mask_daily_val_resampled, \\\n",
    "    mask_individual_val_resampled, y_label_val_resampled = apply_smote_resampling_mask(\n",
    "        X_matrices_coeffs_val,\n",
    "        X_features_daily_val,\n",
    "        X_features_individual_val,\n",
    "        mask_daily_val,\n",
    "        mask_individual_val,\n",
    "        y_label_val, matrix_shape0=matrix_shape0\n",
    "    )\n",
    "    num_epochs = 25\n",
    "    # Create a new model instance\n",
    "    model = create_model()\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    # checkpoint = ModelCheckpoint(filepath=os.path.join(folder_name, 'best_model_fold_{}.keras'.format(fold)), monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "    learning_rate_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-7)\n",
    "    # Model training and evaluation\n",
    "    history_hypo_early_night = model.fit([X_matrices_coeffs_train_resampled, X_features_daily_train_resampled, X_features_individual_train_resampled, mask_daily_train_resampled, mask_individual_train_resampled], \n",
    "                                         y_label_train_resampled, \n",
    "                                         epochs=num_epochs, batch_size=16, verbose=1,\n",
    "                                         validation_data=([X_matrices_coeffs_val_resampled, X_features_daily_val_resampled, X_features_individual_val_resampled, mask_daily_val_resampled, mask_individual_val_resampled], y_label_val_resampled),\n",
    "                                         callbacks=[early_stopping, learning_rate_scheduler])\n",
    "    # Evaluate training and testing performance\n",
    "    train_score = model.evaluate([X_matrices_coeffs_train_resampled, X_features_daily_train_resampled, X_features_individual_train_resampled, mask_daily_train_resampled, mask_individual_train_resampled], \n",
    "                                 y_label_train_resampled, verbose=0)\n",
    "    val_score = model.evaluate([X_matrices_coeffs_val_resampled, X_features_daily_val_resampled, X_features_individual_val_resampled, mask_daily_val_resampled, mask_individual_val_resampled], \n",
    "                                y_label_val_resampled, verbose=0)\n",
    "    print('\\nTrain loss: {}, Train accuracy: {}'.format(train_score[0], train_score[1]))\n",
    "    print('Validation loss: {}, Validation accuracy: {}'.format(val_score[0], val_score[1]))\n",
    "    # print('Test loss: {}, Test accuracy: {}\\n'.format(test_score[0], test_score[1]))\n",
    "    y_pred_train = model.predict([X_matrices_coeffs_train, X_features_daily_train,X_features_individual_train, mask_daily_train, mask_individual_train])\n",
    "    y_pred_test = model.predict([X_matrices_coeffs_test, X_features_daily_test,X_features_individual_test, mask_daily_test, mask_individual_test])\n",
    "\n",
    "    mae_train = mean_absolute_error(y_label_train, y_pred_train)\n",
    "    mse_train = mean_squared_error(y_label_train, y_pred_train)\n",
    "\n",
    "    roc_auc_test = roc_auc_score(y_label_test, y_pred_test)\n",
    "    print(f'Test ROC AUC: {roc_auc_test:.4f}')\n",
    "\n",
    "    y_pred_train_binary = (y_pred_train >= 0.5).astype(int)\n",
    "    y_pred_test_binary = (y_pred_test >= 0.2).astype(int)\n",
    "    mae_test = mean_absolute_error(y_label_test, y_pred_test)\n",
    "    mse_test = mean_squared_error(y_label_test, y_pred_test)\n",
    "    accuracy = accuracy_score(y_label_test, y_pred_test_binary)\n",
    "    recall = recall_score(y_label_test, y_pred_test_binary)\n",
    "    f1 = f1_score(y_label_test, y_pred_test_binary)\n",
    "    precision = precision_score(y_label_test, y_pred_test_binary)\n",
    "    specificity = recall_score(y_label_test, y_pred_test_binary, pos_label=0)\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    print(f'Test MAE: {mae_test:.4f}')\n",
    "    print(f'Test Percision: {precision:.4f}')\n",
    "    print(f'Test Specificity: {specificity:.4f}')\n",
    "    print(f'Test Sensitivity(Recall): {recall:.4f}')\n",
    "    print(f'Test F1: {f1:.4f} \\n')\n",
    "    print(f'Fold {fold + 1} - AUC: {roc_auc_test:.4f}, Accuracy: {accuracy:.4f}, Recall: {recall:.4f}, Precision: {precision:.4f}, Specificity: {specificity:.4f}, F1: {f1:.4f}\\n')\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_label_test, y_pred_test_binary)\n",
    "    # Classification Report\n",
    "    class_report = classification_report(y_label_test, y_pred_test_binary)\n",
    "    print(conf_matrix)\n",
    "    final_results_early_night[\"precision_scores\"].append(precision)\n",
    "    final_results_early_night[\"recall_scores\"].append(recall)\n",
    "    final_results_early_night[\"f1_scores\"].append(f1)\n",
    "    final_results_early_night[\"accuracy_scores\"].append(accuracy)\n",
    "    final_results_early_night[\"roc_auc_scores\"].append(roc_auc_test)\n",
    "    final_results_early_night[\"specificity_scores\"].append(specificity)\n",
    "    final_results_early_night[\"mae\"].append(mae_test)\n",
    "    final_results_early_night[\"mse\"].append(mse_test)\n",
    "    final_results_early_night[\"train_loss\"].append(train_score[0])\n",
    "    final_results_early_night[\"train_acc\"].append(train_score[1])\n",
    "    final_results_early_night[\"val_loss\"].append(val_score[0])\n",
    "    final_results_early_night[\"val_acc\"].append(val_score[1])\n",
    "    final_results_early_night[\"fold_train_acc\"].append(history_hypo_early_night.history['accuracy'])\n",
    "    final_results_early_night[\"fold_train_loss\"].append(history_hypo_early_night.history['loss'])\n",
    "    final_results_early_night[\"fold_val_acc\"].append(history_hypo_early_night.history['val_accuracy'])\n",
    "    final_results_early_night[\"fold_val_loss\"].append(history_hypo_early_night.history['val_loss'])\n",
    "    final_results_early_night[\"conf_matrix\"].append(conf_matrix)\n",
    "    final_results_early_night[\"class_report\"].append(class_report)\n",
    "    final_results_early_night[\"fold_model\"].append(model)\n",
    "          \n",
    "# Calculate and print average and std across folds\n",
    "print(f'\\nAverage Train Accuracy: {np.mean(final_results_early_night[\"train_acc\"]):.4f} (+- {np.std(final_results_early_night[\"train_acc\"]):.4f})')\n",
    "print(f'Average Validation Accuracy: {np.mean(final_results_early_night[\"val_acc\"]):.4f} (+- {np.std(final_results_early_night[\"val_acc\"]):.4f})')\n",
    "print(f'Average Test Accuracy: {np.mean(final_results_early_night[\"accuracy_scores\"]):.4f} (+- {np.std(final_results_early_night[\"accuracy_scores\"]):.4f})')\n",
    "print(f'Average Test Recall: {np.mean(final_results_early_night[\"recall_scores\"]):.4f} (+- {np.std(final_results_early_night[\"recall_scores\"]):.4f})')\n",
    "print(f'Average Test Precision: {np.mean(final_results_early_night[\"precision_scores\"]):.4f} (+- {np.std(final_results_early_night[\"precision_scores\"]):.4f})')\n",
    "print(f'Average Test Specificity: {np.mean(final_results_early_night[\"specificity_scores\"]):.4f} (+- {np.std(final_results_early_night[\"specificity_scores\"]):.4f})')\n",
    "print(f'Average Test AUC: {np.mean(final_results_early_night[\"roc_auc_scores\"]):.4f} (+- {np.std(final_results_early_night[\"roc_auc_scores\"]):.4f})')\n",
    "print(f'Average Test F1: {np.mean(final_results_early_night[\"f1_scores\"]):.4f} (+- {np.std(final_results_early_night[\"f1_scores\"]):.4f})')\n",
    "\n",
    "max_epochs = max(len(fold) for fold in final_results_early_night[\"fold_val_loss\"])\n",
    "# Initialize arrays to store average and std dev for each epoch\n",
    "avg_loss = np.zeros(max_epochs)\n",
    "std_loss = np.zeros(max_epochs)\n",
    "avg_acc = np.zeros(max_epochs)\n",
    "std_acc = np.zeros(max_epochs)\n",
    "# Compute average and standard deviation for each epoch\n",
    "for epoch in range(max_epochs):\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    for fold_loss, fold_acc in zip(final_results_early_night[\"fold_val_loss\"], final_results_early_night[\"fold_val_acc\"]):\n",
    "        if epoch < len(fold_loss):\n",
    "            losses.append(fold_loss[epoch])\n",
    "        if epoch < len(fold_acc):\n",
    "            accuracies.append(fold_acc[epoch])\n",
    "    \n",
    "    if losses:\n",
    "        avg_loss[epoch] = np.mean(losses)\n",
    "        std_loss[epoch] = np.std(losses)\n",
    "    if accuracies:\n",
    "        avg_acc[epoch] = np.mean(accuracies)\n",
    "        std_acc[epoch] = np.std(accuracies)\n",
    "# Plot average loss and accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, max_epochs + 1), avg_loss, color='blue', label='Validation Loss')\n",
    "plt.fill_between(range(1, max_epochs + 1), \n",
    "                 avg_loss - std_loss,\n",
    "                 avg_loss + std_loss,\n",
    "                 color='blue', alpha=0.2)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Validation Loss per Epoch')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, max_epochs + 1), avg_acc, color='blue', label='Validation Accuracy')\n",
    "plt.fill_between(range(1, max_epochs + 1), \n",
    "                 avg_acc - std_acc,\n",
    "                 avg_acc + std_acc,\n",
    "                 color='blue', alpha=0.2)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Validation Accuracy per Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(folder_name, 'loss_accuracy_plot.png'))\n",
    "plt.show()\n",
    "\n",
    "########################################################################################################################################\n",
    "print(f\"Aggregated Models on holdout set ... \\n\")\n",
    "\n",
    "# Train-test split based on indices\n",
    "X_matrices_coeffs_holdout = X_matrices_power_scaled[holdout_idx]\n",
    "X_features_daily_holdout = X_features_daily_imputed[holdout_idx]\n",
    "X_features_individual_holdout = X_features_individual_imputed[holdout_idx]\n",
    "y_label_holdout = y_labels['hypo_early_night'][holdout_idx]\n",
    "mask_daily_holdout = mask_daily[holdout_idx]\n",
    "mask_individual_holdout = mask_individual[holdout_idx]\n",
    "\n",
    "# Initialize arrays to store predictions from each fold\n",
    "y_pred_holdout_agg = np.zeros((len(holdout_idx),))  # Assuming binary classification\n",
    "# Aggregate predictions from each fold model\n",
    "for model in final_results_early_night[\"fold_model\"]:\n",
    "    y_pred_holdout_fold = model.predict([X_matrices_coeffs_holdout, X_features_daily_holdout, X_features_individual_holdout, mask_daily_holdout, mask_individual_holdout])\n",
    "    y_pred_holdout_agg += y_pred_holdout_fold.flatten()  # Accumulate predictions\n",
    "# Average the predictions from all folds\n",
    "y_pred_holdout_agg /= num_splits\n",
    "\n",
    "mae_holdout = mean_absolute_error(y_label_holdout, y_pred_holdout_agg)\n",
    "mse_holdout = mean_squared_error(y_label_holdout, y_pred_holdout_agg)\n",
    "roc_auc = roc_auc_score(y_label_holdout, y_pred_holdout_agg)\n",
    "print(f'Holdout ROC AUC: {roc_auc:.4f}')\n",
    "\n",
    "y_pred_holdout_binary_agg = (y_pred_holdout_agg >= 0.4).astype(int)\n",
    "accuracy = accuracy_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "recall = recall_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "precision = precision_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "f1 = f1_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "specificity = recall_score(y_label_holdout, y_pred_holdout_binary_agg, pos_label=0)\n",
    "\n",
    "print(f'Holdout Accuracy: {accuracy:.4f}')\n",
    "print(f'Holdout MAE: {mae_test:.4f}')\n",
    "print(f'Holdout Percision: {precision:.4f}')\n",
    "print(f'Holdout Specificity: {specificity:.4f}')\n",
    "print(f'Holdout Sensitivity(Recall): {recall:.4f}')\n",
    "print(f'Holdout F1: {f1:.4f} \\n')\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(conf_matrix, cmap='Blues', interpolation='nearest')\n",
    "plt.title('Confusion Matrix for Final Model')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        plt.text(j, i, conf_matrix[i, j], \n",
    "                 ha='center', va='center', color='black', fontsize=14)\n",
    "plt.savefig(os.path.join(folder_name, 'holdout_conf_matrix_plot.png'))\n",
    "plt.show()\n",
    "\n",
    "description_path = os.path.join(folder_name, 'Description.txt')\n",
    "with open(description_path, 'w') as f:\n",
    "    f.write(\"\"\"\n",
    "    # K_Fold 3-channel _ORIGINAL _Below70 Hypo Early Night, input w/ Masking, Daily & Individual input, Classifying Hypo Early Night\n",
    "    \"\"\")\n",
    "        # Write the results\n",
    "    f.write(f'\\nAverage Train Accuracy: {np.mean(final_results_early_night[\"train_acc\"]):.4f} (+- {np.std(final_results_early_night[\"train_acc\"]):.4f})\\n')\n",
    "    f.write(f'Average Validation Accuracy: {np.mean(final_results_early_night[\"val_acc\"]):.4f} (+- {np.std(final_results_early_night[\"val_acc\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Accuracy: {np.mean(final_results_early_night[\"accuracy_scores\"]):.4f} (+- {np.std(final_results_early_night[\"accuracy_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Recall: {np.mean(final_results_early_night[\"recall_scores\"]):.4f} (+- {np.std(final_results_early_night[\"recall_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Precision: {np.mean(final_results_early_night[\"precision_scores\"]):.4f} (+- {np.std(final_results_early_night[\"precision_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Specificity: {np.mean(final_results_early_night[\"specificity_scores\"]):.4f} (+- {np.std(final_results_early_night[\"specificity_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test AUC: {np.mean(final_results_early_night[\"roc_auc_scores\"]):.4f} (+- {np.std(final_results_early_night[\"roc_auc_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test F1: {np.mean(final_results_early_night[\"f1_scores\"]):.4f} (+- {np.std(final_results_early_night[\"f1_scores\"]):.4f})\\n')\n",
    "    \n",
    "    # Writing holdout results\n",
    "    f.write(f'Holdout ROC AUC: {roc_auc:.4f}\\n')\n",
    "    f.write(f'Holdout Accuracy: {accuracy:.4f}\\n')\n",
    "    f.write(f'Holdout MAE: {mae_test:.4f}\\n')\n",
    "    f.write(f'Holdout Precision: {precision:.4f}\\n')\n",
    "    f.write(f'Holdout Specificity: {specificity:.4f}\\n')\n",
    "    f.write(f'Holdout Sensitivity (Recall): {recall:.4f}\\n')\n",
    "    f.write(f'Holdout F1: {f1:.4f}\\n')\n",
    "model_summary_path = os.path.join(folder_name, 'model_summary.txt')\n",
    "with open(model_summary_path, 'w') as f:\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "\n",
    "# Save the final results as pickle\n",
    "final_results_path = os.path.join(folder_name, 'final_results.pkl')\n",
    "with open(final_results_path, 'wb') as file:\n",
    "    pickle.dump(final_results_early_night, file)\n",
    "\n",
    "print(\"\\nBest 3 models (ROC AUC) to prdict holdout:\")\n",
    "best_of = 3\n",
    "top_3_model_indices = np.argsort(final_results_early_night[\"roc_auc_scores\"])[-best_of:][::-1]\n",
    "y_pred_holdout_agg = np.zeros((len(holdout_idx),))  # Assuming binary classification\n",
    "for idx in top_3_model_indices:\n",
    "    model = final_results_early_night[\"fold_model\"][idx]\n",
    "    y_pred_holdout_fold = model.predict([X_matrices_coeffs_holdout, X_features_daily_holdout, X_features_individual_holdout, mask_daily_holdout, mask_individual_holdout])\n",
    "    y_pred_holdout_agg += y_pred_holdout_fold.flatten()\n",
    "y_pred_holdout_agg /= best_of\n",
    "\n",
    "mae_holdout = mean_absolute_error(y_label_holdout, y_pred_holdout_agg)\n",
    "mse_holdout = mean_squared_error(y_label_holdout, y_pred_holdout_agg)\n",
    "roc_auc = roc_auc_score(y_label_holdout, y_pred_holdout_agg)\n",
    "print(f'Holdout ROC AUC: {roc_auc:.4f}')\n",
    "\n",
    "y_pred_holdout_binary_agg = (y_pred_holdout_agg >= 0.4).astype(int)\n",
    "accuracy = accuracy_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "recall = recall_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "precision = precision_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "f1 = f1_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "specificity = recall_score(y_label_holdout, y_pred_holdout_binary_agg, pos_label=0)\n",
    "\n",
    "print(f'Holdout Accuracy: {accuracy:.4f}')\n",
    "print(f'Holdout MAE: {mae_test:.4f}')\n",
    "print(f'Holdout Percision: {precision:.4f}')\n",
    "print(f'Holdout Specificity: {specificity:.4f}')\n",
    "print(f'Holdout Sensitivity(Recall): {recall:.4f}')\n",
    "print(f'Holdout F1: {f1:.4f} \\n')\n",
    "conf_matrix = confusion_matrix(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "conf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68a9c1a-9812-4527-87c3-7dafcab398ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 1...\n",
      "351, 69, 46, participants in Train, Validation, and Test sets\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m923/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - AUC: 0.7527 - accuracy: 0.6830 - loss: 1.9786"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - AUC: 0.7529 - accuracy: 0.6832 - loss: 1.9773"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 34ms/step - AUC: 0.7530 - accuracy: 0.6833 - loss: 1.9767 - val_AUC: 0.9610 - val_accuracy: 0.9087 - val_loss: 0.6803 - learning_rate: 1.0000e-04\n",
      "Epoch 2/25\n",
      "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - AUC: 0.9642 - accuracy: 0.9098 - loss: 0.6105 - val_AUC: 0.9780 - val_accuracy: 0.9313 - val_loss: 0.4411 - learning_rate: 1.0000e-04\n",
      "Epoch 3/25\n",
      "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step - AUC: 0.9810 - accuracy: 0.9388 - loss: 0.3912 - val_AUC: 0.9789 - val_accuracy: 0.9342 - val_loss: 0.3783 - learning_rate: 1.0000e-04\n",
      "Epoch 4/25\n",
      "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step - AUC: 0.9897 - accuracy: 0.9548 - loss: 0.2982 - val_AUC: 0.9760 - val_accuracy: 0.9393 - val_loss: 0.3510 - learning_rate: 1.0000e-04\n",
      "Epoch 5/25\n",
      "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step - AUC: 0.9921 - accuracy: 0.9634 - loss: 0.2555 - val_AUC: 0.9730 - val_accuracy: 0.9389 - val_loss: 0.3650 - learning_rate: 1.0000e-04\n",
      "Epoch 6/25\n",
      "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step - AUC: 0.9946 - accuracy: 0.9686 - loss: 0.2221 - val_AUC: 0.9702 - val_accuracy: 0.9321 - val_loss: 0.3830 - learning_rate: 1.0000e-04\n",
      "Epoch 7/25\n",
      "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step - AUC: 0.9975 - accuracy: 0.9820 - loss: 0.1781 - val_AUC: 0.9656 - val_accuracy: 0.9306 - val_loss: 0.4244 - learning_rate: 5.0000e-05\n",
      "Epoch 8/25\n",
      "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 16ms/step - AUC: 0.9984 - accuracy: 0.9882 - loss: 0.1594 - val_AUC: 0.9651 - val_accuracy: 0.9303 - val_loss: 0.4672 - learning_rate: 5.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-02 02:15:40.528245: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-02 02:15:46.650216: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "2024-10-02 02:15:54.254867: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.23586449027061462, Train accuracy: 0.9715348482131958\n",
      "Validation loss: 0.3509770333766937, Validation accuracy: 0.9392523169517517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m247/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step\n",
      "\u001b[1m30/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n",
      "warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
      "Test ROC AUC: 0.8148\n",
      "Test Accuracy: 0.9010\n",
      "Test MAE: 0.1090\n",
      "Test Percision: 0.4078\n",
      "Test Specificity: 0.9343\n",
      "Test Sensitivity(Recall): 0.5185\n",
      "Test F1: 0.4565 \n",
      "\n",
      "Fold 1 - AUC: 0.8148, Accuracy: 0.9010, Recall: 0.5185, Precision: 0.4078, Specificity: 0.9343, F1: 0.4565\n",
      "\n",
      "[[868  61]\n",
      " [ 39  42]]\n",
      "Processing fold 2...\n",
      "349, 70, 47, participants in Train, Validation, and Test sets\n"
     ]
    }
   ],
   "source": [
    "# Run garbage collection\n",
    "gc.collect()\n",
    "################# ORIGINAL 70 K_Fold 3-channel input w/ Masking, Daily & Individual input, Classifying Hypo Late Night\n",
    "########################################################################################################################################\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "folder_name = \"/home/ma98/Compressed_DEXI_Data/Hypo_70_Original/Hypo_Late_Night\"\n",
    "matrix_shape0 = 288\n",
    "# Reshape matrices to the required shapes\n",
    "X_features_daily_imputed = np.nan_to_num(X_features_daily_scaled, nan=0.0)\n",
    "X_features_individual_imputed = np.nan_to_num(X_features_individual_scaled, nan=0.0)\n",
    "\n",
    "# Create masks for missing values\n",
    "mask_daily = np.isfinite(X_features_daily_scaled).astype(np.float32)\n",
    "mask_individual = np.isfinite(X_features_individual_scaled).astype(np.float32)\n",
    "\n",
    "# Initialize GroupKFold\n",
    "num_splits = 4\n",
    "group_kfold = GroupKFold(n_splits=num_splits)\n",
    "unique_participants = np.unique(participant_ids)\n",
    "# # Shuffle to ensure no artifacts in test train/validation split\n",
    "# unique_participants = shuffle(unique_participants, random_state=42)\n",
    "\n",
    "# Completely hold out a test set before cross-validation\n",
    "holdout_participants = unique_participants[int(0.95 * len(unique_participants)):]\n",
    "holdout_idx = np.where(np.isin(participant_ids, holdout_participants))[0]\n",
    "\n",
    "# Remove the holdout participants from the pool used for cross-validation model\n",
    "model_participants = unique_participants[:int(0.95 * len(unique_participants))]\n",
    "\n",
    "final_results_late_night = {\n",
    "    \"fold_model\": [],\n",
    "    \"specificity_scores\": [],\n",
    "    \"accuracy_scores\": [],\n",
    "    \"precision_scores\": [],\n",
    "    \"recall_scores\": [],\n",
    "    \"f1_scores\": [],\n",
    "    \"roc_auc_scores\": [],\n",
    "    \"mae\": [],\n",
    "    \"mse\": [],\n",
    "    \"fold_train_loss\": [],\n",
    "    \"fold_train_acc\": [],\n",
    "    \"fold_val_loss\": [],\n",
    "    \"fold_val_acc\": [],\n",
    "    \"conf_matrix\": [],\n",
    "    \"class_report\": [],\n",
    "    \"train_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_acc\": []\n",
    "}\n",
    "for fold, (train_idx, val_test_idx) in enumerate(group_kfold.split(X_matrices_power_scaled, y_labels['hypo_late_night'], groups=participant_ids)):\n",
    "    # 75% of the data as train set\n",
    "    train_participants = model_participants[np.isin(model_participants, participant_ids[train_idx])]\n",
    "    # train_participants = shuffle(train_participants, random_state=42)  # Shuffle train participants\n",
    "    \n",
    "    # Randomly shuffle and Split remaining data into validation and test based on participants\n",
    "    val_test_participants = model_participants[np.isin(model_participants, participant_ids[val_test_idx])]\n",
    "    # val_test_participants = shuffle(val_test_participants, random_state=42)  # Shuffle val_test participants\n",
    "    \n",
    "    val_size = int(len(val_test_participants) * 3 / 5)\n",
    "    val_participants = val_test_participants[:val_size]\n",
    "    test_participants = val_test_participants[val_size:]\n",
    "    \n",
    "    # Get corresponding indices\n",
    "    val_idx = np.where(np.isin(participant_ids, val_participants))[0]\n",
    "    test_idx = np.where(np.isin(participant_ids, test_participants))[0]\n",
    "    print(f\"Processing fold {fold + 1}...\")\n",
    "    print(f\"{len(train_participants)}, {len(val_participants)}, {len(test_participants)}, participants in Train, Validation, and Test sets\" )\n",
    "\n",
    "    # Train-test split based on indices\n",
    "    X_matrices_coeffs_train,X_matrices_coeffs_val, X_matrices_coeffs_test = X_matrices_power_scaled[train_idx],X_matrices_power_scaled[val_idx], X_matrices_power_scaled[test_idx]\n",
    "    X_features_daily_train,X_features_daily_val, X_features_daily_test = X_features_daily_imputed[train_idx],X_features_daily_imputed[val_idx], X_features_daily_imputed[test_idx]\n",
    "    X_features_individual_train,X_features_individual_val, X_features_individual_test = X_features_individual_imputed[train_idx],X_features_individual_imputed[val_idx], X_features_individual_imputed[test_idx]\n",
    "    y_label_train,y_label_val, y_label_test = y_labels['hypo_late_night'][train_idx],y_labels['hypo_late_night'][val_idx], y_labels['hypo_late_night'][test_idx]\n",
    "    mask_daily_train,mask_daily_val, mask_daily_test = mask_daily[train_idx], mask_daily[val_idx], mask_daily[test_idx]\n",
    "    mask_individual_train,mask_individual_val, mask_individual_test = mask_individual[train_idx],mask_individual[val_idx], mask_individual[test_idx]\n",
    "\n",
    "    # Resample training data\n",
    "    X_matrices_coeffs_train_resampled, X_features_daily_train_resampled, \\\n",
    "    X_features_individual_train_resampled, mask_daily_train_resampled, \\\n",
    "    mask_individual_train_resampled, y_label_train_resampled = apply_smote_resampling_mask(\n",
    "        X_matrices_coeffs_train,\n",
    "        X_features_daily_train,\n",
    "        X_features_individual_train,\n",
    "        mask_daily_train,\n",
    "        mask_individual_train,\n",
    "        y_label_train, matrix_shape0=matrix_shape0\n",
    "    )\n",
    "    # Resample Validation data\n",
    "    X_matrices_coeffs_val_resampled, X_features_daily_val_resampled, \\\n",
    "    X_features_individual_val_resampled, mask_daily_val_resampled, \\\n",
    "    mask_individual_val_resampled, y_label_val_resampled = apply_smote_resampling_mask(\n",
    "        X_matrices_coeffs_val,\n",
    "        X_features_daily_val,\n",
    "        X_features_individual_val,\n",
    "        mask_daily_val,\n",
    "        mask_individual_val,\n",
    "        y_label_val, matrix_shape0=matrix_shape0\n",
    "    )\n",
    "    num_epochs = 25\n",
    "    # Create a new model instance\n",
    "    model = create_model()\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "    # checkpoint = ModelCheckpoint(filepath=os.path.join(folder_name, 'best_model_fold_{}.keras'.format(fold)), monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "    learning_rate_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-7)\n",
    "    # Model training and evaluation\n",
    "    history_hypo_late_night = model.fit([X_matrices_coeffs_train_resampled, X_features_daily_train_resampled, X_features_individual_train_resampled, mask_daily_train_resampled, mask_individual_train_resampled], \n",
    "                                         y_label_train_resampled, \n",
    "                                         epochs=num_epochs, batch_size=16, verbose=1,\n",
    "                                         validation_data=([X_matrices_coeffs_val_resampled, X_features_daily_val_resampled, X_features_individual_val_resampled, mask_daily_val_resampled, mask_individual_val_resampled], y_label_val_resampled),\n",
    "                                         callbacks=[early_stopping, learning_rate_scheduler])\n",
    "    # Evaluate training and testing performance\n",
    "    train_score = model.evaluate([X_matrices_coeffs_train_resampled, X_features_daily_train_resampled, X_features_individual_train_resampled, mask_daily_train_resampled, mask_individual_train_resampled], \n",
    "                                 y_label_train_resampled, verbose=0)\n",
    "    val_score = model.evaluate([X_matrices_coeffs_val_resampled, X_features_daily_val_resampled, X_features_individual_val_resampled, mask_daily_val_resampled, mask_individual_val_resampled], \n",
    "                                y_label_val_resampled, verbose=0)\n",
    "    print('\\nTrain loss: {}, Train accuracy: {}'.format(train_score[0], train_score[1]))\n",
    "    print('Validation loss: {}, Validation accuracy: {}'.format(val_score[0], val_score[1]))\n",
    "    # print('Test loss: {}, Test accuracy: {}\\n'.format(test_score[0], test_score[1]))\n",
    "    y_pred_train = model.predict([X_matrices_coeffs_train, X_features_daily_train,X_features_individual_train, mask_daily_train, mask_individual_train])\n",
    "    y_pred_test = model.predict([X_matrices_coeffs_test, X_features_daily_test,X_features_individual_test, mask_daily_test, mask_individual_test])\n",
    "\n",
    "    mae_train = mean_absolute_error(y_label_train, y_pred_train)\n",
    "    mse_train = mean_squared_error(y_label_train, y_pred_train)\n",
    "\n",
    "    roc_auc_test = roc_auc_score(y_label_test, y_pred_test)\n",
    "    print(f'Test ROC AUC: {roc_auc_test:.4f}')\n",
    "\n",
    "    y_pred_train_binary = (y_pred_train >= 0.5).astype(int)\n",
    "    y_pred_test_binary = (y_pred_test >= 0.2).astype(int)\n",
    "    mae_test = mean_absolute_error(y_label_test, y_pred_test)\n",
    "    mse_test = mean_squared_error(y_label_test, y_pred_test)\n",
    "    accuracy = accuracy_score(y_label_test, y_pred_test_binary)\n",
    "    recall = recall_score(y_label_test, y_pred_test_binary)\n",
    "    f1 = f1_score(y_label_test, y_pred_test_binary)\n",
    "    precision = precision_score(y_label_test, y_pred_test_binary)\n",
    "    specificity = recall_score(y_label_test, y_pred_test_binary, pos_label=0)\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    print(f'Test MAE: {mae_test:.4f}')\n",
    "    print(f'Test Percision: {precision:.4f}')\n",
    "    print(f'Test Specificity: {specificity:.4f}')\n",
    "    print(f'Test Sensitivity(Recall): {recall:.4f}')\n",
    "    print(f'Test F1: {f1:.4f} \\n')\n",
    "    print(f'Fold {fold + 1} - AUC: {roc_auc_test:.4f}, Accuracy: {accuracy:.4f}, Recall: {recall:.4f}, Precision: {precision:.4f}, Specificity: {specificity:.4f}, F1: {f1:.4f}\\n')\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_label_test, y_pred_test_binary)\n",
    "    # Classification Report\n",
    "    class_report = classification_report(y_label_test, y_pred_test_binary)\n",
    "    print(conf_matrix)\n",
    "    final_results_late_night[\"precision_scores\"].append(precision)\n",
    "    final_results_late_night[\"recall_scores\"].append(recall)\n",
    "    final_results_late_night[\"f1_scores\"].append(f1)\n",
    "    final_results_late_night[\"accuracy_scores\"].append(accuracy)\n",
    "    final_results_late_night[\"roc_auc_scores\"].append(roc_auc_test)\n",
    "    final_results_late_night[\"specificity_scores\"].append(specificity)\n",
    "    final_results_late_night[\"mae\"].append(mae_test)\n",
    "    final_results_late_night[\"mse\"].append(mse_test)\n",
    "    final_results_late_night[\"train_loss\"].append(train_score[0])\n",
    "    final_results_late_night[\"train_acc\"].append(train_score[1])\n",
    "    final_results_late_night[\"val_loss\"].append(val_score[0])\n",
    "    final_results_late_night[\"val_acc\"].append(val_score[1])\n",
    "    final_results_late_night[\"fold_train_acc\"].append(history_hypo_late_night.history['accuracy'])\n",
    "    final_results_late_night[\"fold_train_loss\"].append(history_hypo_late_night.history['loss'])\n",
    "    final_results_late_night[\"fold_val_acc\"].append(history_hypo_late_night.history['val_accuracy'])\n",
    "    final_results_late_night[\"fold_val_loss\"].append(history_hypo_late_night.history['val_loss'])\n",
    "    final_results_late_night[\"conf_matrix\"].append(conf_matrix)\n",
    "    final_results_late_night[\"class_report\"].append(class_report)\n",
    "    final_results_late_night[\"fold_model\"].append(model)\n",
    "          \n",
    "# Calculate and print average and std across folds\n",
    "print(f'\\nAverage Train Accuracy: {np.mean(final_results_late_night[\"train_acc\"]):.4f} (+- {np.std(final_results_late_night[\"train_acc\"]):.4f})')\n",
    "print(f'Average Validation Accuracy: {np.mean(final_results_late_night[\"val_acc\"]):.4f} (+- {np.std(final_results_late_night[\"val_acc\"]):.4f})')\n",
    "print(f'Average Test Accuracy: {np.mean(final_results_late_night[\"accuracy_scores\"]):.4f} (+- {np.std(final_results_late_night[\"accuracy_scores\"]):.4f})')\n",
    "print(f'Average Test Recall: {np.mean(final_results_late_night[\"recall_scores\"]):.4f} (+- {np.std(final_results_late_night[\"recall_scores\"]):.4f})')\n",
    "print(f'Average Test Precision: {np.mean(final_results_late_night[\"precision_scores\"]):.4f} (+- {np.std(final_results_late_night[\"precision_scores\"]):.4f})')\n",
    "print(f'Average Test Specificity: {np.mean(final_results_late_night[\"specificity_scores\"]):.4f} (+- {np.std(final_results_late_night[\"specificity_scores\"]):.4f})')\n",
    "print(f'Average Test AUC: {np.mean(final_results_late_night[\"roc_auc_scores\"]):.4f} (+- {np.std(final_results_late_night[\"roc_auc_scores\"]):.4f})')\n",
    "print(f'Average Test F1: {np.mean(final_results_late_night[\"f1_scores\"]):.4f} (+- {np.std(final_results_late_night[\"f1_scores\"]):.4f})')\n",
    "\n",
    "max_epochs = max(len(fold) for fold in final_results_late_night[\"fold_val_loss\"])\n",
    "# Initialize arrays to store average and std dev for each epoch\n",
    "avg_loss = np.zeros(max_epochs)\n",
    "std_loss = np.zeros(max_epochs)\n",
    "avg_acc = np.zeros(max_epochs)\n",
    "std_acc = np.zeros(max_epochs)\n",
    "# Compute average and standard deviation for each epoch\n",
    "for epoch in range(max_epochs):\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    for fold_loss, fold_acc in zip(final_results_late_night[\"fold_val_loss\"], final_results_late_night[\"fold_val_acc\"]):\n",
    "        if epoch < len(fold_loss):\n",
    "            losses.append(fold_loss[epoch])\n",
    "        if epoch < len(fold_acc):\n",
    "            accuracies.append(fold_acc[epoch])\n",
    "    \n",
    "    if losses:\n",
    "        avg_loss[epoch] = np.mean(losses)\n",
    "        std_loss[epoch] = np.std(losses)\n",
    "    if accuracies:\n",
    "        avg_acc[epoch] = np.mean(accuracies)\n",
    "        std_acc[epoch] = np.std(accuracies)\n",
    "# Plot average loss and accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, max_epochs + 1), avg_loss, color='blue', label='Validation Loss')\n",
    "plt.fill_between(range(1, max_epochs + 1), \n",
    "                 avg_loss - std_loss,\n",
    "                 avg_loss + std_loss,\n",
    "                 color='blue', alpha=0.2)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Validation Loss per Epoch')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, max_epochs + 1), avg_acc, color='blue', label='Validation Accuracy')\n",
    "plt.fill_between(range(1, max_epochs + 1), \n",
    "                 avg_acc - std_acc,\n",
    "                 avg_acc + std_acc,\n",
    "                 color='blue', alpha=0.2)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Validation Accuracy per Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(folder_name, 'loss_accuracy_plot.png'))\n",
    "plt.show()\n",
    "\n",
    "########################################################################################################################################\n",
    "print(f\"Aggregated Models on holdout set ... \\n\")\n",
    "\n",
    "# Train-test split based on indices\n",
    "X_matrices_coeffs_holdout = X_matrices_power_scaled[holdout_idx]\n",
    "X_features_daily_holdout = X_features_daily_imputed[holdout_idx]\n",
    "X_features_individual_holdout = X_features_individual_imputed[holdout_idx]\n",
    "y_label_holdout = y_labels['hypo_late_night'][holdout_idx]\n",
    "mask_daily_holdout = mask_daily[holdout_idx]\n",
    "mask_individual_holdout = mask_individual[holdout_idx]\n",
    "\n",
    "# Initialize arrays to store predictions from each fold\n",
    "y_pred_holdout_agg = np.zeros((len(holdout_idx),))  # Assuming binary classification\n",
    "# Aggregate predictions from each fold model\n",
    "for model in final_results_late_night[\"fold_model\"]:\n",
    "    y_pred_holdout_fold = model.predict([X_matrices_coeffs_holdout, X_features_daily_holdout, X_features_individual_holdout, mask_daily_holdout, mask_individual_holdout])\n",
    "    y_pred_holdout_agg += y_pred_holdout_fold.flatten()  # Accumulate predictions\n",
    "# Average the predictions from all folds\n",
    "y_pred_holdout_agg /= num_splits\n",
    "\n",
    "mae_holdout = mean_absolute_error(y_label_holdout, y_pred_holdout_agg)\n",
    "mse_holdout = mean_squared_error(y_label_holdout, y_pred_holdout_agg)\n",
    "roc_auc = roc_auc_score(y_label_holdout, y_pred_holdout_agg)\n",
    "print(f'Holdout ROC AUC: {roc_auc:.4f}')\n",
    "\n",
    "y_pred_holdout_binary_agg = (y_pred_holdout_agg >= 0.4).astype(int)\n",
    "accuracy = accuracy_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "recall = recall_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "precision = precision_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "f1 = f1_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "specificity = recall_score(y_label_holdout, y_pred_holdout_binary_agg, pos_label=0)\n",
    "\n",
    "print(f'Holdout Accuracy: {accuracy:.4f}')\n",
    "print(f'Holdout MAE: {mae_test:.4f}')\n",
    "print(f'Holdout Percision: {precision:.4f}')\n",
    "print(f'Holdout Specificity: {specificity:.4f}')\n",
    "print(f'Holdout Sensitivity(Recall): {recall:.4f}')\n",
    "print(f'Holdout F1: {f1:.4f} \\n')\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(conf_matrix, cmap='Blues', interpolation='nearest')\n",
    "plt.title('Confusion Matrix for Final Model')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        plt.text(j, i, conf_matrix[i, j], \n",
    "                 ha='center', va='center', color='black', fontsize=14)\n",
    "plt.savefig(os.path.join(folder_name, 'holdout_conf_matrix_plot.png'))\n",
    "plt.show()\n",
    "\n",
    "description_path = os.path.join(folder_name, 'Description.txt')\n",
    "with open(description_path, 'w') as f:\n",
    "    f.write(\"\"\"\n",
    "    # K_Fold 3-channel _ORIGINAL _Below70 Hypo Late Night, input w/ Masking, Daily & Individual input, Classifying Hypo Late Night\n",
    "    \"\"\")\n",
    "        # Write the results\n",
    "    f.write(f'\\nAverage Train Accuracy: {np.mean(final_results_late_night[\"train_acc\"]):.4f} (+- {np.std(final_results_late_night[\"train_acc\"]):.4f})\\n')\n",
    "    f.write(f'Average Validation Accuracy: {np.mean(final_results_late_night[\"val_acc\"]):.4f} (+- {np.std(final_results_late_night[\"val_acc\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Accuracy: {np.mean(final_results_late_night[\"accuracy_scores\"]):.4f} (+- {np.std(final_results_late_night[\"accuracy_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Recall: {np.mean(final_results_late_night[\"recall_scores\"]):.4f} (+- {np.std(final_results_late_night[\"recall_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Precision: {np.mean(final_results_late_night[\"precision_scores\"]):.4f} (+- {np.std(final_results_late_night[\"precision_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Specificity: {np.mean(final_results_late_night[\"specificity_scores\"]):.4f} (+- {np.std(final_results_late_night[\"specificity_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test AUC: {np.mean(final_results_late_night[\"roc_auc_scores\"]):.4f} (+- {np.std(final_results_late_night[\"roc_auc_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test F1: {np.mean(final_results_late_night[\"f1_scores\"]):.4f} (+- {np.std(final_results_late_night[\"f1_scores\"]):.4f})\\n')\n",
    "    \n",
    "    # Writing holdout results\n",
    "    f.write(f'Holdout ROC AUC: {roc_auc:.4f}\\n')\n",
    "    f.write(f'Holdout Accuracy: {accuracy:.4f}\\n')\n",
    "    f.write(f'Holdout MAE: {mae_test:.4f}\\n')\n",
    "    f.write(f'Holdout Precision: {precision:.4f}\\n')\n",
    "    f.write(f'Holdout Specificity: {specificity:.4f}\\n')\n",
    "    f.write(f'Holdout Sensitivity (Recall): {recall:.4f}\\n')\n",
    "    f.write(f'Holdout F1: {f1:.4f}\\n')\n",
    "model_summary_path = os.path.join(folder_name, 'model_summary.txt')\n",
    "with open(model_summary_path, 'w') as f:\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "#model.summary()\n",
    "# Save the final results as pickle\n",
    "final_results_path = os.path.join(folder_name, 'final_results.pkl')\n",
    "with open(final_results_path, 'wb') as file:\n",
    "    pickle.dump(final_results_late_night, file)\n",
    "\n",
    "print(\"\\nBest 3 models (ROC AUC) to prdict holdout:\")\n",
    "best_of = 3\n",
    "top_3_model_indices = np.argsort(final_results_late_night[\"roc_auc_scores\"])[-best_of:][::-1]\n",
    "y_pred_holdout_agg = np.zeros((len(holdout_idx),))  # Assuming binary classification\n",
    "for idx in top_3_model_indices:\n",
    "    model = final_results_late_night[\"fold_model\"][idx]\n",
    "    y_pred_holdout_fold = model.predict([X_matrices_coeffs_holdout, X_features_daily_holdout, X_features_individual_holdout, mask_daily_holdout, mask_individual_holdout])\n",
    "    y_pred_holdout_agg += y_pred_holdout_fold.flatten()\n",
    "y_pred_holdout_agg /= best_of\n",
    "\n",
    "mae_holdout = mean_absolute_error(y_label_holdout, y_pred_holdout_agg)\n",
    "mse_holdout = mean_squared_error(y_label_holdout, y_pred_holdout_agg)\n",
    "roc_auc = roc_auc_score(y_label_holdout, y_pred_holdout_agg)\n",
    "print(f'Holdout ROC AUC: {roc_auc:.4f}')\n",
    "\n",
    "y_pred_holdout_binary_agg = (y_pred_holdout_agg >= 0.4).astype(int)\n",
    "accuracy = accuracy_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "recall = recall_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "precision = precision_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "f1 = f1_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "specificity = recall_score(y_label_holdout, y_pred_holdout_binary_agg, pos_label=0)\n",
    "\n",
    "print(f'Holdout Accuracy: {accuracy:.4f}')\n",
    "print(f'Holdout MAE: {mae_test:.4f}')\n",
    "print(f'Holdout Percision: {precision:.4f}')\n",
    "print(f'Holdout Specificity: {specificity:.4f}')\n",
    "print(f'Holdout Sensitivity(Recall): {recall:.4f}')\n",
    "print(f'Holdout F1: {f1:.4f} \\n')\n",
    "conf_matrix = confusion_matrix(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "conf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce81fee-fd58-436e-9d23-9d7fb990717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# ORIGINAL 70 K_Fold 3-channel input w/ Masking, Daily & Individual input, Classifying Hypo night_morning\n",
    "########################################################################################################################################\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "folder_name = \"/home/ma98/Compressed_DEXI_Data/Hypo_70_Original/Hypo_Night_Morning\"\n",
    "matrix_shape0 = 288\n",
    "# Reshape matrices to the required shapes\n",
    "X_features_daily_imputed = np.nan_to_num(X_features_daily_scaled, nan=0.0)\n",
    "X_features_individual_imputed = np.nan_to_num(X_features_individual_scaled, nan=0.0)\n",
    "\n",
    "# Create masks for missing values\n",
    "mask_daily = np.isfinite(X_features_daily_scaled).astype(np.float32)\n",
    "mask_individual = np.isfinite(X_features_individual_scaled).astype(np.float32)\n",
    "\n",
    "# Initialize GroupKFold\n",
    "num_splits = 4\n",
    "group_kfold = GroupKFold(n_splits=num_splits)\n",
    "unique_participants = np.unique(participant_ids)\n",
    "# # Shuffle to ensure no artifacts in test train/validation split\n",
    "# unique_participants = shuffle(unique_participants, random_state=42)\n",
    "\n",
    "# Completely hold out a test set before cross-validation\n",
    "holdout_participants = unique_participants[int(0.95 * len(unique_participants)):]\n",
    "holdout_idx = np.where(np.isin(participant_ids, holdout_participants))[0]\n",
    "\n",
    "# Remove the holdout participants from the pool used for cross-validation model\n",
    "model_participants = unique_participants[:int(0.95 * len(unique_participants))]\n",
    "\n",
    "final_results_night_morning = {\n",
    "    \"fold_model\": [],\n",
    "    \"specificity_scores\": [],\n",
    "    \"accuracy_scores\": [],\n",
    "    \"precision_scores\": [],\n",
    "    \"recall_scores\": [],\n",
    "    \"f1_scores\": [],\n",
    "    \"roc_auc_scores\": [],\n",
    "    \"mae\": [],\n",
    "    \"mse\": [],\n",
    "    \"fold_train_loss\": [],\n",
    "    \"fold_train_acc\": [],\n",
    "    \"fold_val_loss\": [],\n",
    "    \"fold_val_acc\": [],\n",
    "    \"conf_matrix\": [],\n",
    "    \"class_report\": [],\n",
    "    \"train_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_acc\": []\n",
    "}\n",
    "for fold, (train_idx, val_test_idx) in enumerate(group_kfold.split(X_matrices_power_scaled, y_labels['hypo_night_morning'], groups=participant_ids)):\n",
    "    # 75% of the data as train set\n",
    "    train_participants = model_participants[np.isin(model_participants, participant_ids[train_idx])]\n",
    "    # train_participants = shuffle(train_participants, random_state=42)  # Shuffle train participants\n",
    "    \n",
    "    # Randomly shuffle and Split remaining data into validation and test based on participants\n",
    "    val_test_participants = model_participants[np.isin(model_participants, participant_ids[val_test_idx])]\n",
    "    # val_test_participants = shuffle(val_test_participants, random_state=42)  # Shuffle val_test participants\n",
    "    \n",
    "    val_size = int(len(val_test_participants) * 3 / 5)\n",
    "    val_participants = val_test_participants[:val_size]\n",
    "    test_participants = val_test_participants[val_size:]\n",
    "    \n",
    "    # Get corresponding indices\n",
    "    val_idx = np.where(np.isin(participant_ids, val_participants))[0]\n",
    "    test_idx = np.where(np.isin(participant_ids, test_participants))[0]\n",
    "    print(f\"Processing fold {fold + 1}...\")\n",
    "    print(f\"{len(train_participants)}, {len(val_participants)}, {len(test_participants)}, participants in Train, Validation, and Test sets\" )\n",
    "\n",
    "    # Train-test split based on indices\n",
    "    X_matrices_coeffs_train,X_matrices_coeffs_val, X_matrices_coeffs_test = X_matrices_power_scaled[train_idx],X_matrices_power_scaled[val_idx], X_matrices_power_scaled[test_idx]\n",
    "    X_features_daily_train,X_features_daily_val, X_features_daily_test = X_features_daily_imputed[train_idx],X_features_daily_imputed[val_idx], X_features_daily_imputed[test_idx]\n",
    "    X_features_individual_train,X_features_individual_val, X_features_individual_test = X_features_individual_imputed[train_idx],X_features_individual_imputed[val_idx], X_features_individual_imputed[test_idx]\n",
    "    y_label_train,y_label_val, y_label_test = y_labels['hypo_night_morning'][train_idx],y_labels['hypo_night_morning'][val_idx], y_labels['hypo_night_morning'][test_idx]\n",
    "    mask_daily_train,mask_daily_val, mask_daily_test = mask_daily[train_idx], mask_daily[val_idx], mask_daily[test_idx]\n",
    "    mask_individual_train,mask_individual_val, mask_individual_test = mask_individual[train_idx],mask_individual[val_idx], mask_individual[test_idx]\n",
    "\n",
    "    # Resample training data\n",
    "    X_matrices_coeffs_train_resampled, X_features_daily_train_resampled, \\\n",
    "    X_features_individual_train_resampled, mask_daily_train_resampled, \\\n",
    "    mask_individual_train_resampled, y_label_train_resampled = apply_smote_resampling_mask(\n",
    "        X_matrices_coeffs_train,\n",
    "        X_features_daily_train,\n",
    "        X_features_individual_train,\n",
    "        mask_daily_train,\n",
    "        mask_individual_train,\n",
    "        y_label_train, matrix_shape0=matrix_shape0\n",
    "    )\n",
    "    # Resample Validation data\n",
    "    X_matrices_coeffs_val_resampled, X_features_daily_val_resampled, \\\n",
    "    X_features_individual_val_resampled, mask_daily_val_resampled, \\\n",
    "    mask_individual_val_resampled, y_label_val_resampled = apply_smote_resampling_mask(\n",
    "        X_matrices_coeffs_val,\n",
    "        X_features_daily_val,\n",
    "        X_features_individual_val,\n",
    "        mask_daily_val,\n",
    "        mask_individual_val,\n",
    "        y_label_val, matrix_shape0=matrix_shape0\n",
    "    )\n",
    "    num_epochs = 25\n",
    "    # Create a new model instance\n",
    "    model = create_model()\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True)\n",
    "    # checkpoint = ModelCheckpoint(filepath=os.path.join(folder_name, 'best_model_fold_{}.keras'.format(fold)), monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "    learning_rate_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-7)\n",
    "    # Model training and evaluation\n",
    "    history_hypo_night_morning = model.fit([X_matrices_coeffs_train_resampled, X_features_daily_train_resampled, X_features_individual_train_resampled, mask_daily_train_resampled, mask_individual_train_resampled], \n",
    "                                         y_label_train_resampled, \n",
    "                                         epochs=num_epochs, batch_size=16, verbose=1,\n",
    "                                         validation_data=([X_matrices_coeffs_val_resampled, X_features_daily_val_resampled, X_features_individual_val_resampled, mask_daily_val_resampled, mask_individual_val_resampled], y_label_val_resampled),\n",
    "                                         callbacks=[early_stopping, learning_rate_scheduler])\n",
    "    # Evaluate training and testing performance\n",
    "    train_score = model.evaluate([X_matrices_coeffs_train_resampled, X_features_daily_train_resampled, X_features_individual_train_resampled, mask_daily_train_resampled, mask_individual_train_resampled], \n",
    "                                 y_label_train_resampled, verbose=0)\n",
    "    val_score = model.evaluate([X_matrices_coeffs_val_resampled, X_features_daily_val_resampled, X_features_individual_val_resampled, mask_daily_val_resampled, mask_individual_val_resampled], \n",
    "                                y_label_val_resampled, verbose=0)\n",
    "    print('\\nTrain loss: {}, Train accuracy: {}'.format(train_score[0], train_score[1]))\n",
    "    print('Validation loss: {}, Validation accuracy: {}'.format(val_score[0], val_score[1]))\n",
    "    # print('Test loss: {}, Test accuracy: {}\\n'.format(test_score[0], test_score[1]))\n",
    "    y_pred_train = model.predict([X_matrices_coeffs_train, X_features_daily_train,X_features_individual_train, mask_daily_train, mask_individual_train])\n",
    "    y_pred_test = model.predict([X_matrices_coeffs_test, X_features_daily_test,X_features_individual_test, mask_daily_test, mask_individual_test])\n",
    "\n",
    "    mae_train = mean_absolute_error(y_label_train, y_pred_train)\n",
    "    mse_train = mean_squared_error(y_label_train, y_pred_train)\n",
    "\n",
    "    roc_auc_test = roc_auc_score(y_label_test, y_pred_test)\n",
    "    print(f'Test ROC AUC: {roc_auc_test:.4f}')\n",
    "\n",
    "    y_pred_train_binary = (y_pred_train > 0.5).astype(int)\n",
    "    y_pred_test_binary = (y_pred_test > 0.5).astype(int)\n",
    "    mae_test = mean_absolute_error(y_label_test, y_pred_test)\n",
    "    mse_test = mean_squared_error(y_label_test, y_pred_test)\n",
    "    accuracy = accuracy_score(y_label_test, y_pred_test_binary)\n",
    "    recall = recall_score(y_label_test, y_pred_test_binary)\n",
    "    f1 = f1_score(y_label_test, y_pred_test_binary)\n",
    "    precision = precision_score(y_label_test, y_pred_test_binary)\n",
    "    specificity = recall_score(y_label_test, y_pred_test_binary, pos_label=0)\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    print(f'Test MAE: {mae_test:.4f}')\n",
    "    print(f'Test Percision: {precision:.4f}')\n",
    "    print(f'Test Specificity: {specificity:.4f}')\n",
    "    print(f'Test Sensitivity(Recall): {recall:.4f}')\n",
    "    print(f'Test F1: {f1:.4f} \\n')\n",
    "    print(f'Fold {fold + 1} - AUC: {roc_auc_test:.4f}, Accuracy: {accuracy:.4f}, Recall: {recall:.4f}, Precision: {precision:.4f}, Specificity: {specificity:.4f}, F1: {f1:.4f}\\n')\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_label_test, y_pred_test_binary)\n",
    "    # Classification Report\n",
    "    class_report = classification_report(y_label_test, y_pred_test_binary)\n",
    "    print(conf_matrix)\n",
    "    final_results_night_morning[\"precision_scores\"].append(precision)\n",
    "    final_results_night_morning[\"recall_scores\"].append(recall)\n",
    "    final_results_night_morning[\"f1_scores\"].append(f1)\n",
    "    final_results_night_morning[\"accuracy_scores\"].append(accuracy)\n",
    "    final_results_night_morning[\"roc_auc_scores\"].append(roc_auc_test)\n",
    "    final_results_night_morning[\"specificity_scores\"].append(specificity)\n",
    "    final_results_night_morning[\"mae\"].append(mae_test)\n",
    "    final_results_night_morning[\"mse\"].append(mse_test)\n",
    "    final_results_night_morning[\"train_loss\"].append(train_score[0])\n",
    "    final_results_night_morning[\"train_acc\"].append(train_score[1])\n",
    "    final_results_night_morning[\"val_loss\"].append(val_score[0])\n",
    "    final_results_night_morning[\"val_acc\"].append(val_score[1])\n",
    "    final_results_night_morning[\"fold_train_acc\"].append(history_hypo_night_morning.history['accuracy'])\n",
    "    final_results_night_morning[\"fold_train_loss\"].append(history_hypo_night_morning.history['loss'])\n",
    "    final_results_night_morning[\"fold_val_acc\"].append(history_hypo_night_morning.history['val_accuracy'])\n",
    "    final_results_night_morning[\"fold_val_loss\"].append(history_hypo_night_morning.history['val_loss'])\n",
    "    final_results_night_morning[\"conf_matrix\"].append(conf_matrix)\n",
    "    final_results_night_morning[\"class_report\"].append(class_report)\n",
    "    final_results_night_morning[\"fold_model\"].append(model)\n",
    "          \n",
    "# Calculate and print average and std across folds\n",
    "print(f'\\nAverage Train Accuracy: {np.mean(final_results_night_morning[\"train_acc\"]):.4f} (+- {np.std(final_results_night_morning[\"train_acc\"]):.4f})')\n",
    "print(f'Average Validation Accuracy: {np.mean(final_results_night_morning[\"val_acc\"]):.4f} (+- {np.std(final_results_night_morning[\"val_acc\"]):.4f})')\n",
    "print(f'Average Test Accuracy: {np.mean(final_results_night_morning[\"accuracy_scores\"]):.4f} (+- {np.std(final_results_night_morning[\"accuracy_scores\"]):.4f})')\n",
    "print(f'Average Test Recall: {np.mean(final_results_night_morning[\"recall_scores\"]):.4f} (+- {np.std(final_results_night_morning[\"recall_scores\"]):.4f})')\n",
    "print(f'Average Test Precision: {np.mean(final_results_night_morning[\"precision_scores\"]):.4f} (+- {np.std(final_results_night_morning[\"precision_scores\"]):.4f})')\n",
    "print(f'Average Test Specificity: {np.mean(final_results_night_morning[\"specificity_scores\"]):.4f} (+- {np.std(final_results_night_morning[\"specificity_scores\"]):.4f})')\n",
    "print(f'Average Test AUC: {np.mean(final_results_night_morning[\"roc_auc_scores\"]):.4f} (+- {np.std(final_results_night_morning[\"roc_auc_scores\"]):.4f})')\n",
    "print(f'Average Test F1: {np.mean(final_results_night_morning[\"f1_scores\"]):.4f} (+- {np.std(final_results_night_morning[\"f1_scores\"]):.4f})')\n",
    "\n",
    "max_epochs = max(len(fold) for fold in final_results_night_morning[\"fold_val_loss\"])\n",
    "# Initialize arrays to store average and std dev for each epoch\n",
    "avg_loss = np.zeros(max_epochs)\n",
    "std_loss = np.zeros(max_epochs)\n",
    "avg_acc = np.zeros(max_epochs)\n",
    "std_acc = np.zeros(max_epochs)\n",
    "# Compute average and standard deviation for each epoch\n",
    "for epoch in range(max_epochs):\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    for fold_loss, fold_acc in zip(final_results_night_morning[\"fold_val_loss\"], final_results_night_morning[\"fold_val_acc\"]):\n",
    "        if epoch < len(fold_loss):\n",
    "            losses.append(fold_loss[epoch])\n",
    "        if epoch < len(fold_acc):\n",
    "            accuracies.append(fold_acc[epoch])\n",
    "    \n",
    "    if losses:\n",
    "        avg_loss[epoch] = np.mean(losses)\n",
    "        std_loss[epoch] = np.std(losses)\n",
    "    if accuracies:\n",
    "        avg_acc[epoch] = np.mean(accuracies)\n",
    "        std_acc[epoch] = np.std(accuracies)\n",
    "# Plot average loss and accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, max_epochs + 1), avg_loss, color='blue', label='Validation Loss')\n",
    "plt.fill_between(range(1, max_epochs + 1), \n",
    "                 avg_loss - std_loss,\n",
    "                 avg_loss + std_loss,\n",
    "                 color='blue', alpha=0.2)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Validation Loss per Epoch')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, max_epochs + 1), avg_acc, color='blue', label='Validation Accuracy')\n",
    "plt.fill_between(range(1, max_epochs + 1), \n",
    "                 avg_acc - std_acc,\n",
    "                 avg_acc + std_acc,\n",
    "                 color='blue', alpha=0.2)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Validation Accuracy per Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(folder_name, 'loss_accuracy_plot.png'))\n",
    "plt.show()\n",
    "\n",
    "########################################################################################################################################\n",
    "print(f\"Aggregated Models on holdout set ... \\n\")\n",
    "\n",
    "# Train-test split based on indices\n",
    "X_matrices_coeffs_holdout = X_matrices_power_scaled[holdout_idx]\n",
    "X_features_daily_holdout = X_features_daily_imputed[holdout_idx]\n",
    "X_features_individual_holdout = X_features_individual_imputed[holdout_idx]\n",
    "y_label_holdout = y_labels['hypo_night_morning'][holdout_idx]\n",
    "mask_daily_holdout = mask_daily[holdout_idx]\n",
    "mask_individual_holdout = mask_individual[holdout_idx]\n",
    "\n",
    "# Initialize arrays to store predictions from each fold\n",
    "y_pred_holdout_agg = np.zeros((len(holdout_idx),))  # Assuming binary classification\n",
    "# Aggregate predictions from each fold model\n",
    "for model in final_results_night_morning[\"fold_model\"]:\n",
    "    y_pred_holdout_fold = model.predict([X_matrices_coeffs_holdout, X_features_daily_holdout, X_features_individual_holdout, mask_daily_holdout, mask_individual_holdout])\n",
    "    y_pred_holdout_agg += y_pred_holdout_fold.flatten()  # Accumulate predictions\n",
    "# Average the predictions from all folds\n",
    "y_pred_holdout_agg /= num_splits\n",
    "\n",
    "mae_holdout = mean_absolute_error(y_label_holdout, y_pred_holdout_agg)\n",
    "mse_holdout = mean_squared_error(y_label_holdout, y_pred_holdout_agg)\n",
    "roc_auc = roc_auc_score(y_label_holdout, y_pred_holdout_agg)\n",
    "print(f'Holdout ROC AUC: {roc_auc:.4f}')\n",
    "\n",
    "y_pred_holdout_binary_agg = (y_pred_holdout_agg > 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "recall = recall_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "precision = precision_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "f1 = f1_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "specificity = recall_score(y_label_holdout, y_pred_holdout_binary_agg, pos_label=0)\n",
    "\n",
    "print(f'Holdout Accuracy: {accuracy:.4f}')\n",
    "print(f'Holdout MAE: {mae_test:.4f}')\n",
    "print(f'Holdout Percision: {precision:.4f}')\n",
    "print(f'Holdout Specificity: {specificity:.4f}')\n",
    "print(f'Holdout Sensitivity(Recall): {recall:.4f}')\n",
    "print(f'Holdout F1: {f1:.4f} \\n')\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(conf_matrix, cmap='Blues', interpolation='nearest')\n",
    "plt.title('Confusion Matrix for Final Model')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        plt.text(j, i, conf_matrix[i, j], \n",
    "                 ha='center', va='center', color='black', fontsize=14)\n",
    "plt.savefig(os.path.join(folder_name, 'holdout_conf_matrix_plot.png'))\n",
    "plt.show()\n",
    "\n",
    "description_path = os.path.join(folder_name, 'Description.txt')\n",
    "with open(description_path, 'w') as f:\n",
    "    f.write(\"\"\"\n",
    "    # K_Fold 3-channel _ORIGINAL _Below70 Hypo Night+Morning, input w/ Masking, Daily & Individual input, Classifying Hypo Night & Morning\n",
    "    \"\"\")\n",
    "        # Write the results\n",
    "    f.write(f'\\nAverage Train Accuracy: {np.mean(final_results_night_morning[\"train_acc\"]):.4f} (+- {np.std(final_results_night_morning[\"train_acc\"]):.4f})\\n')\n",
    "    f.write(f'Average Validation Accuracy: {np.mean(final_results_night_morning[\"val_acc\"]):.4f} (+- {np.std(final_results_night_morning[\"val_acc\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Accuracy: {np.mean(final_results_night_morning[\"accuracy_scores\"]):.4f} (+- {np.std(final_results_night_morning[\"accuracy_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Recall: {np.mean(final_results_night_morning[\"recall_scores\"]):.4f} (+- {np.std(final_results_night_morning[\"recall_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Precision: {np.mean(final_results_night_morning[\"precision_scores\"]):.4f} (+- {np.std(final_results_night_morning[\"precision_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Specificity: {np.mean(final_results_night_morning[\"specificity_scores\"]):.4f} (+- {np.std(final_results_night_morning[\"specificity_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test AUC: {np.mean(final_results_night_morning[\"roc_auc_scores\"]):.4f} (+- {np.std(final_results_night_morning[\"roc_auc_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test F1: {np.mean(final_results_night_morning[\"f1_scores\"]):.4f} (+- {np.std(final_results_night_morning[\"f1_scores\"]):.4f})\\n')\n",
    "    \n",
    "    # Writing holdout results\n",
    "    f.write(f'Holdout ROC AUC: {roc_auc:.4f}\\n')\n",
    "    f.write(f'Holdout Accuracy: {accuracy:.4f}\\n')\n",
    "    f.write(f'Holdout MAE: {mae_test:.4f}\\n')\n",
    "    f.write(f'Holdout Precision: {precision:.4f}\\n')\n",
    "    f.write(f'Holdout Specificity: {specificity:.4f}\\n')\n",
    "    f.write(f'Holdout Sensitivity (Recall): {recall:.4f}\\n')\n",
    "    f.write(f'Holdout F1: {f1:.4f}\\n')\n",
    "model_summary_path = os.path.join(folder_name, 'model_summary.txt')\n",
    "with open(model_summary_path, 'w') as f:\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "#model.summary()\n",
    "# Save the final results as pickle\n",
    "final_results_path = os.path.join(folder_name, 'final_results.pkl')\n",
    "with open(final_results_path, 'wb') as file:\n",
    "    pickle.dump(final_results_night_morning, file)\n",
    "\n",
    "print(\"\\nBest 3 models (ROC AUC) to prdict holdout:\")\n",
    "best_of = 3\n",
    "top_3_model_indices = np.argsort(final_results_night_morning[\"roc_auc_scores\"])[-best_of:][::-1]\n",
    "y_pred_holdout_agg = np.zeros((len(holdout_idx),))  # Assuming binary classification\n",
    "for idx in top_3_model_indices:\n",
    "    model = final_results_night_morning[\"fold_model\"][idx]\n",
    "    y_pred_holdout_fold = model.predict([X_matrices_coeffs_holdout, X_features_daily_holdout, X_features_individual_holdout, mask_daily_holdout, mask_individual_holdout])\n",
    "    y_pred_holdout_agg += y_pred_holdout_fold.flatten()\n",
    "y_pred_holdout_agg /= best_of\n",
    "\n",
    "mae_holdout = mean_absolute_error(y_label_holdout, y_pred_holdout_agg)\n",
    "mse_holdout = mean_squared_error(y_label_holdout, y_pred_holdout_agg)\n",
    "roc_auc = roc_auc_score(y_label_holdout, y_pred_holdout_agg)\n",
    "print(f'Holdout ROC AUC: {roc_auc:.4f}')\n",
    "\n",
    "y_pred_holdout_binary_agg = (y_pred_holdout_agg > 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "recall = recall_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "precision = precision_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "f1 = f1_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "specificity = recall_score(y_label_holdout, y_pred_holdout_binary_agg, pos_label=0)\n",
    "\n",
    "print(f'Holdout Accuracy: {accuracy:.4f}')\n",
    "print(f'Holdout MAE: {mae_test:.4f}')\n",
    "print(f'Holdout Percision: {precision:.4f}')\n",
    "print(f'Holdout Specificity: {specificity:.4f}')\n",
    "print(f'Holdout Sensitivity(Recall): {recall:.4f}')\n",
    "print(f'Holdout F1: {f1:.4f} \\n')\n",
    "conf_matrix = confusion_matrix(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "conf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37ecdc9-26b1-438e-ba4b-a3b5488020f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# AUC Focued ORIGINAL 70 K_Fold 3-channel input w/ Masking, Daily & Individual input, Classifying Hypo day\n",
    "########################################################################################################################################\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "folder_name = \"/home/ma98/Compressed_DEXI_Data/Hypo_70_Original/Hypo_Day\"\n",
    "\n",
    "matrix_shape0 = 288\n",
    "# Reshape matrices to the required shapes\n",
    "X_features_daily_imputed = np.nan_to_num(X_features_daily_scaled, nan=0.0)\n",
    "X_features_individual_imputed = np.nan_to_num(X_features_individual_scaled, nan=0.0)\n",
    "\n",
    "# Create masks for missing values\n",
    "mask_daily = np.isfinite(X_features_daily_scaled).astype(np.float32)\n",
    "mask_individual = np.isfinite(X_features_individual_scaled).astype(np.float32)\n",
    "\n",
    "# Initialize GroupKFold\n",
    "num_splits = 4\n",
    "group_kfold = GroupKFold(n_splits=num_splits)\n",
    "unique_participants = np.unique(participant_ids)\n",
    "# # Shuffle to ensure no artifacts in test train/validation split\n",
    "# unique_participants = shuffle(unique_participants, random_state=42)\n",
    "\n",
    "# Completely hold out a test set before cross-validation\n",
    "holdout_participants = unique_participants[int(0.95 * len(unique_participants)):]\n",
    "holdout_idx = np.where(np.isin(participant_ids, holdout_participants))[0]\n",
    "\n",
    "# Remove the holdout participants from the pool used for cross-validation model\n",
    "model_participants = unique_participants[:int(0.95 * len(unique_participants))]\n",
    "final_results_day = {\n",
    "    \"fold_model\": [],\n",
    "    \"specificity_scores\": [],\n",
    "    \"accuracy_scores\": [],\n",
    "    \"precision_scores\": [],\n",
    "    \"recall_scores\": [],\n",
    "    \"f1_scores\": [],\n",
    "    \"roc_auc_scores\": [],\n",
    "    \"mae\": [],\n",
    "    \"mse\": [],\n",
    "    \"fold_train_loss\": [],\n",
    "    \"fold_train_acc\": [],\n",
    "    \"fold_val_loss\": [],\n",
    "    \"fold_val_acc\": [],\n",
    "    \"conf_matrix\": [],\n",
    "    \"class_report\": [],\n",
    "    \"train_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_acc\": []\n",
    "}\n",
    "for fold, (train_idx, val_test_idx) in enumerate(group_kfold.split(X_matrices_power_scaled, y_labels['hypo_day'], groups=participant_ids)):\n",
    "    # 75% of the data as train set\n",
    "    train_participants = model_participants[np.isin(model_participants, participant_ids[train_idx])]\n",
    "    # train_participants = shuffle(train_participants, random_state=42)  # Shuffle train participants\n",
    "    \n",
    "    # Randomly shuffle and Split remaining data into validation and test based on participants\n",
    "    val_test_participants = model_participants[np.isin(model_participants, participant_ids[val_test_idx])]\n",
    "    # val_test_participants = shuffle(val_test_participants, random_state=42)  # Shuffle val_test participants\n",
    "    \n",
    "    val_size = int(len(val_test_participants) * 3 / 5)\n",
    "    val_participants = val_test_participants[:val_size]\n",
    "    test_participants = val_test_participants[val_size:]\n",
    "    \n",
    "    # Get corresponding indices\n",
    "    val_idx = np.where(np.isin(participant_ids, val_participants))[0]\n",
    "    test_idx = np.where(np.isin(participant_ids, test_participants))[0]\n",
    "    print(f\"Processing fold {fold + 1}...\")\n",
    "    print(f\"{len(train_participants)}, {len(val_participants)}, {len(test_participants)}, participants in Train, Validation, and Test sets\" )\n",
    "\n",
    "    # Train-test split based on indices\n",
    "    X_matrices_coeffs_train,X_matrices_coeffs_val, X_matrices_coeffs_test = X_matrices_power_scaled[train_idx],X_matrices_power_scaled[val_idx], X_matrices_power_scaled[test_idx]\n",
    "    X_features_daily_train,X_features_daily_val, X_features_daily_test = X_features_daily_imputed[train_idx],X_features_daily_imputed[val_idx], X_features_daily_imputed[test_idx]\n",
    "    X_features_individual_train,X_features_individual_val, X_features_individual_test = X_features_individual_imputed[train_idx],X_features_individual_imputed[val_idx], X_features_individual_imputed[test_idx]\n",
    "    y_label_train,y_label_val, y_label_test = y_labels['hypo_day'][train_idx],y_labels['hypo_day'][val_idx], y_labels['hypo_day'][test_idx]\n",
    "    mask_daily_train,mask_daily_val, mask_daily_test = mask_daily[train_idx], mask_daily[val_idx], mask_daily[test_idx]\n",
    "    mask_individual_train,mask_individual_val, mask_individual_test = mask_individual[train_idx],mask_individual[val_idx], mask_individual[test_idx]\n",
    "    num_epochs = 25\n",
    "    # Create a new model instance\n",
    "    model = create_model()\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True)\n",
    "    # checkpoint = ModelCheckpoint(filepath=os.path.join(folder_name, 'best_model_fold_{}.keras'.format(fold)), monitor='val_AUC', save_best_only=True, mode='max')\n",
    "    learning_rate_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-7)\n",
    "    y_label_train_flat = y_label_train.ravel()\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_label_train_flat), y=y_label_train_flat)\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "    print(\"Class weights: \", class_weight_dict)\n",
    "    history_hypo_day = model.fit([X_matrices_coeffs_train, X_features_daily_train, X_features_individual_train, mask_daily_train, mask_individual_train], \n",
    "                                         y_label_train, \n",
    "                                         epochs=num_epochs, batch_size=16, verbose=1,\n",
    "                                         validation_data=([X_matrices_coeffs_val, X_features_daily_val, X_features_individual_val, mask_daily_val, mask_individual_val], y_label_val),\n",
    "                                         callbacks=[early_stopping, learning_rate_scheduler],\n",
    "                                         class_weight=class_weight_dict)\n",
    "    # Evaluate training and testing performance\n",
    "    train_score = model.evaluate([X_matrices_coeffs_train_resampled, X_features_daily_train_resampled, X_features_individual_train_resampled, mask_daily_train_resampled, mask_individual_train_resampled], \n",
    "                                 y_label_train_resampled, verbose=0)\n",
    "    val_score = model.evaluate([X_matrices_coeffs_val_resampled, X_features_daily_val_resampled, X_features_individual_val_resampled, mask_daily_val_resampled, mask_individual_val_resampled], \n",
    "                                y_label_val_resampled, verbose=0)\n",
    "    print('\\nTrain loss: {}, Train accuracy: {}'.format(train_score[0], train_score[1]))\n",
    "    print('Validation loss: {}, Validation accuracy: {}'.format(val_score[0], val_score[1]))\n",
    "    # print('Test loss: {}, Test accuracy: {}\\n'.format(test_score[0], test_score[1]))\n",
    "    y_pred_train = model.predict([X_matrices_coeffs_train, X_features_daily_train,X_features_individual_train, mask_daily_train, mask_individual_train])\n",
    "    y_pred_test = model.predict([X_matrices_coeffs_test, X_features_daily_test,X_features_individual_test, mask_daily_test, mask_individual_test])\n",
    "\n",
    "    mae_train = mean_absolute_error(y_label_train, y_pred_train)\n",
    "    mse_train = mean_squared_error(y_label_train, y_pred_train)\n",
    "\n",
    "    roc_auc_test = roc_auc_score(y_label_test, y_pred_test)\n",
    "    print(f'Test ROC AUC: {roc_auc_test:.4f}')\n",
    "\n",
    "    y_pred_train_binary = (y_pred_train > 0.5).astype(int)\n",
    "    y_pred_test_binary = (y_pred_test > 0.5).astype(int)\n",
    "    mae_test = mean_absolute_error(y_label_test, y_pred_test)\n",
    "    mse_test = mean_squared_error(y_label_test, y_pred_test)\n",
    "    accuracy = accuracy_score(y_label_test, y_pred_test_binary)\n",
    "    recall = recall_score(y_label_test, y_pred_test_binary)\n",
    "    f1 = f1_score(y_label_test, y_pred_test_binary)\n",
    "    precision = precision_score(y_label_test, y_pred_test_binary)\n",
    "    specificity = recall_score(y_label_test, y_pred_test_binary, pos_label=0)\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    print(f'Test MAE: {mae_test:.4f}')\n",
    "    print(f'Test Percision: {precision:.4f}')\n",
    "    print(f'Test Specificity: {specificity:.4f}')\n",
    "    print(f'Test Sensitivity(Recall): {recall:.4f}')\n",
    "    print(f'Test F1: {f1:.4f} \\n')\n",
    "    print(f'Fold {fold + 1} - AUC: {roc_auc_test:.4f}, Accuracy: {accuracy:.4f}, Recall: {recall:.4f}, Precision: {precision:.4f}, Specificity: {specificity:.4f}, F1: {f1:.4f}\\n')\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_label_test, y_pred_test_binary)\n",
    "    # Classification Report\n",
    "    class_report = classification_report(y_label_test, y_pred_test_binary)\n",
    "    print(conf_matrix)\n",
    "    final_results_day[\"precision_scores\"].append(precision)\n",
    "    final_results_day[\"recall_scores\"].append(recall)\n",
    "    final_results_day[\"f1_scores\"].append(f1)\n",
    "    final_results_day[\"accuracy_scores\"].append(accuracy)\n",
    "    final_results_day[\"roc_auc_scores\"].append(roc_auc_test)\n",
    "    final_results_day[\"specificity_scores\"].append(specificity)\n",
    "    final_results_day[\"mae\"].append(mae_test)\n",
    "    final_results_day[\"mse\"].append(mse_test)\n",
    "    final_results_day[\"train_loss\"].append(train_score[0])\n",
    "    final_results_day[\"train_acc\"].append(train_score[1])\n",
    "    final_results_day[\"val_loss\"].append(val_score[0])\n",
    "    final_results_day[\"val_acc\"].append(val_score[1])\n",
    "    final_results_day[\"fold_train_acc\"].append(history_hypo_day.history['accuracy'])\n",
    "    final_results_day[\"fold_train_loss\"].append(history_hypo_day.history['loss'])\n",
    "    final_results_day[\"fold_val_acc\"].append(history_hypo_day.history['val_accuracy'])\n",
    "    final_results_day[\"fold_val_loss\"].append(history_hypo_day.history['val_loss'])\n",
    "    final_results_day[\"conf_matrix\"].append(conf_matrix)\n",
    "    final_results_day[\"class_report\"].append(class_report)\n",
    "    final_results_day[\"fold_model\"].append(model)\n",
    "          \n",
    "# Calculate and print average and std across folds\n",
    "print(f'\\nAverage Train Accuracy: {np.mean(final_results_day[\"train_acc\"]):.4f} (+- {np.std(final_results_day[\"train_acc\"]):.4f})')\n",
    "print(f'Average Validation Accuracy: {np.mean(final_results_day[\"val_acc\"]):.4f} (+- {np.std(final_results_day[\"val_acc\"]):.4f})')\n",
    "print(f'Average Test Accuracy: {np.mean(final_results_day[\"accuracy_scores\"]):.4f} (+- {np.std(final_results_day[\"accuracy_scores\"]):.4f})')\n",
    "print(f'Average Test Recall: {np.mean(final_results_day[\"recall_scores\"]):.4f} (+- {np.std(final_results_day[\"recall_scores\"]):.4f})')\n",
    "print(f'Average Test Precision: {np.mean(final_results_day[\"precision_scores\"]):.4f} (+- {np.std(final_results_day[\"precision_scores\"]):.4f})')\n",
    "print(f'Average Test Specificity: {np.mean(final_results_day[\"specificity_scores\"]):.4f} (+- {np.std(final_results_day[\"specificity_scores\"]):.4f})')\n",
    "print(f'Average Test AUC: {np.mean(final_results_day[\"roc_auc_scores\"]):.4f} (+- {np.std(final_results_day[\"roc_auc_scores\"]):.4f})')\n",
    "print(f'Average Test F1: {np.mean(final_results_day[\"f1_scores\"]):.4f} (+- {np.std(final_results_day[\"f1_scores\"]):.4f})')\n",
    "\n",
    "max_epochs = max(len(fold) for fold in final_results_day[\"fold_val_loss\"])\n",
    "# Initialize arrays to store average and std dev for each epoch\n",
    "avg_loss = np.zeros(max_epochs)\n",
    "std_loss = np.zeros(max_epochs)\n",
    "avg_acc = np.zeros(max_epochs)\n",
    "std_acc = np.zeros(max_epochs)\n",
    "# Compute average and standard deviation for each epoch\n",
    "for epoch in range(max_epochs):\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    for fold_loss, fold_acc in zip(final_results_day[\"fold_val_loss\"], final_results_day[\"fold_val_acc\"]):\n",
    "        if epoch < len(fold_loss):\n",
    "            losses.append(fold_loss[epoch])\n",
    "        if epoch < len(fold_acc):\n",
    "            accuracies.append(fold_acc[epoch])\n",
    "    \n",
    "    if losses:\n",
    "        avg_loss[epoch] = np.mean(losses)\n",
    "        std_loss[epoch] = np.std(losses)\n",
    "    if accuracies:\n",
    "        avg_acc[epoch] = np.mean(accuracies)\n",
    "        std_acc[epoch] = np.std(accuracies)\n",
    "# Plot average loss and accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, max_epochs + 1), avg_loss, color='blue', label='Validation Loss')\n",
    "plt.fill_between(range(1, max_epochs + 1), \n",
    "                 avg_loss - std_loss,\n",
    "                 avg_loss + std_loss,\n",
    "                 color='blue', alpha=0.2)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Validation Loss per Epoch')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, max_epochs + 1), avg_acc, color='blue', label='Validation Accuracy')\n",
    "plt.fill_between(range(1, max_epochs + 1), \n",
    "                 avg_acc - std_acc,\n",
    "                 avg_acc + std_acc,\n",
    "                 color='blue', alpha=0.2)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Validation Accuracy per Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(folder_name, 'loss_accuracy_plot.png'))\n",
    "plt.show()\n",
    "\n",
    "########################################################################################################################################\n",
    "print(f\"Aggregated Models on holdout set ... \\n\")\n",
    "\n",
    "# Train-test split based on indices\n",
    "X_matrices_coeffs_holdout = X_matrices_power_scaled[holdout_idx]\n",
    "X_features_daily_holdout = X_features_daily_imputed[holdout_idx]\n",
    "X_features_individual_holdout = X_features_individual_imputed[holdout_idx]\n",
    "y_label_holdout = y_labels['hypo_day'][holdout_idx]\n",
    "mask_daily_holdout = mask_daily[holdout_idx]\n",
    "mask_individual_holdout = mask_individual[holdout_idx]\n",
    "\n",
    "# Initialize arrays to store predictions from each fold\n",
    "y_pred_holdout_agg = np.zeros((len(holdout_idx),))  # Assuming binary classification\n",
    "# Aggregate predictions from each fold model\n",
    "for model in final_results_day[\"fold_model\"]:\n",
    "    y_pred_holdout_fold = model.predict([X_matrices_coeffs_holdout, X_features_daily_holdout, X_features_individual_holdout, mask_daily_holdout, mask_individual_holdout])\n",
    "    y_pred_holdout_agg += y_pred_holdout_fold.flatten()  # Accumulate predictions\n",
    "# Average the predictions from all folds\n",
    "y_pred_holdout_agg /= num_splits\n",
    "\n",
    "mae_holdout = mean_absolute_error(y_label_holdout, y_pred_holdout_agg)\n",
    "mse_holdout = mean_squared_error(y_label_holdout, y_pred_holdout_agg)\n",
    "roc_auc = roc_auc_score(y_label_holdout, y_pred_holdout_agg)\n",
    "print(f'Holdout ROC AUC: {roc_auc:.4f}')\n",
    "\n",
    "y_pred_holdout_binary_agg = (y_pred_holdout_agg > 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "recall = recall_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "precision = precision_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "f1 = f1_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "specificity = recall_score(y_label_holdout, y_pred_holdout_binary_agg, pos_label=0)\n",
    "\n",
    "print(f'Holdout Accuracy: {accuracy:.4f}')\n",
    "print(f'Holdout MAE: {mae_test:.4f}')\n",
    "print(f'Holdout Percision: {precision:.4f}')\n",
    "print(f'Holdout Specificity: {specificity:.4f}')\n",
    "print(f'Holdout Sensitivity(Recall): {recall:.4f}')\n",
    "print(f'Holdout F1: {f1:.4f} \\n')\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(conf_matrix, cmap='Blues', interpolation='nearest')\n",
    "plt.title('Confusion Matrix for Final Model')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        plt.text(j, i, conf_matrix[i, j], \n",
    "                 ha='center', va='center', color='black', fontsize=14)\n",
    "plt.savefig(os.path.join(folder_name, 'holdout_conf_matrix_plot.png'))\n",
    "plt.show()\n",
    "\n",
    "description_path = os.path.join(folder_name, 'Description.txt')\n",
    "with open(description_path, 'w') as f:\n",
    "    f.write(\"\"\"\n",
    "    # K_Fold 3-channel AUC Focused+Class Weights _ORIGINAL _Below70 Hypo Night+Morning, input w/ Masking, Daily & Individual input, Classifying Hypo Night & Morning\n",
    "    \"\"\")\n",
    "        # Write the results\n",
    "    f.write(f'\\nAverage Train Accuracy: {np.mean(final_results_day[\"train_acc\"]):.4f} (+- {np.std(final_results_day[\"train_acc\"]):.4f})\\n')\n",
    "    f.write(f'Average Validation Accuracy: {np.mean(final_results_day[\"val_acc\"]):.4f} (+- {np.std(final_results_day[\"val_acc\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Accuracy: {np.mean(final_results_day[\"accuracy_scores\"]):.4f} (+- {np.std(final_results_day[\"accuracy_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Recall: {np.mean(final_results_day[\"recall_scores\"]):.4f} (+- {np.std(final_results_day[\"recall_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Precision: {np.mean(final_results_day[\"precision_scores\"]):.4f} (+- {np.std(final_results_day[\"precision_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test Specificity: {np.mean(final_results_day[\"specificity_scores\"]):.4f} (+- {np.std(final_results_day[\"specificity_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test AUC: {np.mean(final_results_day[\"roc_auc_scores\"]):.4f} (+- {np.std(final_results_day[\"roc_auc_scores\"]):.4f})\\n')\n",
    "    f.write(f'Average Test F1: {np.mean(final_results_day[\"f1_scores\"]):.4f} (+- {np.std(final_results_day[\"f1_scores\"]):.4f})\\n')\n",
    "    \n",
    "    # Writing holdout results\n",
    "    f.write(f'Holdout ROC AUC: {roc_auc:.4f}\\n')\n",
    "    f.write(f'Holdout Accuracy: {accuracy:.4f}\\n')\n",
    "    f.write(f'Holdout MAE: {mae_test:.4f}\\n')\n",
    "    f.write(f'Holdout Precision: {precision:.4f}\\n')\n",
    "    f.write(f'Holdout Specificity: {specificity:.4f}\\n')\n",
    "    f.write(f'Holdout Sensitivity (Recall): {recall:.4f}\\n')\n",
    "    f.write(f'Holdout F1: {f1:.4f}\\n')\n",
    "model_summary_path = os.path.join(folder_name, 'model_summary.txt')\n",
    "with open(model_summary_path, 'w') as f:\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "#model.summary()\n",
    "# Save the final results as pickle\n",
    "final_results_path = os.path.join(folder_name, 'final_results.pkl')\n",
    "with open(final_results_path, 'wb') as file:\n",
    "    pickle.dump(final_results_day, file)\n",
    "\n",
    "print(\"\\nBest 3 models (ROC AUC) to prdict holdout:\")\n",
    "best_of = 3\n",
    "top_3_model_indices = np.argsort(final_results_day[\"roc_auc_scores\"])[-best_of:][::-1]\n",
    "y_pred_holdout_agg = np.zeros((len(holdout_idx),))  # Assuming binary classification\n",
    "for idx in top_3_model_indices:\n",
    "    model = final_results_day[\"fold_model\"][idx]\n",
    "    y_pred_holdout_fold = model.predict([X_matrices_coeffs_holdout, X_features_daily_holdout, X_features_individual_holdout, mask_daily_holdout, mask_individual_holdout])\n",
    "    y_pred_holdout_agg += y_pred_holdout_fold.flatten()\n",
    "y_pred_holdout_agg /= best_of\n",
    "\n",
    "mae_holdout = mean_absolute_error(y_label_holdout, y_pred_holdout_agg)\n",
    "mse_holdout = mean_squared_error(y_label_holdout, y_pred_holdout_agg)\n",
    "roc_auc = roc_auc_score(y_label_holdout, y_pred_holdout_agg)\n",
    "print(f'Holdout ROC AUC: {roc_auc:.4f}')\n",
    "\n",
    "y_pred_holdout_binary_agg = (y_pred_holdout_agg > 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "recall = recall_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "precision = precision_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "f1 = f1_score(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "specificity = recall_score(y_label_holdout, y_pred_holdout_binary_agg, pos_label=0)\n",
    "\n",
    "print(f'Holdout Accuracy: {accuracy:.4f}')\n",
    "print(f'Holdout MAE: {mae_test:.4f}')\n",
    "print(f'Holdout Percision: {precision:.4f}')\n",
    "print(f'Holdout Specificity: {specificity:.4f}')\n",
    "print(f'Holdout Sensitivity(Recall): {recall:.4f}')\n",
    "print(f'Holdout F1: {f1:.4f} \\n')\n",
    "conf_matrix = confusion_matrix(y_label_holdout, y_pred_holdout_binary_agg)\n",
    "conf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07056c7-4856-4883-8500-1fd35e960031",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
